---
title: Nginx Cookbook
categories:
- Nginx
feature_text: |
  ## Nginx Cookbook
feature_image: "https://picsum.photos/2560/600?image=733"
image: "https://picsum.photos/2560/600?image=733"
---
<style>
	thead td { text-align: center; }
	td { border: 1px solid #444444; }
</style>

+ ADC(Application Delivery Controller)  
서버에서 구동되는 코드 혹은 코드의 산출물을 사용자에게 전달하는 과정에서 필요한 전송과 보안을 담당해 부하를 분산하고 가용성을 보장하는 하드웨어나 소프트웨어  

### 1. 엔진엑스 기초  
<br/>

#### 1.5. 주요 설정 파일, 디렉터리, 명령어  
<br/>

##### 1.5.1. 엔진엑스 주요 설정 파일과 디렉터리  
<br/>

+ /etc/nginx/  
엔진엑스 서버가 사용하는 기본 설정이 저장된 루트 디렉터리  

+ /etc/nginx/nginx.conf  
엔진엑스의 기본 설정 파일로, 모든 설정에 대한 진입점입니다. 워커 프로세스 개수, 튜닝, 동적 모듈 적재와 같은 글로벌 설정 항목을 포함하며, 다른 엔진엑스 세부 설정 파일에 대한 참조를 지정합니다. 그뿐 아니라 이어서 설명할 디렉터리에 위치한 모든 설정 파일을 포함하는 최상위 http 블록을 갖고 있습니다.  

+ /etc/nginx/conf.d/  
기본 HTTP 서버 설정 파일을 포함합니다. 디렉터리 내 파일 중 이름이 .conf로 끝나는 파일은 앞서 언급한 /etc/nginx/nginx.conf 파일이 가진 최상위 http 블록에 포함됩니다. 이처럼 엔진엑스 설정은 include 구문을 활용해 구조화함으로써 각 설정 파일을 간결하게 유지하면 좋습니다. 몇몇 패키지 저장소에서 배포되는 엔진엑스는 설치 시 conf.d 디렉터리 대신 site-enabled 디렉터리가 있고, symlink를 통해 site-available 디렉터리에 저장된 설정 파일들이 연결돼 있을 수 있습니다. 하지만 이 방식은 더 이상 사용되지 않습니다.  

+ /var/log/nginx/  
엔진엑스의 로그가 저장되는 디렉터리로, access.log와 error.log 파일이 있습니다. 접근 로그 파일은 엔진엑스 서버가 수신한 개별 요청에 대한 로그를 저장하며, 오류 로그 파일은 오류 발생 시 이벤트 내용을 저장합니다. 엔진엑스 설정을 통해 debug 모듈을 활성화했다면 디버그 정보도 오류 로그 파일에 기록됩니다.  

##### 1.5.2. 엔진엑스 명령어  
<br/>

+ nginx -h  
엔진엑스 도움말을 살펴봅니다.

+ nginx -v  
엔진엑스 버전 정보를 확인합니다.

+ nginx -V  
엔진엑스 버전 정보뿐아니라 빌드 정보를 보여줍니다. 그리고 엔진엑스 바이너리에 포함된 모듈을 보여주는 설정 인숫값을 확인합니다.  

+ nginx -t  
엔진엑스 설정을 시험합니다.  

+ nginx -T  
엔진엑스 설정을 시험하고 결과를 화면에 보여줍니다. 기술 지원이 필요할 때 유용합니다.  

+ nginx -s signal  
-s 매개변수는 지정된 신호(stop, quit, reload, reopen)를 엔진엑스 마스터 프로세스에 전송합니다. stop은 엔진엑스 프로세스가 즉시 동작을 멈추게 하며 quit은 현재 진행 중인 요청을 모두 처리한 뒤 엔진엑스 프로세스를 종료합니다. reload는 엔진엑스가 설정을 다시 읽어들이게 하며 reopen은 지정된 로그 파일을 다시 열도록 명령합니다. 매개변수는 네 가지 신호만 지원하지만 엔진엑스 프로세스 자체는 더 많은 신호를 처리할 수 있습니다. 자세한 내용은 https://www.nginx.com/resources/start/topics/tutorials/commandline을 참고하기 바랍니다.  

#### 1.6. 정적 콘텐츠 서비스하기  
<br/>

```
server {
    listen 80 default_server;
    server_name www.example.com

    location / {
        root /usr/share/nginx/html;
        # alias /usr/share/nginx/html;
        index index.html index.htm;
    }
}
```

+ server 블록  
엔진엑스가 처리할 새로운 컨텍스트(context)를 정의  

+ default_server 매개변수  
매개변수가 선언된 블록에 정의된 내용이 80 포트에 대한 기본 컨텍스트(default context)가 되도록 사용  

+ listen 지시자  
요청을 받을 단일 포트 또는 포트범위를 정의  

+ server_name 지시자  
서버가 처리할 호스트명(hostname)이나 도메인명을 지정하고 설정이 default_server 매개변수를 통해 기본 컨텍스트로 지정되지 않았다면, 엔진엑스는 요청 호스트 헤더값이 server_name 지시자에 지정된 값과 같을 때만 server 블록에 지정된 내용을 수행  

+ location 블록  
URL의 경로를 기반으로 엔진엑스는 요청된 URI에 가장 적합한 location 블록을 찾으며 URI 접두어를 사용했다면 이 값도 root 지시자에 지정한 값을 결합

+ root 지시자  
주어진 컨텍스트에서 콘텐츠를 제공할 때 서버의 어떤 경로에서 파일을 찾을지 알림  

+ index 지시자  
URI에 더는 참고할 경로 정보가 없을 때 엔진엑스가 사용할 기본 파일 혹은 확인할 파일 목록을 알림  

#### 1.7 무중단으로 설정 리로드하기  
<br/>

```
nginx -s reload
```

### 2. 고성능 부하분산  
<br/>

+ 업스트림 서버  
로드 밸런서나 프록시 서버 뒤에 위치한 실제 서버 장비  

+ 엑티브(active) 방식  
로드 밸런서 장비가 스스로 업스트림 서버와 주기적으로 연결을 시도하거나 요청을 보내 서버 응답에 문제가 없는지 확인하는 방식으로 업스트림 서버의 상태를 사용자 요청을 받기 전에 미리 확인할 때 사용  

+ 패시브 방식  
사용자의 요청을 로드 밸런서가 받은 시점에 업스트림 서버와의 연결이나 응답을 확인하는 방식으로 업스트림 서버의 부하를 늘리지 않으면서 상태를 확인할 때 사용  

#### 2.1. HTTP 부하분산  
<br/>

```
upstream backend {
    server 10.10.12.45:80       weight=1;
    server app.example.com:80   weight=2;
    server spare.example.com:80 backup;
}
server {
    location / {
        proxy_pass https://backend;
    }
}
```
+ 프라이머리(primary) 서버  
server 지시자에 weight 매개변수로 가중치를 설정한 서버  

+ HTTP upstream 모듈  
HTTP 프로토콜 요청에 대한 부하분산 방식과 개별 요청에 대해 어떤 업스트림 서버를 할당할지 매개변수로 정의

+ 목적지 풀(pool)  
여러 대의 서버를 지칭하는 용어로, 서버 그룹 혹은 서버 팜(farm)이라고도 합니다.  

+ server 지시자  
유닉스 소켓, IP 주소, 전제 주소 도메인 네임(fully qualified domain name) 형식으로 표시된 도메인 정보 등을 몇 가지 추가 매개변수와 함께 지정하고 매개변수는 요청을 적절한 목적지로 전달하도록 추가 제어 방법을 제공하며 분산 알고리즘에 가중치를 적용하거나 서버가 어떤 상태인지 알려주며, 서버 가용 여부를 판단하는 방법 등을 포함  

이 엔진엑스 설정은 80 포트를 사용하는 HTTP 서버 두 대로 부하를 분산합니다. 설정한 프라이머리(primary) 서버 두 대에 문제가 발생해 연결이 불가능하면 backup으로 지정한 서버를 사용합니다. 지정한 weight 매개변수값에 따라 두 번째 서버는 첫 번째 서보보다 두 배 많은 요청을 받습니다. 참고로 weight의 기본값은 1이며 생략할 수 있습니다.  

부하분산을 위한 목적지 풀은 유닉스 소켓, IP 주소, DNS(Domain name server) 레코드 혹은 이들의 조합으로 구성합니다. 엔진엑스 플러스는 고급 매개변수를 제공해, 특정 서버로의 연결 수를 제한하거나, 고급 DNS 질의를 제어하고 가동된 지 얼마 안 된 서버로는 연결이 천천히 늘어가도록 할 수 있습니다.  

#### 2.2. TCP 부하분산  
<br/>

```
stream {
    upstream mysql_read {
        server read1.example.com:3306 weight=5;
        server read2.example.com:3306;
        server 10.10.12.34:3306 backup;
    }
    server {
        listen 3306;
        proxy_pass mysql_read;
    }
}
```

이 엔진엑스 설정의 server 블록은 3306 포트로 TCP 요청을 받아 읽기 전용 복제본(read replica) 두 대로 구성된 MySQL 서버로 부하를 분산합니다. 만약 프라이머리로 지정한 MySQL 서버 두 대가 모두 다운되면 backup 매개변수로 지정한 서버로 요청을 전달합니다.  

엔진엑스 설치 전후 특별히 설정을 바꾸지 않았다면 엔진엑스의 기본 설정 파일 경로인 conf.d 폴더는 http 블록에 포함됩니다. 따라서 stream 모듈을 이용한 이 설정은 stream.conf.d라는 별도의 폴더를 생성해 저장하는 편이 좋습니다. 경로를 nginx.conf 파일의 stream 블록에 추가해 엔진엑스가 참조하도록 합니다.  

/etc/nginx/nginx.conf 설정 파일
```
user nginx;
worker_processes auto;
pid /run/nginx.pid;

stream {
    include /etc/nginx/stream.conf.d/*.conf;
}
```

/etc/nginx/stream.conf.d/mysql_read.conf 설정 파일
```
upstream mysql_read {
    server read1.example.com:3306;  weight=5;
    server read2.example.com:3306;
    server 10.10.12.34:3306         backup;
}

server {
    listen 3306;
    proxy_pass mysql_read;
}
```

http와 stream의 가장 큰 차이점은 두 모듈이 OSI 모델의 서로 다른 계층에서 동작한다는 점입니다. http 컨텍스트는 OSI 모델의 7계층인 애플리케이션 계층(application layer)에서 동작하며 stream 컨텍스트는 4계층인 전송 계층(transport layer)에서 동작합니다. 그렇다고 stream 모듈이 (아무리 잘 만들어진 스크립트가 있더라도) 애플리케이션을 인지해 동작할 수 없음을 의미하지는 않습니다. 다만 http 모듈이 HTTP 프로토콜을 완전히 이해하도록 특별히 설계된 반면 stream 모듈은 패킷의 전달 경로 결정과 부하분산에 더 중점을 둔다는 정도로 이해하면 적당하겠습니다.  

엔진엑스에서 TCP 부하분산은 stream 모듈을 이용해 정의합니다. http 모듈과 마찬가지로 stream 모듈도 업스트림 서버 풀을 만들거나 수신할 개별 서버를 지정합니다. 서버가 특정 포트로 요청을 받게 하려면 수신할 포트를 설정에 추가하거나 IP 주소와 함께 포트 번호를 기술합니다. 정의한 서버가 다른 서버로 요청을 전달하는 리버스 프록시 서버인지 혹은 일반적인 업스트림 풀에 포함된 서버인지에 관계없이 목적지 서버 목록에 정의합니다.  

stream 모듈을 이용하는 경우 옵션을 통해 TCP 연결과 관계된 리버스 프록시의 여러 고성을 변경할 수 있습니다. 대표적인 속성으로는 유효한 SSL/TLS 인증서 제한, 타임아웃, 킵얼라이브(keepalive) 시간 설정 등이 있습니다. 일부 옵션은 엔진엑스 변수를 값으로 사용할 수 있는데, 다운로드 속도 제한이나 SSL/TLS 인증서 유효성 검사에서 사용할 이름이 지정된 변수 혹은 이 변수가 포함된 값을 옵션에 사용할 수 있습니다.  

TCP 부하분산을 위한 업스트림 블록은 HTTP의 업스트림 블록과 매우 유사합니다. 목적지를 정의하는 데 유닉스 소켓, IP 주소, FQDN을 사용하며 가중치, 최대 동시 연결 수, DNS 리졸버(resolver), 연결 증가 주기, 서버의 상태 매개변수 등을 사용합니다.  

엔진엑스 플러스는 TCP 부하분산을 위한 기능을 보다 많이 제공합니다.  

#### 2.3. UDP 부하분산  
<br/>

```
stream {
    upstream ntp {
        server ntp1.example.com:123 weight=2;
        server ntp2.example.com:123;
    }

    server {
        listen 123 udp;
        proxy_pass ntp;
    }
}
```

예시의 설정은 UDP 프로토콜을 사용해 네트워크 타임 프로토콜(Network Time Protocol) 서버 두 대로 부하를 전달합니다. UDP 프로토콜의 부하분산 설정은 listen 지시자에 udp 매개변수만 추가하면 될 정도로 무척 간단합니다.  

부하분산이 적용된 서비스에서 클라이언트와 서버가 패킷을 여러 번 주고받아야 한다면 reuseport 매개변수를 사용합니다. 부하분산이 적용된 서비스는 오픈VPN(OpenVPN), 음성 인터넷 프로토콜(Voice over Internet Protocol), 가상 데스크톱 환경, DTLS(Datagram Transport Layer Security)가 대표적입니다.  

다음 예시는 엔진엑스를 통해 오픈VPN에 대한 연결을 관리하고 로컬 환경에서 동작 중인 오픈VPN으로 패킷을 전달해주는 설정입니다.  

```
stream {
    server {
        listen 1195 udp reuseport;
        proxy_pass 127.0.0.1:1194;
    }
}
```

"DNS를 이용해 여러 개의 A 레코드 주소나 SRV 레코드를 갖고 있으면 로드 밸런서는 필요 없지 않나요?"라는 궁금증이 생길 수 있습니다. 로드 밸런서를 사용하는 이유는 부하분산을 위한 여러 대체 알고리즘을 사용할 수 있고 DNS 서버의 부하도 분산할 수 있기 때문입니다. UDP는 DNS, NTP, QUIC, HTTP/3, VoIP처럼 네트워크 기반 시스템에서 사용하는 많은 서비스의 근간입니다.  

UDP 부하분산은 TCP와 마찬가지로 stream 모듈을 통해 설정하며 그 방법도 매우 비슷합니다. 가장 큰 차이점은 listen 지시자를 통해 UDP 데이터그램(datagram)을 처리할 소켓을 지정한다는 점입니다. 데이터그램을 다룰 때는 TCP 부하분산에서 사용하지 않는 지시자를 몇 가지 사용합니다. 대표적으로 엔진엑스가 업스트림 서버로부터 수신할 것으로 예상되는 응답의 크기를 지정하는 데 proxy_timeout 지시자의 제한값이 되기 전까지 무제한으로 응답을 처리합니다. proxy_timeout은 연결을 닫기 전에 목적지 서버로의 읽기, 쓰기 작업 완료를 기다리는 시간을 지정하는 데 사용합니다.  

reuseport 매개변수는 엔진엑스가 워커 프로세스별로 개별 수신 소켓을 만들어 사용하도록 합니다. 커널은 엔진엑스로 보내야 하는 연결들을 워커 프로세스 단위로 분산하며, 따라서 클라이언트와 서버가 주고받는 여러 패킷을 동시에 처리할 수 있습니다. reuseport는 리눅스 커널 3.9 이상 버전과 드래건플라이 BSD(DragonFly BSD), 프리 BSD(Free BSD) 12 이상 버전에서만 사용할 수 있습니다.  

#### 2.4. 부하분산 알고리즘  
<br/>

+ 문제  
서로 다른 특성을 갖는 작업이나 사양이 다른 서버로 구성된 서버 풀로 인해 라운드 로빈(round robin) 방식의 부하분산이 적합하지 않은 상황  

엔진엑스가 제공하는 다른 부하분산 알고리즘은 사용합니다. 연결이 적은 서버를 먼저 활용하는 리스트 커넥션(least connection), 응답 속도가 빠른 서버를 우선 사용하는 리스트 타임(least time), 특정 문자열 기반 해시를 활용하는 제네릭 해시(generic hash), 임의 서버를 할당하는 랜덤(random), IP 주소 기반 해시를 사용하는 IP 해시(IP hash) 등이 있습니다. 다음 예시는 부하분산에 사용할 알고리즘으로 리스트 커넥션을 지정하기 위해 least_conn 지시자를 사용합니다.  

```
upstream backend {
    least_conn;
    server backend.example.com;
    server backend1.example.com;
}
```

제네릭 해시, 랜덤, 리스트 타임을 제외한 모든 부하분산 알고리즘은 리스트 커넥션 알고리즘과 마찬가지로 단독으로 사용합니다.  

모든 요청과 패킷의 가중치가 같지는 않습니다. 본 가중치가 들어간 라운드 로빈 방식조차도 모든 애플리케이션이나 트래픽 흐름에 적합하지는 않습니다. 엔진엑스는 특정 사례에 맞는 다양한 부하분삭 알고리즘을 제공합니다. 필요에 따라 알고리즘을 선택할 수 있을 뿐 아니라 알고리즘 동작의 세부 사항도 설정할 수 있습니다.  

+ 라운드 로빈  
기본값으로 설정된 부하분산 방법입니다. 업스트림 풀에 지정된 서버의 순서에 따라 요청을 분산합니다. 업스트림 서버의 가용량이 다양하다면 가중치를 적용한 라운드 로빈 방식도 설정할 수 있습니다. 가중치로 더 높은 정숫값이 지정된 서버는 더 많은 요청을 받습니다. 가중치는 단순히 가중치 평균의 통계적 확률에 따라 계산합니다.  

+ 리스트 커넥션  
엔진엑스와 연결 수가 가장 적은 업스트림 서버로 요청을 전달해 부하를 분산합니다. 라운드 로빈과 마찬가지로 가중치를 기반으로 요청을 어떤 서버로 보낼지 계산합니다. 리스트 커넥션 알고리즘 지시자는 least_conn입니다.  

+ 리스트 타임  
엔진엑스 플러스에서만 사용할 수 잇는 방법입니다. 리스트 커넥션과 마찬가지로 연결 수가 가장 적은 업스트림 서버로 요청을 전달하지만, 그중 응답 시간이 가중 빠른 서버를 우선시한다는 차이가 있습니다. 가장 복잡한 부하분산 알고리즘으로, 높은 성능이 필요한 웹 애플리케이션에 적합합니다. 업스트림 서버가 처리하는 요청 수가 적다고 해서 늘 가장 빠른 응답 시간을 보장하지는 않으므로, 이 알고리즘은 리스트 커넥션 방식에 대한 일종의 부가 기능으로 생각할 수 있습니다. 리스트 타임 알고리즘을 사용할 때는 요청 처리 시간의 분산(variance)응 고려해야 합니다. 애초부터 처리 시간이 긴 요청이 있다면 요청 처리 시간 통계의 범위가 넓어지며, 처리 시간이 길어도 항상 서버 성능이 낮거나 과부하가 걸린 것은 아닙니다. 따라서 많은 처리가 필요한 요청은 부하분산 알고리즘을 고민하기 전에 비동기로 처리하는 편이 나을 수 있습니다. 리스트 타임 알고리즘을 사용할 때는 header나 last_byte 매개변수 중 하나를 지정합니다. header를 지정하면 업스트림 서버로부터 응답 헤더를 받을 때까지 소요된 시간을 사용하고, last_byte를 지정하면 헤더뿐 아니라 응답 전체를 받을 때까지 소요된 시간을 사용합니다. 알고리즘 지시자는 least_time 입니다.  

+ 제네릭 해시  
서버 운영자는 주어진 텍스트 문자열 혹은 요청이나 런타임의 변수(혹은 둘 다)를 사용해 해시를 정의합니다. 엔진엑스는 수신한 요청의 해시를 생성하고 업스트림 서버 선택에 활용해 부하를 분산합니다. 제네릭 해시는 요청을 처리할 서버를 선택하는 데 깊이 개입해야 할 때나 캐시가 있을 확률이 높은 서버로 요청을 전달하고 싶을 때 무척 유용합니다. 다만 서버가 업스트림 풀에서 추가되거나 삭제되면 해시 처리된 요청이 재분배된다는 점을 주의합시다. consistent 옵션 매개변수를 사용하면 재분배의 영향을 최소화할 수 있습니다. 알고리즘 지시자는 hash입니다.  

+ 랜덤  
엔진엑스가 업스트림 풀에 지정된 서버를 임의로 선택해 요청을 전달하며 이때 업스트림 서버에 지정된 가중치를 고려합니다. 매개변수로 two [method]를 사용하면 먼저 서버 두 대를 임의로 선택하고 method에 지정된 알고리즘을 이용해 2차 부하분산을 합니다. method 값을 생략하면 기본 알고리즘은 least_conn으로 지정됩니다. 알고리즘 지시자는 random입니다.  

+ IP 해시  
HTTP에 대해서만 동작하는 방법으로, IP 주소를 이용해 해시를 생성합니다. 원격 변수를 사용하는 제네릭 해시와 달리 IPv4 주소 체계의 옥텟(octet)값 중 처음 세 값 혹은 IPv6 주소 전체를 해시에 사용합니다. 이 방식을 통해 사용자는 업스트림 서버에 문제가 없는 한 같은 서버로 할당됩니다. 이러한 동작 특성은 세션 상태가 중요하며, 이 정보가 애플리케이션의 공유 메모리를 통해 공유되지 않는 경우 유용합니다. 마찬가지로 weight 매개변수를 고려해 부하를 분산합니다. 알고리즘 지시자는 ip_hash입니다.  

#### 2.5. 스티키 쿠키(엔진엑스 플러스)  
<br/>

sticky cookie 지시자를 사용해 엔진엑스 플러스가 쿠키를 생성하고 추적하게 됩니다.  

```
upstream backend {
    server backend1.example.com;
    server backend2.example.com;
    sticky cookie
           affinity
           expires=1h
           domain=.example.com
           httponly
           secure path=/;
}
```

이 설정은 사용자가 지속적으로 특정 업스트림 서버에 연결되도록 쿠키를 생성해 추적합니다. 예시에서 생성하는 쿠키의 이름은 affinity이며 example.com 도메인에서 사용할 수 있습니다. 쿠키는 1시간 후에 만료되며 HTTPS를 통해서만 주고받을 수 있습니다. 사용자 브라우저에서 쿠키를 조작하지 못하도록 httponly를 지정하고 도메인의 모든 하위 경로에 대해 유효하도록 path 값을 지정합니다.  

sticky 지시자를 cookie 매개변수와 함께 사용하면 사용자의 첫 번째 요청 수신 시 업스트림 서버 정보를 포함하는 쿠키를 생성합니다. 엔진엑스 플러스는 쿠키를 추적해 이어지는 사용자 요청을 같은 서버로 전달합니다. cookie 매개변수의 첫 번째 항목은 쿠키 이름입니다. 다른 항목들은 쿠키에 대한 추가 제어 항목으로 만료 시간(expires), 도메인(domain), 경로(path), 사용자 측의 쿠키 사용 제한(secure)과 쿠키 전송을 위한 프로토콜(httponly)을 지정함으로써 쿠키 사용에 대한 정보를 브라우저에 제공합니다.  

#### 2.6. 스트키 런(엔진엑스 플러스)  
<br/>

sticky learn 지시자로 업스트림 애플리케이션이 생성한 쿠키를 찾아내어 추적합니다.  

```
upstream backend {
    server backend1.example.com:8080;
    server backend2.example.com:8081;

    sticky learn
           create=$upstream_cookie_cookiename
           lookup=$cookie_cookiename
           zone=client_sessions:2m;
}
```

업스트림 서버의 응답 헤더 중 Set-Cookie 헤더에서 이름이 cookiename인 쿠키를 찾아 추적합니다. 이 값은 엔진엑스에 저장되고 사용자 요청 헤더에서 쿠키 이름이 같은 값이 확인되면 해당 세션을 가진 업스트림 서버로 요청을 전달합니다. 이러한 세션 고정(session affinity) 값은 2MB 용량으로 생성된 공유 메모리 영역(shared memory zone)에 저장되며 여기에는 대략 1만 6000개의 세션 정보를 저장할 수 있습니다. 세션 정보를 담고 있는 쿠키의 이름은 애플리케이션과 개발 환경에 따라 다릅니다. 예를 들어, 자바 애플리케이션에서는 기본 세션 쿠키 이름이 jsessionid이고 PHP 애플리케이션에서는 phpsessionid입니다.  

애플리케이션이 세션 상태를 위한 쿠키를 별도로 사용하고 있다면 엔진엑스 플러스는 쿠키를 따로 생성하지 않고 요청이나 응답에 포함된 쿠키 이름과 값을 찾아 추적할 수 있습니다. 이러한 방식을 사용하려면 sticky 지시자에 learn 매개변수를 지정합니다. 각 매개변수에서 사용하는 변수들은 http 모듈에서 제공하는 내장 변수입니다.  

+ zone 매개변수
쿠키 추적을 위한 공유 메모리 영역을 정의하고 이름과 크기를 지정  

+ create 매개변수  
업스트림 서버의 응답 헤더에서 찾을 쿠키 이름을 지정  

+ lookup 매개변수  
지정한 사용자 쿠키 이름으로 이전에 저장해둔 세션값이 있는지 확인  

엔진엑스는 여러 가지 내장 변수를 제공합니다. 업스트림 서버의 정보를 담는 내장 변수는 $upstream_을 접두어로 가지며 특히 Set-cookie 헤더값의 정보는 $upstream_cookie_로 시작하는 변수명을 갖습니다. 한편 $cookie_로 시작하는 내장 변수는 사용자 요청의 쿠키 헤더값입니다. http://nginx.org/en/docs/http/ngx_http_upstream_module.html#variables와 http://nginx.org/en/docs/http/ngx_http_core_module.html#variables를 참고하기 바랍니다.  

#### 2.7. 스티키 라우팅(엔진엑스 플러스)  
<br/>

+ 문제  
엔진엑스 플러스 환경에서 영구 세션(persistent session)을 세부적으로 제어해 업스트림 서버로 전달하기  

sticky 지시자를 route 매개변수와 함께 사용합니다.이때 사용자 요청을 특정 업스트림 서버로 보내려면 경로에 대한 매핑 정보를 포함하는 변수를 사용합니다.  

```
map $cookie_jsessionid $route_cookie {
    ~.+\.(?P<route>\w+)$ $route;
}

map $request_uri $route_uri {
    ~jsessionid=.+\.(?P<route>\w+)$ $route;
}

upstream backend {
    server backend1.example.com route=a;
    server backend2.example.com route=b; 

    sticky route $route_cookie $route_uri;
}
```

예시는 업스트림 서버가 자바 애플리케이션일 대 세션 Id 값을 추출하고, 이 값을 이용해 특정 업스트림 서버로 요청을 전달합니다. 첫 번째 map 블록은 사용자 요청 쿠키에서 jsessionid 값을 추출해 $route_cookie 변수에 할당합니다. 두 번째 map 블록은 URI에 jsessionid 값이 있으면 값을 $route_uri 변수에 할당합니다. route 매개변수와 함께 사용된 sticky 지시자는 변수 여러 개를 인수로 사용할 수 있습니다. 변수들 중 0이 아닌 값이나 비어 있지 않은 값이 먼저 사용됩니다. 쿠키에서 jsessionid 값을 추출했다면 $route_cookie 변숫값이 존재하므로 backend1 서버로 요청을 보냅니다. 만약 URI에서 값이 발견됐다면 backend2 서버로 요청을 보냅니다. 예시에서는 자바의 일반적인 세션 ID를 다루지만 PHP의 phpsessionid나 다른 방법으로 생성된 고유한 세션 ID에도 같은 방법을 적용합니다.  

때때로 더 정교하게 트래픽을 특정 서버로 보내야 하는 상황이 있습니다. 이를 위해 sticky 지시자와 route 매개변수가 만들어졌습니다. 해시 기반으로 부하를 분산하는 일반적인 방법과 달리 스티키 라우팅(sticky routing)은 더 정교하고 추적이 가능하며 고정된 서버로 요청을 보낼 수 있습니다. 클라이언트가 보낸 최초 요청은 엔진엑스 설정에 지정된 규칙에 따라 업스트림 서버로 전달됩니다. 업스트림 서버는 쿠키나 URI에 세션 정보를 내려주고, 이어지는 요청은 쿠키나 URI에 저장된 경로 정보를 활용해 특정 서버로 전달됩니다. 스티키 라우팅은 업스트림 서버 결정에 사용하기 위해 평가한 여러 개의 매개변수를 사용합니다. 요청을 서버로 라우팅할 때는 매개변수 중 비어 있지 않은 첫 번째 값이 사용됩니다. map 블록은 변수를 파싱으로 sticky route 지시자는 다양한 방식으로 생성되는 업스트림 서버의 세션 정보를 추적하기 위해 엔진엑스 플러스의 공유 메모리 영역에 별도로 세션 정보를 저장합니다. 세션 정보는 사용자 요청을 지속적으로 같은 업스트림 서버로 전달하는 데 사용됩니다.  

#### 2.8. 커넥션 드레이닝(엔진엑스 플러스)  
<br/>

+ 문제  
서버 유지보수가 필요하거나 서버를 종료해야 하는 상황에서 활성 사용자 세션이 남아 있는 엔진엑스 서버를 점직적으로 서비스에서 제외하기  

엔진엑스 플러스 API로 drain 매개변수를 보내 엔진엑스가 추적 중이 아닌 새로운 연결을 더는 업스트림 서버로 보내지 않도록 설정합니다.  

```
curl -X POST -d '{"drain":true}' 'http://nginx.local/api/3/http/upstreams/backend/servers/0'
```

세션 상태가 각 서버의 로컬에 저장되는 경우, 서버가 서비스에서 제외되기 전에 모든 연결과 세션이 비워져야 합니다. 서버에서 연결을 비우는 것은 서버가 각 세션의 사용이 끝나면 자연스럽게 연결을 파기하도록 하는 절차입니다. 이 동작은 예시와 같이 API를 이용해 특정 서버로 drain 매개변숫값을 전달함으로써 동적으로 설정할 수 있습니다. drain 매개변수가 설정되면 엔진엑스 플러스는 해당 서버에서 더는 새로운 세션을 만들지 않습니다. 다만 이미 연결돼 있는 세션은 유효 기간 동안 유지됩니다. 보통 API를 이용해 제어하지만 엔진엑스 설정의 server 지시자에 drain 매개변수를 넣은 후 엔진엑스 플러스 설정을 리로드해서 제어할 수도 있습니다.  

#### 2.9. 수동적인 헬스 체크  
<br/>

동작에 문자가 없는 업스트림 서버만 사용하려면 엔진엑스 부하분산 설정에 헬스 체크(health check) 매개변수를 추가합니다.  

```
upstream backend {
    server backend1.example.com:1234 max_fails=3 fail_timeout=3s;
    server backend2.example.com:1234 max_fails=3 fail_timeout=3s;
}
```

이 설정은 사용자 요청에 대한 업스트림 서버의 응답을 모니터링해 업스트림 서버의 상태를 수동(사용자 요청이 들어오기 전에 선제적으로 상태 확인을 하지 않음)으로 확인합니다. max_fails 매개변수는 헬스 체크의 최대 실패 횟수이며 예시 설정에서는 3회로 지정하고, fail_timeout은 실패에 대한 타임아웃 값이며 3초로 지정합니다. 이 매개변수들은 stream과 HTTP 서버에서 같은 방식으로 동작합니다.  

수동적인 헬스 체크는 오픈 소스 엔진엑스에서 사용 가능하며 HTTP, TCP, UDP 부하분산 구성의 server 지시자에 설정합니다. 수동적인 모니터링은 클라이언트의 요청이 엔진엑스를 경유해 업스트림 서버로 보내진 후 타임아웃이나 요청 실패가 발생하는지 확인합니다. 수동적인 헬스 체크는 기본으로 활성화대 있으며 본문에서 언급한 매개변숫값들로 동작을 조정합니다. max_fails 매개변수의 기본값은 1회이고 fail_timeout의 기본값은 10초입니다. 부하분산에서 업스트림 서버의 상태를 모니터링하는 작업은 사용자 및 비즈니스 연속성 관점에서 중요하므로 엔진엑스는 수동적인 모니터링으로 업스트림 서버가 원활하게 동작하는지 확인합니다.  

+ HTTP 헬스 체크 설정하기: https://oreil.ly/9xsNp
+ TCP 헬스 체크 설정하기: https://oreil.ly/_2MKS_
+ UDP 헬스 체크 설정하기: https://oreil.ly/kEYQN  

#### 2.10. 능동적인 헬스 체크(엔진엑스 플러스)  
<br/>

http 모듈을 사용하는 경우 location 블록에 health_check 지시자를 사용해 능동적으로 상태를 확인합니다.  

```
http {
    server {
        # ...
        location / {
            proxy_pass http://backend;
            health_check interval=2s
                         fails=2
                         passes=5
                         uri=/
                         match=welcome;
        }
    }
    # 응답 코드가 200이고 Content-Type이 "text/html"이면서
    # 응답 바디에 "Welcome to nginx!" 문자열이 있는지 확인합니다.
    match welcome {
        status 200;
        header Content-Type=text/html;
        body ~ "Welcome to nginx!";
    }
}
```

이 설정은 업스트림 서버의 최상위(/) 경로로 2초마다 HTTP GET 요청을 보내 서버 상태를 확인합니다. 헬스 체크 설정은 HTTP 메서드 중 GET만 사용할 수 있는데, 이는 HTTP 메서드가 백엔드(backend) 서버 상태를 바꿔 헬스 체크 결과가 변하는 것을 방지하기 위함입니다. 업스트림 서버는 헬스 체크에 대해 5회 연속 정상적으로 응답하면 상태가 양호하다고 간주됩니다. 헬스 체크가 2회 연속 실패하면 해당 업스트림 서버는 문제가 있다고 판단되며 업스트림 풀에서 제외됩니다. 업스트림 서버는 match 블록에 지정한 것과 같이 HTTP 응답 코드(status)가 200이고 콘텐츠 타입(Content-Type) 헤더값이 text/html이면서 응답 바디(body) 값이 "Welcome to nginx!"이면 정상으로 간주됩니다. 예시와 같이 match 블록은 status, header, body 지시자로 구성되며 지시자들은 비교 플래그를 제공합니다. TCP/UDP 프로토콜을 사용하는 stream 모듈의 헬스 체크도 매우 비슷합니다.  

```
stream {
    # ...
    server {
        listen 1234;
        proxy_pass stream_backend;
        health_check interval=10s
                     passes= 2
                     fails= 3;
        health_check_timeout 5s;
    }
    # ...
}
```

예시에서 TCP 서버는 1234 포트로 들어오는 요청을 수신하며, 능동적으로 헬스 체크를 하는 업스트림 서버로 요청을 전달합니다. stream 모듈의 health_check 지시자는 http 모듈에서 헬스 체크 구성 시 사용했던 매개변수를 대부분 사용할 수 있지만 uri 매개변수는 사용하지 않습니다. 대신 udp 매개변수를 사용해 헬스 체크 프로토콜을 변경합니다. 예시의 health_check 지시자는 10초 간격(interval)으로 헬스 체크를 수행하며 시험이 2회 연속 성공(passes)하면 업스트림 서버를 정상으로 판단하고 3회 연속 실패(fails)하면 비정상으로 판단하도록 설정합니다. stream 모듈에서 헬스 체크를 수행할 때도 match 블록을 사용할 수 있지만 send와 expect라는 두 가지 지시자만 제공됩니다.  

+ send 지시자  
업스트림 서버로 보낼 원시 데이터(raw data) 확인에 사용

+ expect 지시자  
서버의 응답과 비교할 값이나 정규 표현식(regular expression)에 사용  

엔진엑스 플러스는 수동적인 헬스 체크와 능동적인 헬스 체크를 지원하며, 두 가지 모두 업스트림 서버의 응답 코드를 확인하는 것 이상의 상태 확인 동작을 수행합니다. http 모듈에 대한 능동적인 헬스 체크는 업스트림 서버의 여러 응답값이 허용 기준이 맞는지 모니터링합니다. 업스트림 서버를 얼마나 자주 시험할지, 허용 기준에 맞는 응답이 몇 번 전달되면 서버가 정상이라고 판단할지, 몇 번 실패하면 서버가 비정상이라고 판단할지를 지정할 수 있으며 정상 상태에 대한 응답 또한 정의할 수 있습니다. 더 복잡한 조건으로 상태를 확인하려면 match 블록의 require 지시자로 변수가 빈 값이나 0이 아닌지 확인합니다. health_check 지시자의 match 매개변수는 응답 허용 기준을 정의한 match 블록을 가리킵니다. TCP/UDP 프로토콜을 사용하는 stream 모듈에서는 헬스 체크 요청 시 업스트림 서버로 보낼 데이터를 match 블록을 통해 정의하기도 합니다. 이러한 기능으로 엔진엑스는 업스트림 서버가 항상 정상 상태임을 확인합니다.  

+ HTTP 헬스 체크 설정하기: https://oreil.ly/9xsNp
+ TCP 헬스 체크 설정하기: https://oreil.ly/_2MKS_
+ UDP 헬스 체크 설정하기: https://oreil.ly/kEYQN  

#### 2.11. 슬로 스타트(엔진엑스 플러스)  
<br/>

+ 문제  
운영 환경에서 실사용자 트래픽을 받기 전에 애플리케이션의 예열(ramp up)이 필요한 상황  

애플리케이션의 성격과 동작 방식에 따라 실행 초기에 많은 요청을 한 번에 수용하기 힘든 경우가 있습니다. 대표적인 예로 캐시(cache) 기능이 있는 애플리케이션은 조금씩 캐시를 채우면서 트래픽을 수용해야 합니다.  

server 지시자에 slow_start 매개변수를 사용해 점진적으로 사용자 연결을 늘려나갈 시간 범위를 지정하고 업스트림 서버 부하분산 풀(load balancing pool)에 각 서버가 투입되도록 합니다.  

```
upstream {
    zone backend 64k;

    server server1.example.com slow_start=20s;
    server server2.example.com slow_start=15s;
}
```

server 지시자의 설정에 따라 서버가 다시 풀에 투입된 후 천천히 전달되는 트래픽을 늘려갑니다. server1은 20초, server2는 15초에 걸쳐 연결 수를 천천히 늘려갑니다.  

슬로 스타트(slow start)는 지정된 시간 동안 업스트림 서버로 전달하는 요청의 수를 점진적으로 늘려나가는 개념입니다. 서버 시작 직후에 연결 폭주 없이 데이터베이스 연결을 맺고 캐시를 쌓을 시간을 확보함으로써 애플리케이션은 서비스를 원활히 제공할 준비를 할 수 있습니다. 이 기능은 서버가 헬스 체크 실패로 풀에서 제외된 후 다시 정상화되어 풀에 투입되는 시점에 유용합니다. 단, 엔진엑스 플러스에서만 제공되며, hash, ip_hash, random 부하분산 방식에서는 사용할 수 없습니다.  

### 3. 트래픽 관리  
<br/>

#### 3.0. 소개  
<br/>

엔진엑스와 엔진엑스 플러스는 웹 트래픽 컨트롤러로도 분류됩니다. 엔진엑스를 이용해 트래픽 경로를 결정하고 여러 속성값을 이용해 흐름을 제어할 수 있습니다.  

#### 3.1. A/B 테스트  
<br/>

split_clients 모듈을 사용해 사용자 요청을 지정된 비율에 따라 서로 다른 업스트림 풀로 전달합니다.  

```
split_clients "${remote_addr}AAA" $variant {
    20.0%   "backend2";
    *       "backend1";
}
```

split_clients 지시자는 첫 번째 매개변수에 지정된 문자열을 활용해 해시를 생성하고, 지정된 비율에 따라 두 번째 매개변수에 지정된 변수에 값을 할당합니다. 큰따옴표로 묶인 첫 번째 매개변수에 보이는 문자열 AAA는 비율 분기 시 사용하는 해시를 생성할 때도 제네릭 해시 알고리즘과 마찬가지로 여러 변수와 문자열을 조합할 수 있음을 보여줍니다. 세 번째 매개변수는 키-값(key-value) 조합으로 구성된 객체로, 키는 분기 비율이고 값은 큰따옴표로 묶인 문자열입니다. 분기 비율은 숫자로 표기된 비율이나 별표(asterisk)로 지정합니다. 일반적인 경우처럼 별표는 비율로 지정되지 않은 나머지 전체를 의미합니다. 두 번째 매개변수인 $variant는 세 번째 매개변수에 지정된 분기 비율에 따라 특정 값을 저장합니다. 즉, 예시의 $variant 변수는 요청의 20%에 대해 backendv2가 할당되고 나머지 80%에 대해 backendv1이 할당됩니다.  

예시에서 backendv1과 backendv2는 proxy_pass 지시자 등에서 사용할 수 있는 업스트림 서버 풀을 나타냅니다.  

```
location / {
    proxy_pass http://$variant
}
```

엔진엑스로 수신된 트래픽은 $variant 변수를 사용해 두 개의 애플리케이션 서버 풀로 분기됩니다.  

+ 카나리 배포(canary release)  
새로운 기능이나 변경 사항을 모든 서비스에 한 번에 적용하지 않고 일부 서버에만 적용해서 실서비스 환경의 트래픽을 이용해 문제가 있는지 확인하는 배포 방식  

이러한 A/B 테스트는 전자 상거래 사이트에서 여러 가지 마케팅이나 프런트엔드 기능의 전환율(conversion rate)을 즉정하는 데 유용합니다. 애플리케이션을 배포할 때는 카나리 배포(canary release)가 널리 사용됩니다. 카나리 배포 방식은 새로운 버전의 애플리케이션으로 사용자 요청이 전달되는 비율을 조금씩 늘려가면서 트래픽이 천천히 새 버전으로 전환되도록 합니다. 애플리케이션의 서로 다른 버전을 사용하도록 사용자를 나누면 새로운 버전 전개 시 오류 상황이 급격히 번지는 것을 막을 수 있어 매우 유용합니다. 카나리 배포보다 더 일반적으로는 블루-그린 배포 방식(blue-green deployment style)이 사용됩니다. 블루-그린 방식은 모든 사용자가 한 번에 새로운 애플리케이션을 사용하도록 분기하되 새 버전에 문제가 없다고 확인될 때까지 기존 버전을 유지합니다. 분기 목적이 무엇이든 엔진엑스는 split_clients 모듈을 통해 간단히 분기처리를 합니다.  

+ split_clients 모듈 공식 문서: https://oreil.ly/Fn61k  

#### 3.2. GeoIP 모듈과 데이터베이스 활용하기  
<br/>

+ 문제  
GeoIP 데이터베이스를 설치하고 엔진엑스의 관련 내장 변수(embedded variable)를 활성화해 엔진엑스가 로그, 요청 프록시, 요청 분기 등을 수행할 때 사용자 위치를 확인하도록 하기  

엔진엑스 공식 오픈 소스 패키지 저장소는 nginx-module-geoip라는 모듈을 제공합니다. 엔진엑스 플러스 패키지 저장소를 이용하고 있다면 nginx-plus-module-geoip라는 이름으로 패키지를 찾을 수 있습니다.  

GeoIP 모듈을 설치했으면 맥스마인드(Maxmind)에서 제공하는 GeoIP 국가 및 도시 데이터베이스를 다운로드합니다.  

엔진엑스에서 GeoLite2 데이터베이스를 사용하려면 약간의 데이터 가공이 필요합니다. 쉬운 가공을 위해 CSV 포맷의 국가 및 도시 데이터베이스 zip 파일을 다운로드하기 바랍니다.  

맥스마인드에서 제공하는 GeoIP 국가 및 도시 데이터베이스를 geoip_country 지시자의 geoip_city 지시자를 통해 사용하기 위해 데이터를 가공합시다. 다행히 파이썬 기반의 맥스마인드 데이터 변환 스크립트가 공개돼 있습니다. 깃허브 저장소에서 저장소 주소를 복사해 로컬 환경에 복제(clone)하기 바랍니다.  

```sh
mkdir /etc/nginx/geoip
cd /etc/nginx/geoip

git clone https://github.com/sherpya/geolite2legacy.git
cd geolite2legacy

python3 geolite2legacy.py -i <파일다운로드경로>/GeoLite2-Country-CSV_20220802.zip -f geoname2fips.csv -o GeoIP.dat
python3 geolite2legacy.py -i <파일다운로드경로>/GeoLite2-City-CSV_20220802.zip -f geoname2fips.csv -o GeoLiteCity.dat
```

명령을 순차적으로 실행하면 /etc/nginx/geoip 경로를 생성하고 해당 디렉터리로 이동한 뒤 다운로드한 CSV 형식의 압축된 데이터베이스 파일을 엔진엑스 GeoIP 모듈이 사용할 수 있는 형식으로 변환합니다. 참고로, 다운로드한 zip 파일 이름 뒷부분에는 다운로드 시점의 날짜가 yyyymmdd 형식으로 붙어 있습니다.  

엔진엑스의 GeoIP 모듈은 로컬 디스크에 저장된 GeoIP 국가 및 도시 데이터베이스를 이용해 사용자 IP 주소에 대한 위치 정보를 내장 변수로 사용합니다.  

```
load module "/usr/lib64/nginx/modules/ngx_http_geoip_module.so";

http {
    geoip_country /etc/nginx/geoip/GeoIP.dat;
    geoip_city /etc/nginx/geoip/GeoLiteCity.dat;
    # ...
}
```

load_module 지시자는 파일시스템의 지정된 경로에서 모듈을 동적으로 읽어옵니다. 이 지시자는 반드시 엔진엑스의 공통 설정 부분에서 사용해야 합니다. geoip_country 지시자는 IP와 국가 코드 정보가 담긴 GeoIP.dat 파일의 경로를 매개변수로 전달받으며 http 컨텍스트 내에서만 유효합니다.  

사용자 위치 확인 기능을 사용하려면 엔진엑스 GeoIP 모듈을 설치하고 엔진엑스 서버의 로컬 디스크에 GeoIP 국가 및 도시 데이터베이스를 설치합니다.  

geoip_country와 geoip_city 지시자는 GeoIP 모듈에서 사용 가능한 여러 내장 변수를 쓸 수 있게 해줍니다. geoip_country 지시자는 사용자가 어느 국가에서 접근하는지 식별하는 변수($geoip_country_code, $geoip_country_code3, $geoip_country_name)를 제공합니다. $geoip_country_code 변수 두 개 중 첫 번째는 두 자리 문자로 구성된 국가 코드를 제공하며, 3으로 끝나는 변수는 세 자리 문자로 구성된 국가 코드를 제공합니다. geoip_country_name 변수는 각 국가의 전체 이름(fullname)을 제공합니다.  

geoip_city 지시자도 여러 내장 변수를 활성화합니다. geoip_city 지시자는 geoip_country 지시자가 제공하는 것과 동일한 변수를 제공하며 변수명만 조금 다릅니다($geoip_city_country_code, $geoip_city_country_code3, $geoip_city_country_name), 그 외에도 내장 변수 $geoip_city, $geoip_latitude, $geoip_longitude, $geoip_city_continent_code, $geoip_postal_code 등이 제공되며 각 변수가 제공하는 정보는 이름으로 쉽게 추측할 수 있습니다. $geoip_region과 geoip_region_name은 지역(region)과 행정구역(territory), 주(state)(일부 국가 한정)나 도(province), 연방토지(federal land)(미국 한정)와 같은 세부 정보를 제공합니다.  

$geoip_region은 두 글자로 구성된 구성된 영문 코드이며 $geoip_region_name은 지역의 전체 이름을 영문으로 제공합니다. $geoip_area_code는 미국 내에서만 의미 있는 값으로 세 자리의 지역 전화번호 코드를 담고 있습니다.  

이러한 변수들을 활용해 사용자 위치 정보를 로그에 남깁니다. 정보는 헤더나 변수 등을 통해 업스트림 서버의 애플리케이션에 전송할 수 있으며 엔진엑스에서 요청을 분기하는 구성을 만들 때도 활용할 수 있습니다.  

+ 엔진엑스 geoip 모듈 공식 문서: https://oreil.ly/zleE0
+ 맥스마인드에서 제공하는 GeoIP 데이터베이스: https://oreil.ly/rJp_a  

#### 3.3. 국가 단위 접근 차단하기  
<br/>

map 지시자를 사용해 접근을 차단하거나 허용할 국가 코드를 변수에 할당합니다.  

```
load_module "/usr/lib64/nginx/modules/ngx_http_module.so";

http {
    map $geoip_country_code $country_access {
        "US"    0;
        default 1;
    }
    # ...
}
```

예시의 map 지시자는 $country_access 변수에 1이나 0을 할당합니다. 사용자 IP 주소의 위치 정보가 미국(US)이면 변수에 0을 할당합니다. 그 외의 국가이면 기본값인 1로 설정됩니다.  

이제 server 블록에서 if 문을 사용해 미국에서 온 요청이 아니면 차단합니다.  

```
server {
    if ($country_access = '1') {
        return 403;
    }
    # ...
}
```

예시는 널리 사용되는 개발 언어의 if 문과 마찬가지로 $country_access 값이 1인지 확인해 참(true)과 거짓(false)을 판별합니다. 비교 결과가 참이면 차단 대상 요청이므로 엔진엑스는 '403 Forbidden' 응답을 반환하고 결과가 거짓이면 이후 설정 내용에 따라 동작합니다. 이와 같이 if 문을 사용해 미국에서 접근하는 사용자가 아니면 리소스에 대한 접근을 차단할 수 있습니다.  

#### 3.4. 실제 사용자 IP 찾기  
<br/>

geoip_proxy 지시자로 프록시 서버 IP 대역을 정의하고 geoip_proxy_recursive 지시자로 사용자의 원래 IP 주소를 확인합니다.  

```
load_module "/usr/lib64/nginx/modules/ngx_http_geoip_module.so";

http {
    geoip_country /etc/nginx/geoip/GeoIP.dat;
    geoip_city /etc/nginx/geoip/GeoLiteCity.dat;
    geoip_proxy 10.0.16.0/26;
    geoip_proxy_recursive on;
    # ...
}
```

geoip_proxy 지시자에 사이더(classless inter-domain routing, CIDR) 표기법으로 프록시 서버의 IP 대역을 지정하고 엔진엑스가 X-Forwarded-For 헤더값을 활용해 실제 사용자 IP를 찾도록 합니다. geoip_proxy_recursive 지시자를 사용하면 엔진엑스는 X-Forwarded-For 헤더값을 순차적으로 탐색해 최종 사용자의 IP를 확인합니다.  

+ X-Forwarded-For 헤더  
프록시 서버를 경유할 때마다 서버의 IP 주소 정보를 쉼표로 구분해 연결해나갑니다.  

프록시는 프록시를 경유해 전달되는 사용자 요청에 Forwarded 표준 헤더를 추가합니다. 그러나 엔진엑스 GeoIP 모듈은 표준 헤더가 아닌 X-Forwarded-For를 사용하며 고정된 값입니다.  

엔진엑스 앞단에 프록시 서버를 운용한다면 엔진엑스가 식별하는 사용자 IP는 실제 사용자가 아닌 프록시 서버의 IP입니다. geoip_proxy 지시자를 사용해 특정 IP 대역에서 들어오는 요청에 대해 X-Forwarded-For 헤더값을 참조하도록 할 수 있습니다. geoip_proxy 지시자는 단일 IP 주소나 CIDR 표기법을 사용한 IP 주소 대역을 사용합니다. 요청이 여러 프록시를 경유해 들어오면 geoip_proxy_recursive 지시자를 사용해 X-Forwarded-For 헤더에 기록된 각 프록시 주소를 탐색해 실제 사용자 IP를 찾을 수 있습니다. 엔진엑스 앞단에 AWS 일래스틱 로드 밸런서(Amazon Web Services - Elastic Load Balancer, AWS ELB)나 구글 클라우드 플랫폼(Google Cloud Platform, GCP)의 로드 밸런서 또는 마이크로소프트 애저(Microsoft Azure)의 로드 밸런서를 사용할 때도 이러한 방식으로 실제 사용자 IP를 확인합니다.  

#### 3.5. 연결 제한하기  
<br/>

연결에 대한 지표를 저장할 공유 메모리 영역을 만들고 limit_conn 지시자를 사용해 연결 수를 제한합니다.  

```
http {
    limit_conn_zone $binary_remote_addr zone=limitbyaddr:10m;
    limit_conn_status 429;
    # ...
    server {
        # ...
        limit_conn limitbyaddr 40;
        # ...
    }
}
```

이 설정은 limitbyaddr라는 공유 메모리 영역을 생성합니다. 사전에 정의된 키는 바이너리 형태로 변환된 사용자의 IP 주소입니다. 공유 메모리 영역의 크기는 10메가바이트로 설정합니다. limit_conn 지시자는 limit_conn_zone 지시자로 선언한 공간 이름과 허용 연결 수를 매개변수로 받습니다. limit_conn_status 지시자는 지정된 연결 수를 초과하면 사용자에게 전달할 HTTP 상태 코드를 지정하며 예시에서는 요청이 너무 많음을 의미하는 HTTP의 429 상태 코드를 사용합니다. limit_conn과 limit_conn_status 지시자는 http.server.location 컨텍스트에서 사용할 수 있습니다.  

지정된 키 기반으로 연결 수를 제한하면 악의적인 사용자를 막을 수 있으며 모든 사용자가 서버 리소스를 공평하게 사용할 수 있습니다. 따라서 어떤 키로 연결 수를 제한할지 신중히 결정해야 합니다. 앞선 예시처럼 IP 주소를 사용해 접근을 제한하는 방식은 네트워크 주소 변환(network address translation, NAT) 장비 뒤에 구성된 네트워크에서 접근하는 사용자가 많으면 매우 위험할 수 있습니다. 자칫 잘못 설정하면 해당 네트워크 전체 사용자의 접근이 제한됩니다. limit_conn_zone 지시자는 http 컨텍스트 내에서만 사용 가능합니다. 연결 수 제한 조건에 사용할 문자열을 만드는 데는 http 컨텍스트 내 여러 변수를 조합해 사용할 수 있습니다. 애플리케이션 레벨에서 사용자를 식별하기 위해 세션 쿠키값과 같은 변수를 사용할 수 있으며, 이는 비즈니스 요구사항에 따라 명확한 해결 방법이 되기도 합니다. limit_conn_status 지시자는 서비스 불능(service unavailable)을 의미하는 503을 기본 응답 코드로 사용합니다. HTTP에서 400번대 응답 코드는 사용자 측 오류를, 500번대 응답 코드는 서버 오류를 의미합니다. HTTP에서 400번대 응답 코드는 사용자 측 오류를, 500번대 응답 코드는 서버 오류를 의미합니다. 그러므로 503보다는 429와 같은 응답 코드는 사용하는 편이 나을 수 있습니다.  

이렇게 설정한 연결 수 제한은 시험하기가 쉽지 않습니다. 시험을 위해 별도로 구성한 환경에서는 실제 트래픽을 재현하기가 어렵기 때문입니다. 이때 limit_req_dry_run 지시자를 on으로 설정하고 접근 로그에 기록하는 항목으로 $limit_req_status 변수를 사용함으로써 실제 서비스 환경에서 어떤 형태의 연결 수 제한이 발생할지 가늠해볼 수 있습니다. $limit_req_status 변숫값은 PASSED, DELAYED, REJECTED, DELAYED_DRY_RUN, REJECTED_DRY_RUN이 될 수 있습니다. 모의 시험(dry run)을 활성화해 실제 사용자 트래픽에 제한이 적용되는 상황을 가늠해보고, 서비스 적용 전에 제한 설정이 적절한 값으로 구성됐는지 확인합니다.  

#### 3.6. 요청 빈도 제한하기  
<br/>

빈도 제한 모듈을 활용해 요청 빈도를 제한합니다.  

```
http {
    limit_req_zone $binary_remote_addr zone=limitbyaddr:10m rate=3r/s;
    limit_req_status 429;
    # ...
    server {
        # ...
        limit_req zone=limitbyaddr;
        # ...
    }
}
```

limitbyaddr라는 이름으로 공유 메모리 영역을 생성합니다. 또한 사용자 IP 주소를 바이너리 형태로 변환해 사전에 정의된 키로 활용합니다. 공유 메모리 영역은 정의된 키를 사용해 빈도를 설정하며 limit_req 지시자는 zone 매개변수를 통해 키를 전달받습니다. 다시 말하면 zone 매개변수는 어떤 공유 메모리 영역을 참고해 요청 빈도를 제한할지 결정합니다. 지정된 빈도를 초과하는 요청은 limit_req_status 지시자에 지정된 429 응답 코드를 받습니다. limit_req_status 지시자로 별도 응답 코드를 지정하지 않았으면 기본값인 503이 반환됩니다. 따라서 사용자 요청이 과도한 상황을 표현해줄 400번대 HTTP 응답 코드를 limit_req_status 지시자에 지정하는 편이 좋습니다.  

limit_req 지시자는 zone과 별개로 추가 매개변수를 사용하면 두 단계로 요청 빈도 제한을 수행할 수 있습니다.  

```
server {
    location / {
        limit_req zone=limitbyaddr burst=12 delay=9;
    }
}
```

간혹 사용자 측에서 한 번에 많은 요청을 전송한 후 일정 시간 동안 요청 빈도를 줄이는 경우가 있습니다. 이 경우 burst 매개변수를 사용해 빈도가 지정된 값보다 낮으면 차단하지 않고 허용하도록 설정할 수 있습니다. delay 매개변숫값을 초과한 요청은 지정된 rate에 맞춰 지연 처리를 합니다. 이 동작은 delay 외에 nodelay로도 제어합니다. nodelay 매개변수는 특정 수치를 지정하지 않고 키워드만으로 사용하며, 임계치를 초과한 요청을 수신하면 빈도 제한 수치를 하회할 때까지 모든 요청에 지정된 오류 코드로 응답합니다. 예를 들어, 예시 설정에서 nodelay 매개변수를 사용했다면 사용자는 처음 1초간 요청 12개를 오류 없이 전송하지만 다음 요청을 보내면 4초간 대기해야 합니다(rate 매개변수가 3r/s로 지정돼 있으므로 요청 12개를 처리하는 데 4초가 필요합니다. 따라서 12개를 우선 처리하고 4초간 대기한 후 다음 요청을 처리합니다.). delay 매개변수는 지연을 적용하지 않고 처리할 수 있는 최대 요청 빈도를 지정합니다. 예시에서는 사용자가 요청을 초당 9개까지 지연 없이 전송할 수 있으며 초과 요청 3개는 쓰로틀링(throttling)돼 지연 처리가 됩니다. 마찬가지로 요청이 한 번에 12개 이상 들어오면 4초간 해당 사용자 요청은 거절됩니다.  

빈도 제한 모듈을 사용해 일반 사용자에게는 정상적인 서비스를 제공하면서 악의적으로 아주 많은 요청을 보내는 사용자의 접근을 제한할 수 있습니다. 요청 빈도를 제한하는 이유는 다양하며 보안 또한 중요한 목적입니다. 예를 들어, 로그인 페이지에 강력한 요청 빈도 제한을 적용해 브루트포스 공격(brute-force attack)을 차단하거나, 매우 엄격한 요청 빈도 제한으로 악의적인 사용자가 애플리케이션을 응답 불능 상태에 빠뜨리거나 서버 리소스를 고갈시키는 문제에 대응합니다. 빈도 제한 모듈 설정은 연결 수 제한과 매우 유사하며 같은 고민이 많이 녹아 있습니다. 요청을 초 단위로 제한할지 혹은 분 단위로 제한할지 결정할 수 있으며 빈도 제한에 도달하면 이력이 로그에 기록됩니다. 예시에는 적용되지 않았지만 limit_req_log_level 지시자는 빈도 제한 초과에 대한 로그 레벨을 결정합니다. 기본값은 오류(error)이지만 정보(info), 공지(notice), 혹은 경고(warn)로 변경해 로그를 얼마나 상세히 남길지 결정할 수 있습니다. 엔진엑스 플러스는 클러스터 단위로 빈도 제한을 설정할 수 있습니다.  

빈도 제한이 잘 적용되는지 시험하기는 쉽지 않습니다. 시험 환경에서 실제 트래픽을 재현하기는 매우 어렵습니다. 시험하려면 limit_req_dry_run 지시자를 on으로 설정하고 $limit_req_status 변숫값을 로그에 남깁니다. $limit_req_status 변숫값은 PASSED, REJECTED, REJECTED_DRY_RUN 중 하나가 됩니다. 모의 시험이 활성화돼 있다면 수집된 로그를 통해 실제 트래픽을 분석하고, 설정하려는 빈도 제한 수치가 적절한지 실제 서비스 환경 적용 전에 확인해볼 수 있습니다.  

#### 3.7. 전송 대역폭 제한하기  
<br/>

엔진엑스가 제공하는 limit_rate와 limit_rate_after 지시자를 사용해 사용자에 대한 응답 대역폭을 제한합니다.  

```
location /download/ {
    limit_rate_after 10m;
    limit_rate 1m;
}
```

이 location 블록을 설정함으로써 /download/ 경로로 시작하는 URI에 대해 누적 전송량이 10MB를 초과하면 초당 1MB를 넘지 않도록 제한합니다. 대역폭 제한은 개별 연결에 적용되는 설정이므로 연결 수와 함께 전송 대역폭을 제한할 필요가 있습니다.  

연결 단위로 전송 대역폭을 제한해 엔진엑스가 설정에서 지정한 대로 업로드 대역폭을 모든 사용자가 나눠 쓰게 할 수 있습니다. 대역폭을 제한하는 데는 limit_rate_after와 limit_rate 지시자를 사용합니다. 두 지시자 모두 http, server, location 컨텍스트와 location 블록 내부에 위치한 if 문 등 다양한 곳에서 사용할 수 있습니다. 지시자를 사용하지 않고 $limit_rate 변수로도 설정할 수 있음을 기억해둡시다.  

limit_rate_after 지시자는 특정 연결에서 지정된 양만큼 데이터가 전송되지 않았으면 대역폭이 제한되지 않도록 합니다. limit_rate 지시자는 초당 전송량을 매개변수로 사용하며, 사용된 모듈과 블록에 따라 지정된 수치에 맞춰 대역폭을 제한합니다. 두 지시자 모두 단위로 메가바이트(megabyte)를 뜻하는 m이나 기가바이트(gigabyte)를 뜻하는 g 등을 사용합니다. 기본값은 0이며 값을 설정하지 않으면 대역폭이나 누적 전송량 제한이 없습니다. 이 모듈을 사용해 프로그래밍적으로 사용자의 대역폭을 제한할 수 있습니다.  

### 4. 대규모 확장 가능한 콘텐츠 캐싱  
<br/>

#### 4.0. 소개  
<br/>

+ 캐싱(caching)  
미래에 다시 제공해야 하는 응답을 저장해뒀다가 빠르게 콘텐츠를 제공하는 방법  

+ 콘텐츠 캐싱  
업스트림 서버가 동일한 요청에 대해 계산이나 질의를 다시 수행하지 않도록 전체 응답을 저장함으로써 업스트림 서버의 부하를 감소  

캐싱을 통해 성능을 높이고 부하를 낯추면 더 적은 리소스로도 더 빠르게 콘텐츠를 제공할 수 있으며, 캐싱 서버를 전략적인 위치에 확대, 분산 배치해 사용자 경험을 개선할 수 있습니다. 사용자에게 최고의 성능을 보장하려면 콘텐츠가 사용자 가까이에서 제공돼야 합니다. 이를 위해 사용자 가까이에 있는 서버에 콘텐츠를 캐시할 수 있으머, 이는 콘텐츠 전송 네트워크(content delivery network, CDN) 사업자 사용하는 전략이기도 합니다. 엔진엑스를 사용하면 엔진엑스 서버가 배치된 모든 곳에 콘텐츠를 캐시할 수 있어 효과적으로 자신만의 CDN을 만들 수 있습니다. 엔진엑스 캐싱을 통해 수동적으로 콘텐츠를 캐싱할 뿐 아니라 업스트림 서버에 문제가 생기면 캐싱된 응답으로 사용자에게 콘텐츠를 제공할 수 있습니다. 다만 캐싱 기능은 http 컨텍스트 내에서만 사용할 수 있다는 점에 유의합시다.  

#### 4.1. 캐시 영역  
<br/>

proxy_cache_path 지시자를 사용해 공유 메모리 캐시 영역을 정의하고 콘텐츠 위치를 지정합니다.  

```
proxy_cache_path /var/nginx/cache
                 keys_zone=CACHE:60m
                 levels=1:2
                 inactive=3h
                 max_size=20g;
proxy_cache CACHE;
```

예시는 캐시 응답을 저장하기 위해 /var/nginx/cache 디렉터리를 생성하고 메모리에 CACHE라는 공유 메모리 영역을 60MB 크기로 생성합니다. 또한 디렉터리 구조의 레벨(level)을 지정하며 캐시 휘 3시간 동안 해당 응답에 대한 요청이 없으면 캐시를 비활성화합니다. max_size 매개변수는 캐시 영역의 크기가 20GB를 넘지 않도록 지정하고 proxy_cache 지시자는 어떤 캐시 영역을 사용할지 지정합니다. proxy_cache_path는 http 컨텍스트에서만 유효하며 proxy_cache 지시자는 http, server, location 컨텍스트에서 사용 가능합니다.  

엔진엑스에 캐싱을 설정하려면 캐시를 저장할 경로와 캐시 영역을 지정합니다. 캐시 영역은 proxy_cache_path 지시자를 통해 생성합니다. proxy_cache_path는 캐시 정보를 저장할 위치와 활성화된 캐시 키 및 응답에 대한 메타데이터 정보를 저장할 공유 메모리 영역을 지정합니다. 욥션 매개변수를 사용하면 캐시를 어떻게 관리하고 접근할지에 대한 추가 제어도 가능합니다. levels 매개변수는 캐시 파일을 저장할 디렉터리 구조를 어떻게 생성할지 정의합니다. 서브디렉터리 이름의 길이를 콜론으로 구분해 지정하며 최대 3단계의 서브디렉터리를 생성할 수 있습니다. 엔진엑스는 해시 형태의 캐시 키를 기반으로 콘텐츠를 캐시합니다. 그리고 levels에 정의된 디렉터리 구조를 생성하고 캐시 키를 파일 경로로 해서 결과를 저장합니다. 예시처럼 levels=1:2를 지정하면 /var/nginx/cache/c/29/b7f54b2df7773722d382f4809d65029c 같은 형태로 캐시가 저장됩니다. 첫 번째 서브디렉터리는 한 글자, 두 번째 서브디렉터리는 두 글자로 저장했으므로 /c/29/ 형태로 디렉터리 구조가 생성됩니다. inactive 매개변수는 마지막 요청 이후 오랫동안 요청되지 않더라도 캐시를 보관할 기간을 결정합니다. 저장 가능한 캐시의 총 용량은 max_size 매개변수로 설정합니다. 다른 매개변수들은 디스크에 저장된 캐시 파일의 캐시 키를 공유 메모리 영역으로 읽어들이는 cache-loading 프로세스와 관련됩니다.  

#### 4.2. 캐시 락  
<br/>

proxy_cache_lock 지시자는 동일한 리소스에 대한 요청이 여러 개 들어오면 한 번에 하나의 요청을 통해서만 캐시가 만들어지도록 합니다. 캐시가 만들어지는 동안 수신된 요청은 가장 먼저 도착한 요청으로 캐시가 생성될 때까지 처리되지 않고 기다립니다.  

```
proxy_cache_lock on;
proxy_cache_lock_age 10s;
proxy_cache_locak_timeout 3s;
```

proxy_cache_lock 지시자를 on으로 설정하면 생성 중인 캐시에 대해 동일한 요청이 들어와도 엔진엑스가 요청을 처리하지 않고 캐시 생성이 완료될 때까지 기다립니다. 캐시는 proxy_cache_lock_age 지시자에 지정된 시간(기본값은 5초) 내에 생성돼야 하며, 시간이 초과되면 대기 중인 다른 요청을 업스트림 서버로 보내 응답 결과 캐시를 다시 시도합니다. 반면에 proxy_cache_lock_timeout 지시자는 지정된 시간(기본값은 5초) 내에 캐시 생성이 완료되지 못하면 다른 요청을 업스트림 서버로 보내 필요한 콘텐츠를 가져오게 하되 캐시는 생성하지 않도록 해줍니다. 비슷해 보이는 두 지시자의 차이를 다시 설명하면, proxy_cache_lock_age는 '캐시 생성이 너무 오래 걸리는군. 내가 대신 캐시를 만들어줄게'라는 동작을 수행하는 반면 proxy_cache_lock_timeout은 '캐시 생성이 너무 오래 걸리는군. 나는 업스트림 서버에서 필요한 콘텐츠를 가져올 테니 너는 계속 캐시를 생성하도록 해'라는 의미입니다.  

#### 4.3. 해시 키 값 캐시  
<br/>

proxy_cache_key 지시자와 변수를 사용해 캐시 적중(hit)과 실패(miss) 기준을 정의합니다.  

```
proxy_cache_key "$host$request_uri $cookie_user";
```

예시는 엔진엑스가 요청된 페이지를 캐시로 저장할 때 요청 호스트명, URI, 쿠키값으로 사용자마다 서로 다른 해시를 생성해 캐시 키로 사용하도록 합니다. 이를 통해 동적인 페이지를 캐시하지만 다른 사용자의 콘텐츠가 잘못 전달되지 않도록 합니다.  

proxy_cache_key의 기본값은 "$scheme$proxy_host$request_uri"로 일반적으로 무난하게 사용할 수 있습니다. $scheme은 HTTP나 HTTPS 값을 가지며 proxy_host는 요청을 보낼 업스트림 호스트 값을 갖습니다. request_uri는 요청의 세부 경로를 나타냅니다. 즉, 셋을 합친 값은 엔진엑스가 요청을 위임받은 URL입니다. 그 외에도 애플리케이션에 대한 요청을 구분하기 위한 쿼리스트링, 헤더, 세션 식별자 등 여러 요소가 있으며 이 값들을 활용해 직접 해시 키를 구성할 수 있습니다. 이와 같이 엔진엑스에서 사용 가능한 변수와 문자열의 다양한 조합을 활용해 캐시 키를 만들 수 있습니다.  

해시 키 선택은 매우 중요하므로 애플리케이션에 대한 이해를 바탕으로 좋은 해시 키를 선택해야 합니다. 정적인 콘텐츠에서 사용할 캐시 키는 보통 직관적으로 어렵지 않게 선택할 수 있습니다. 호스트명과 URI만 사용해도 충분합니다. 반면에 대시보드 애플리케이션 화면처럼 어느 정도 변화가 있는 콘텐츠를 캐시할 때는 사용자의 애플리케이션 사용 방식이나 경험치 차이와 같은 정보가 필요합니다. 다만 특정 사용자의 동작을 통해 캐시된 콘텐츠를 상황에 대한 충분한 이해 없이 다른 사용자에게 제공하면 보안 문제를 야기할 수 있습니다. proxy_cache_key server, location 블록 컨텍스트에서 사용할 수 있으며 사용자 요청을 어떻게 캐시할지 유연하게 제어하도록 해줍니다.  

#### 4.4. 캐시 우회  
<br/>

proxy_cache_bypass 지시자를 비어 있지 않은 값이나 0이 아닌 값으로 지정해 캐시를 우회합니다. 대표적인 방법으로, 캐시하고 싶지 않은 location 블록 내에서 지시자의 매개변수로 사용된 특정 변숫값을 빈 문자열이나 0이 아닌 어떤 값으로든 설정합니다.  

```
proxy_cache_bypass $http_cache_bypass;
```

이 설정은 cache-bypass라는 HTTP 요청 헤더값이 0이 아닐 때 엔진엑스가 캐시를 우회하도록 합니다. 캐시를 우회할지 판단하기 위해 특정 헤더값을 변수로 사용하며 사용자는 캐시 우회가 필요하면 이 헤더를 요청에 포함해야 합니다.  

서비스를 운영하다 보면 요청한 콘텐츠를 캐시하지 말아야 하는 다양한 상황에 맞닥뜨립니다. 이때 proxy_cache_bypass 지시자의 매개변수를 비어 있지 않은 값이나 0이 아닌 값으로 할당하면 요청에 대한 응답을 캐시에서 가져오지 않고 업스트림 서버로부터 받아 사용자에게 전달합니다. 캐시를 우회하는 데 사용하는 방법은 애플리케이션 사용 방식에 따라 다를 수 있습니다. 간단히 요청 헤더나 응답 헤더를 사용하기도 하지만, 맵(map) 블록 여러 개 사용해 복잡하게 구현하는 방법도 있습니다.  

캐시를 우회하는 이유는 다양하며 트러블슈팅과 디버깅이 대표적입니다. 캐시된 페이지가 계속 응답되거나 사용자를 특정하도록 설정된 캐시 키를 사용하면 문제 상황을 재현하기가 어렵습니다. 따라서 캐시를 그대로 두고 업스트림 서버로 우회할 방법을 확보하는 일이 매우 중요합니다. 물론 특정 쿠키와 헤더 값, 쿼리스트링이 존재할 때 캐시 우회만이 유일한 방법은 아닙니다. location 블록과 같이 주어진 컨텍스트 내에서 proxy_cache 지시자를 off로 설정함으로써 캐시 기능을 완전히 끄는 방법도 좋은 선택입니다.  

#### 4.5. 캐시 성능  
<br/>

사용자 환경에서 유효한 Cache-Control 헤더를 사용합니다.  

```
location -* \.(css|js)$ {
    expires 1y;
    add_header Cache-Control "public";
}
```

이 location 블록은 사용자가 CSS와 자바스크립트 파일을 캐시하도록 명시합니다. expires 지시자는 사용자 환경에 캐시된 콘텐츠가 1년이 지나면 더는 유효하지 않도록 지정합니다. add_header 지시자는 HTTP 응답에 Cache-Control 헤더를 추가하며 값을 public으로 지정해 사용자에게 콘텐츠가 전달되는 중간에 위치한 어떤 캐시 서버라도 리소스를 캐시할 수 있도록 합니다. 헤더값을 private으로 지정하면 실제 사용자 환경에만 리소스를 캐시합니다.  

캐시 성능은 많은 요소에 좌우되며 특히 하드디스크의 입출력(I/O) 속도에 크게 좌우됩니다. 엔진엑스에는 캐시 성능을 높이는 데 도움을 주는 다양한 설정값이 있습니다. 대표적인 방법은 사용자 환경에 콘텐츠를 캐시하도록 응답 헤더를 내려주고 이후의 요청은 엔진엑스로 보내지 않고 로컬 환경에 캐시된 콘텐츠를 만료 전까지 사용하는 방법입니다.  

#### 4.6. 캐시 퍼지(엔진엑스 플러스)  
<br/>

엔진엑스 플러스의 퍼지(purge) 기능을 사용하고 proxy_cache_purge 지시자에 비어 있지 않은 값이나 0이 아닌 값을 할당합니다.  

```
map $request_method $purge_method {
    PURGE 1;
    default 0;
}

server {
    # ...
    location / {
        # ...
        proxy_cache_purge $purge_method;
    }
}
```

예시는 HTTP 요청 메서드가 PURGE이면 요청된 리소스에 대한 캐시를 퍼지합니다. 다음은 main.js 파일을 퍼지하는 curl 명령의 예입니다.  

```
curl -XPURGE localhost/main.js
```

정적인 파일을 다를 때는 일반적으로 파일 이름에 파일의 해시값을 사용합니다. 이렇게 하면 새로운 코드나 콘텐츠 배포 시 사용 중인 CDN이 변경된 URI를 기준으로 새로운 파일을 인식할 수 있습니다. 하지만 이 방식은 지정된 캐시 키 규칙에 따라 캐시하도록 설정된 동적 콘텐츠에는 잘 맞지 않습니다. 모든 캐시 시나리오는 캐시를 퍼지할 방법이 있어야 합니다. 엔진엑스 플러스는 캐시된 업스트림 서버의 응답을 퍼지하는 간단한 방법을 제공합니다. proxy_cache_purge 지시자는 0이 아닌 값이 할당되면 조건에 맞는 요청의 캐시를 퍼지합니다. 퍼지 기능을 사용하려면 예시처럼 간단히 PURGE 요청 메서드를 사용합니다. 다만 실제로는 geo_ip 모듈이나 사용자 인증 방법을 함께 사용해 아무나 함부로 캐시를 삭제하지 못하게 해야 합니다. 엔진엑스는 와일드카드(&#43;)를 사용해 URI 접두어가 같은 캐시를 퍼지할 수 있습니다. 와일드카드를 퍼지에 사용하려면 proxy_cache_path 지시자에 purger=on 인수를 할당합니다.  

#### 4.7. 캐시 분할  
<br/>

엔진엑스의 slice 지시자와 내장 변수를 캐시 결과를 작은 조각으로 나눕니다.  

```
proxy_cache_path /tmp/mycache keys_zone= mycache: 10m;

server {
    # ...
    proxy_cache mycache;
    slice 1m;
    proxy_cache_key $host$url$is_args$args$slice_range;
    proxy_set_header Range $slice_range;
    proxy_http_version 1.1;
    proxy_cache_valid 200 206 1h;

    location / {
        proxy_pass http://origin:80;
    }
}
```

이 설정은 캐시 영역을 정의하고 활성화합니다. 이후 slice 지시자를 사용하면 엔진엑스가 업스트림 서버의 응답을 1MB 크기 파일 조각으로 나눕니다. 나눠진 파일들은 proxy_cache_key 지시자에 지정된 규칙에 따라 저장됩니다. 예시에서 사용한 slice_range 내장 변수에 주목해봅시다. proxy_set_header 지시자를 사용해 원본 서버(origin server)로 요청을 보낼 때 Range 헤더를 추가하고 헤더값으로 slice_range 변숫값을 쓰도록 지정합니다.  

이렇게 설정하면 HTTP의 바이트 레인지(byte range) 요청을 사용할 수 있습니다. 다만 HTTP 1.1 버전부터 지원되는 기능이므로 proxy_http_version 지시자를 사용해 프로토콜 버전을 업그레이드해야 합니다. 캐시가 200과 206 응답에 한해 1시간 동안 유효하도록 proxy_cache_valid 지시자를 사용하며 이후에 location 블록과 원본 서버를 정의합니다.  

+ 가짜 스트림(pseudostream)  
HTTP 프로토콜의 바이트 레인지 요청으로 용량이 큰 비디오 파일을 작은 파일로 쪼개어 전송하는 방식은 사실상 스트리밍은 아니지만 스트리밍처럼 동작  

캐시 분할 모듈은 바이트 레인지를 사용하는 HTML5 비디오를 위해 개발됐습니다. 바이트 레인지를 사용하면 콘텐츠를 브라우저로 스트리밍과 유사하게 전달할 수 있습니다. 기본적으로 엔진엑스는 바이트 레인지 요청에 캐시된 콘텐츠를 제공합니다. 캐시되지 않은 콘텐츠에 대해 바이트 레인지 요청을 하면 엔진엑스는 원본 서버로부터 콘텐츠 전체를 가져오지만, 캐시 분할 모듈을 사용하도록 설정하면 필요한 파일 범위에 대해서만 원본 서버에 요청합니다. 분할 크기보다 큰 범위(전체 파일 전송 포함)에 대한 바이트 레인지 요청이 오면, 요청된 범위를 지정된 크기로 나눠 여러 개의 바이트 레인지 요청을 원본 서버로 보내고 콘텐츠를 캐시합니다. 모든 파일 조각이 캐시되면 사용자에게 보낼 응답을 만들어 엔젠엑스가 보다 효율적으로 콘텐츠를 캐시하고 제공하도록 합니다.  

캐시 분할 모듈은 변경되지 않고 용량이 큰 파일에만 적용해야 합니다. 엔진엑스는 원본으로부터 파일 조각을 받을 때마다 ETag 헤더값을 이용해 변경 유무를 검사합니다. ETag 값이 변경됐으면 엔진엑스는 파일이 더는 유효하지 않다고 판단해 파일 조각에 대한 캐시 생성을 중지합니다. 콘텐츠가 자주 변경되고 파일이 아주 크지 않을 때나 원본 서버가 캐시가 채워지는 동안 밀려드는 요청을 처리할 만큼 용량이 충분하다면 캐시 락(cache lock) 모듈을 써봐도 좋습니다. 캐시 락 모듈은 기본 엔진엑스 바이너리에 포함되지 않으므로 --with-http_slice_module 옵션을 사용해 소스 코드를 빌드해야 합니다.  

+ 엔진엑스 블로그 게시글 '엔진엑스와 엔진엑스 플러스를 사용한 효율적인 바이트 레인지 캐싱(Smart and Efficient Byte-Range Caching with NGINX & NGINX Plus)': https://oreil.ly/6Nkxs  

### 5. 프로그래머빌리티와 자동화  
<br/>

#### 5.0. 소개  
<br/>

+ 프로그래머빌리티(programmability)  
프로그래밍을 통해 상호 작용을 하는 능력  

엔진엑스 플러스 API는 HTTP 요청을 통해 업스트림 서버를 추가하거나 삭제함으로써 엔진엑스 플러스를 재설정하게 해줍니다. 엔진엑스 플러스가 제공하는 키-값 저장소는 HTTP 호출을 통해 엔진엑스 플러스에 정보를 주입하고 업스트림 경로나 트래픽을 제어해 한 단계 높은 수준의 동적인 설정 변경이 가능하도록 합니다.  

#### 5.1. 엔진엑스 플러스 API  
<br/>

엔진엑스 플러스 API가 API 호출을 통해 서버를 추가하거나 삭제하도록 설정합니다.  

```
upstream backend {
    zone http_backend 64k;
}

server {
    # ...
    location /api {
        api     [write= on];
    }

    location = /dashboard.html {
        root    /usr/share/nginx/html;
    }
}
```

이 설정은 공유 메모리 영역을 사용하는 업스트림 서버를 생성하고 /api 경로에 대한 location 블록을 통해 API를 활성화하며 엔진엑스 플러스 대시보드 접근을 위한 location 블록을 구성합니다.  

서버가 사용 가능해지면 API를 통해 업스트림 서버로 추가할 수 있습니다.  

```
curl -X POST -d '{"server":"172.17.0.3"}' 'http://nginx.local/api/3/http/upstreams/backend/servers/'
```

예시의 curl 명령은 엔진엑스 플러스의 업스트림 서버 설정에 새로운 서버를 추가합니다. HTTP POST 메서드를 사용했으며 -d 옵션으로 JSON 객체를 요청의 바디로 전송해 JSON 형식 응답을 받았습니다. 엔진엑스 플러스가 보낸 JSON 응답은 요청한 서버 객체에 대한 설정값입니다. 새로운 id 값이 생성되고 여러 항목이 기본값으로 설정됐습니다.  

엔진엑스 플러스 API는 RESTful하므로 요청 URI에 필요한 매개변수가 모두 기술돼 있습니다. URI의 형식은 다음과 같습니다.  

/api/{version}/http/upstreams/{httpUpstreamName}/servers/  

이번에는 업스트림 서버 풀에 포함된 모든 서버를 알려주는 API를 호출해봅니다.  

```
curl 'http://nginx.local/api/3/http/upstreams/backend/servers/'
```

이 curl 명령을 사용하면 엔진엑스 플러스는 이름이 backend인 업스트림 서버 풀에 포함된 모든 서버 목록을 가져옵니다. 앞선 예시에서 curl 명령으로 추가한 서버 한 대가 풀에 포함됐습니다. 이 API로 설정 가능한 모든 옵션값이 포함된 업스트림 서버 객체 정보를 확인합니다.  

업스트림 풀에서 서버를 제외하려면 해당 서버의 연결이 모두 종료돼야 하며 다음 예시처럼 엔진엑스 플러스 API를 이용해 서버의 연결을 점진적으로 종료할 수 있습니다.  

```
curl -X PATCH -d '{"drain":true}' 'http://nginx.local/api/3/http/upstreams/backend/servers/0'
```

이 curl 명령은 PATCH 메서드를 사용하며 JSON 바디를 통해 특정 서버의 연결을 감소하도록 지시합니다. 대상 서버 ID는 URI의 마지막에 포함되며, 서버 ID는 앞선 curl 명령 예시에서 살펴봤듯 업스트림 풀의 서버 목록을 통해 확인할 수 있습니다.  

엔진엑스 플러스는 API를 통해 전달된 명령을 수행하며 해당 서버의 연결은 점차 감소합니다. 이 절차는 애플리케이션이 사용하는 세션 수에 따라 처리 시간이 길어질 수 있습니다. curl을 통해 드레인(drain) API를 호출한 후 업스트림 서버가 맺은 활성 연결 현황을 보려면 다음 명령으로 active 속성값을 확인합니다.  

```
curl 'http://nginx.local/api/3/http/upstreams/backend'
```

마침내 모든 연결이 종료되면 다음 엔진엑스 플러스 API로 해당 업스트림 서버 풀에서 제외합니다.  

```
curl -X DELETE 'http://nginx.local/api/http/upstreams/backend/servers/0'
```

예시에서 curl 명령은 DELETE 메서드를 사용하며 URI는 연결 상태를 확인할 때 사용한 것과 동일합니다. DELETE 메서드는 엔진엑스가 서버를 풀에서 제외하도록 합니다. 이 API 호출은 아직 모든 연결이 종료되지 않은 서버와 서버의 ID 값을 응답 바디로 전송합니다. 예시에서는 서버가 한 대도 할당되지 않은 빈 서버 풀에서 시작해 API로 서버를 추가하고, 연결을 감소하고, 마지막으로 서버를 삭제했으므로 서버 풀은 다시 비게 됩니다.  

엔진엑스 플러스 API는 동적으로 애플리케이션 서버를 업스트림 서버 풀에 넣거나 제외할 수 있습니다. 서버가 활성화되면 서버 풀에 유효 서버로 등록되며 엔진엑스는 사용자 요청을 새롭게 활성화된 서버로 보내기 시작합니다. 서버를 풀에서 제외하려면 먼저 엔진엑스 플러스가 해당 서버의 연결을 감소하도록 하고, 서버가 종료되기 전에 업스트림 서버 플에서 제외하면 됩니다. 이처럼 API 호출을 통해 자동화를 할 수 있으며 운영자 개입 없이 서버 풀을 수평적으로 확장하거나 축소할 수도 있습니다.  

+ 엔진엑스 플러스 REST API 공식 문서: https://oreil.ly/BsdN5  

#### 5.2. 키-값 저장소 사용하기(엔진엑스 플러스)  
<br/>

엔진엑스 클러스터에 대한 키-값 저장소와 API를 설정하고 저장소에 키와 값을 추가합니다.  

```
keyval_zone zone=blocklist:1M;
keyval $remote_addr $blocked zone=blocklist;

server {
    # ...
    location / {
        if ($blocked) {
            return 403 'Forbidden';
        }
        return 200 'OK';
    }
}

server {
    # ...
    location /api {
        api write=on;
    }
}
```

예시에서는 엔진엑스 플러스가 keyval_zone 지시자를 사용해 blocklist라는 공유 메모리 영역을 만들고 용량 제한을 1MB로 설정합니다. keyval 지시자는 $remote_addr 값과 일치하는 키가 있으면 키값을 $blocked 변수에 저장합니다. 이렇게 정의된 새로운 변수는 엔진엑스 플러스 '403 Forbidden'을 응답할지 혹은 요청된 리소스를 응답할지 결정하는 데 사용합니다.  


이 설정으로 엔진엑스 플러스를 실행한 후 curl 명령으로 로컬 서버를 호출하면 아직 로컬 환경의 IP 주소가 blocklist 저장소에 등록되지 않았기 때문에 정상 응답을 받습니다.  

```
curl 'http://127.0.0.1/'
```

이제 API를 호출해 blocklist 저장소에 로컬 호스트 주소를 1이라는 값으로 추가해봅니다.  

```
curl -X POST -d '{"127.0.0.1":"1"}' 'http://127.0.0.1/api/http/keyvals/blocklist'
```

이 curl 명령은 POST 메서드를 통해 blocklist 공유 메모리 영역에 추가할 키-값 객체를 JSON 형태로 전송합니다. 키-값 저장소에 접근하기 위한 API URI는 다음과 같습니다.  

/api/{version}/http/keyvals/{httpKeyvalZoneName}

이제 로컬 호스트 IP 주소는 blocklist 키-값 저장소에 1로 저장됐습니다. 엔진엑스 플러스는 이후 수신되는 요청의 $remote_addr 값이 키-값 저장소에 저장돼 있는지 찾아보고 해당하는 키가 있으면 값을 $blocked 변수에 지정합니다. 이 변수는 if 구문에서 활용됩니다. 변수에 값이 지정돼 있다면 if 구문은 참으로 판정되고 엔진엑스 플러스는 요청에 '403 Forbidden'을 응답합니다.  

```
curl 'http://127.0.0.1/'
```

등록된 키-값을 갱신(update)하거나 삭제하려면 PATCH 메서드를 사용해 API를 호출합니다.  

```
curl -X PATCH -d '{"127.0.0.1":null}' 'http://127.0.0.1/api/3/http/keyvals/blocklist'
```

키 값이 널(null)이면 키는 삭제되며, 이후 요청은 다시 '200 OK' 응답을 받습니다.  

엔진엑스 플러스에서만 제공되는 키-값 저장소는 애플리케이션이 엔진엑스 플러스에 필요한 정보를 전달하는 데 사용합니다. 앞서 살펴본 예시에서 동적으로 차단리스트를 생성하는 데 $remote_addr 변수를 사용했습니다. 엔진엑스 플러스에서 변수로 다룰 수 있는(예: 세션 쿠기)을 가진 키를 키-값 저장소에 저장해 엔진엑스 플러스에 제공할 수 있습니다. 엔진엑스 플러스 R16 버전부터는 키-값 저장소가 클러스터 단위로 확대돼 엔진엑스 플러스 서버 한 대가 저장한 값을 클러스터 내 모든 서버가 함께 사용할 수 있습니다.  

엔진엑스 플러스 R19 버전 이후에는 키-값 저장소에 자료형(type)이 도입돼 특정 형식의 키에 대해서 저장된 자료를 인덱싱할 수 있습니다. 자료형의 기본값은 string이며 ip나 prefix 같은 자료형도 제공됩니다. string 형식에 대해서는 인덱스가 생성되지 않으며 모든 키가 정확히 일치할 때만 값을 찾을 수 있습니다. 반면에 prefix 형식은 키의 일부만 일치해도 자료를 찾을 수 있습니다. ip 형식에는 CIDR 표기법을 사용할 수 있습니다. 앞선 예시에서 키-값 저장소의 키 형식을 ip로 지정했다면 차단할 사용자 IP에 RFC1918에서 지정된 사설 대역의 CIDR 표기인 192.168.0.0/16이나 localhost에서 흔히 사용되는 127.0.0.1/32를 사용해도 같은 결과를 얻습니다.  

+ 엔진엑스 블로그 게시글 '엔진엑스 플러스의 키-값 저장소를 이용한 동적인 대역폭 제한(Dynamic Bandwidth Limits Using NGINX Plus Key-Value Store)': https://bit.ly/2qYPFII  

#### 5.3. NJS 모듈로 엔진엑스 자바스크립트 기능 활용하기  
<br/>

엔진엑스 NJS 모둘을 설치해 엔진엑스에서 자바스크립트를 사용하도록 활성화합니다.  

엔진엑스 설정 파일 경로 내에 자바스크립트 리소스를 위한 디렉토리를 아직 만들지 않았다면 다음과 같이 생성합시다.  

```
mkdir -p /etc/nginx/njs
```

만들어진 디렉터리에 /etc/nginx/njs/jwt.js라는 파일을 만들고 다음 내용을 입력합니다.  

```js
function jwt(data) {
    var parts = data.split('.').slice(0,2)
            .map(v=>Buffer.from(v, 'base64url').toString())
            .map(JSON.parse);
    return { headers:parts[0], payload: parts[1] };
}

function jwt_payload_subject(r) {
    return jwt(r.headersIn.Authorization.slice(7)).payload.sub;
}

function jwt_payload_issuer(r) {
    return jwt(r.headersIn.Authorization.slice(7)).payload.iss;
}

export default {jwt_payload_subject, jwt_payload_issuer}
```

이 자바스크립트 예시는 JSON 웹 토큰(JSON Web Token, JWT)을 디코딩하는 함수와 이 함수를 이용해 JSON 웹 토큰에 포함된 특정 키를 획득하는 함수 두 개를 정의합니다. 키를 획득하는 두 함수는 엔진엑스에서 활용할 수 있도록 익스포트(export) 명령으로 노출합니다. 이 함수들은 JSON 웹 토큰으로부터 두 개의 공통키 subject와 issuer를 반환합니다. 코드의 .slice(7) 부분은 권한 헤더값(Authrization header value)에서 처음 일곱 개 문자이지만 구분자로 사용하는 공백까지 감안해 총 일곱 개 문자를 잘라냅니다. AWS Cognito를 비롯한 몇몇 인증 서비스는 타입 정보를 제공하지 않으므로 JSON 웹 토큰의 순수한 토큰값만 취득할 수 있도록 이와 같은 코드로 불필요한 부분을 제거할 필요가 있습니다.  

엔진엑스 기본 설정 파일에서 다음과 같이 NJS 모듈 사용을 선언합니다. 모듈을 선언했으면 http 블록 내에서 사용할 자바스크립트 파일을 임포트해 사용할 수 있습니다.  

```
load_module /etc/nginx/modules/ngx_http_js_module.so;

http {
    js_path "/etc/nginx/njs/";
    js_import main from jwt.js;
    js_set $jwt_payload_subject main.jwt_payload_subject;
    js_set $jwt_payload_issuer main.jwt_payload_issuer;
}
```

이 엔진엑스 설정은 동적으로 NJS 모듈을 불러오고 앞서 작성한 자바스크립트 파일을 임포트합니다. 엔진엑스 지시자들은 자바스크립트 함수가 반환한 값을 엔진엑스 변수에 설정합니다.  

이 변수들을 활용해 자바스크립트 로직을 검증할 수 있습니다. 자바스크립트를 통해 설정된 값을 가진 변수들을 반환하는 server 블록을 정의합시다.  

```
server {
    listen 80 default_server;
    listen [::]:80 default_server;
    server_name _;
    location / {
        return 200 "$jwt_payload_subject $jwt_payload_issuer";
    }
}
```

이 설정이 생성하는 서버는 클라이언트가 권한 헤더로 보낸 값에서 추출한 subject와 issuer 값을 반환합니다. 이 값들은 자바스크립트 코드를 통해 디코딩된 값들입니다.  

코드가 잘 동작하는지 검증하려면 다음 내용을 포함하고 있는 JSON 웹 토큰 값을 요청에 담아 보냅니다. 다음과 같은 JSON 웹 토큰의 JSON 형태 값을 사용해 코드가 잘 동작하는지 검증해봅니다.  

다음 명령으로 주어진 JSON 웹 토큰을 포함한 요청을 서버로 보내서 자바스크립트 코드가 정상적으로 동작하고 정확한 값을 반환하는지 검증합니다.  

```
curl 'http://localhost/' -H "Authorization: Bearer eyJ0eXAi0i_JKV10iLCJhbGci0iJIUzI1NiIsImV4cCI6MTU4NDcyMzA4NX0.eyJpc3Mi0iJuZ2lueCIsInN1YiI6ImFsaWNlIwiZm9vIjoxMjMsImJhciI6InFxIiwienl4IjpmYWxzZX0.Kftl23Rvv9dIso1RuZ8uHaJ83BkKmMtTwch09rJtwgk"
```

엔진엑스가 제공하는 NJS 모듈은 요청과 응답을 처리하는 동안 표준 자바스크립트를 사용할 수 있도록 해줍니다. 이 모듈을 통해 필요한 비즈니스 로직을 프록시 계층에서 처리할 수 있습니다. 자바스크립트로 이러한 작업을 할 수 있도록 한 것은 자바스크립트가 널리 사용되고 있기 때문입니다.  

NJS 모듈이 제공됨으로써 엔진엑스로 요청이 수신됐을 때뿐 아니라 엔진엑스가 클라이언트로 응답을 보낼 때도 로직을 주입할 수 있습니다. JSON 웹 토큰을 디코딩하는 예시에서 봤듯 요청이 프록시를 통과하는 동안 요청을 검증하고 조작할 수 있습니다. NJS 모듈은 또한 업스트림 서비스의 응답 데이터도 자바스크립트 로직을 통해 조작한 후 클라이언트에게 응답할 수 있습니다. 게다가 스트림 서비스가 애플리케이션 계층에서 인식될 수 있도록 해줍니다.  

+ njs 스크립트 언어 공식 문서: https://oreil.ly/5NMAN
+ 엔진엑스 플러스 njs 모듈 설치하기: https://oreil.ly/OHtC_  

#### 5.4. 상용 프로그래밍 언어로 엔진엑스 확장하기  
<br/>

사용자 정의 엔진엑스 모듈을 C언어로 밑바닥부터 만들기 전에 여러분의 사용 사례에 다른 프로그래밍 언어를 쓸 수 있는지 확인합시다. C언어는 확실히 강력하고 성능이 뛰어나지만 그 외에도 엔진엑스가 제공하는 다양한 프로그래밍 언어 모듈을 사용해 익숙한 언어로 사용자 정의 모듈을 만들 수 있습니다. 대표적으로 엔진엑스가 만든 자바스크립트 기반 스크립트인 NGINX JavaScript(NJS)가 있으며 루아(Lua)와 펄(Perl) 모듈 또한 사용 가능합니다.  

이러한 언어 모듈을 통해 코드가 작성된 파일을 불러오거나 엔진엑스 설정 내부에 직접 코드 블록을 작성합니다. 루아 스크립트를 사용하려면 먼저 루아 모듈을 설치하고 다음처럼 인라인 코드 블록 형태로 코드를 작성합니다.  

```
load_module modules/ndk_http_module.so;
load_module modules/ngx_http_lua_module.so;

events {}

http {
    server {
        listen 8080;
        location / {
            default_type text/html;
            content_by_lua_block {
                ngx.say("hello, world")
            }
        }
    }
}
```

루아로 만들어진 모듈은 ngx라는 이름으로 제공되는 내장 객체를 가지며, 이를 통해 엔진엑스 API를 다룹니다. ngx 객체는 NJS의 요청 객체와 마찬가지로 엔진엑스가 수신한 요청을 다루는 여러 속성과 메서드가 있으며 이는 응답을 만드는 데 사용됩니다.  

펄 모듈이 설치돼 있다면 코드가 어떻게 엔진엑스 변수를 실행 환경에서 설정하는지 확인합니다.  

```
load_module modules/ngx_http_perl_module.so;

events {}

http {
    perl_set $app_endpoint 'sub { return $ENV{"APP_DNS_ENDPOINT"};}';
    server {
        listen 8080;
        location / {
            proxy_pass http://$app_endpoint
        }
    }
}
```

예시는 언어 모듈이 단순히 응답을 만들어내는 것을 넘어 더 많은 기능을 어떤 방식으로 수행하는지 보여줍니다. perl_set 지시자는 펄 스크립트가 반환한 데이터를 엔진엑스 변수에 저장합니다. 이 예시에서는 요청을 어떤 업스트림 서버로 보낼지 결정할 때 간단히 시스템 환경 변숫값을 사용합니다.  

엔진엑스 확장 기능의 능력은 무한합니다. 소스 코드를 직접 컴파일하면 엔진엑스에 C언어 모듈을 포함할 수 있으며, 이를 통해 만들어진 커스텀 코드나 코드가 포함된 설정을 동적으로 불러와 엔진엑스 기능을 확장할 수 있습니다. 그리고 자바스크립트, 루아 펄 문법과 기능을 제공하는 엔진엑스 모듈을 사용할 수 있습니다. 많은 경우 커스텀 엔진엑스 기능을 만들지 않고 이미 존재하는 모듈만 사용해도 충분합니다. 모듈에서 사용 가능한 여러 스크립트가 다양한 오픈 소스 커뮤니티에 이미 공개돼 있습니다.  

+ 엔진엑스 플러스 루아 모듈 설치하기: https://oreil.ly/WUpBI
+ 엔진엑스 플러스 펄 모듈 설치하기: https://oreil.ly/_ym5V
+ 엔진엑스 루아 모듈 설치하기: https://oreil.ly/trDKl
+ 엔진엑스 펄 모듈 설치하기: https://oreil.ly/V3dh0  

#### 5.5. 셰프로 엔진엑스 설치하기  
<br/>

```
knife supermarket install nginx
```

이 쿡북은 리소스 기반으로, 여러분이 직접 쿡북을 만들 때 사용 가능한 셰프 리소스를 제공합니다. 이를 활용해 여러분의 필요에 맞는 쿡북을 만듭니다. 이 쿡북은 슈퍼마켓에서 설치한 nginx 쿡북에 대한 의존성을 포함합니다. 의존성이 설치됐다면 제공되는 리소스를 활용할 수 있습니다. 다음과 같이 엔진엑스를 설치하는 레시피를 만들어봅시다.  

```
nginx_install 'nginx' do
    source 'repo'
end
```

source가 repo로 지정되면 엔진엑스 사에서 관리하는 저장소를 통해 최신 버전의 엔진엑스가 설치됩니다. 레시피에서 nginx_config 리소스를 사용하면 기본 엔진엑스 설정 파일을 덮어 쓸 수 있습니다.  

```
nginx_config 'nginx' do
    default_site_enabled true
    keepalive_timeout 65
    worker_processes 'auto'
    action :create
    notifies :reloadm 'nginx_service[nginx]', :delayed
end
```

레시피에서 nginx_site 리소스를 사용해 엔진엑스 설정에 서버 블록을 만듭니다.  

```
nginx_site 'test_site' do mode '0644'
    variables(
        'server' => {
            'listen' => [ '*:80' ],
            'server_name => [ 'test.example.com' ],
            'access_log' => '/var/log/nginx/test_site.access.log',
            'locations' => {
                '/' => {
                    'root' => '/var/www/nginx-default',
                    'index' => 'index.html index.htm',
                },
            },
        }
    )
    action :create
    notifies :reload, 'nginx_service[nginx]', :delayed
end
```

셰프는 루비로 만들어진 설정 관리 도구이며 클라이언트-서버 형태로 실행되거나 단독 설정으로 실행됩니다. 슈퍼마켓이라는 아주 큰 공개 쿡북 커뮤니티가 있으며 공개 쿡북은 명령줄 도구인 Knife를 통해 설치되고 관리됩니다. 셰프는 예시에서 살펴본 기능을 비롯해 매우 다양한 기능이 있습니다.  

슈퍼마켓에 공개된 엔진엑스 쿡북은 매우 유연하며 엔진엑스를 패키지 매니저나 소스 코드로 손쉽게 설치하는 옵션을 제공합니다. 다양한 모듈과 기본 설정을 템플릿으로 컴파일하고 설치하는 기능 또한 제공합니다.  

#### 5.6. 앤서블로 엔진엑스 설치하기  
<br/>

#### 5.7. 콘술 템플릿 기능으로 설정 자동화하기  
<br/>

consul-template 데몬과 템플릿 파일을 이용해 필요한 엔진엑스 설정을 템플릿으로 만듭니다.  

```
upstream backend { {{range service "app.backend"}}
    server {{.Address}};{{end}}
}
```

예시는 콘술 템플릿으로 만들어본 엔진엑스 업스트림 설정 블록입니다. 이 템플릿은 콘술이 app.backend에서 확인된 모든 노드를 순회하고, 콘술은 각 노드의 IP 주소에 대해 server 지시자를 생성합니다.  

consul-template 데몬은 명령줄 도구를 통해 실행되며 변경이 발생해 설정 파일이 생성될 때마다 엔진엑스를 리로드합니다.  

```
consul-template -consul-addr consul.example.internal -template ./upstream.template:/etc/nginx/conf.d/upstream.conf:"nginx -s reload"
```

명령은 consul-template 데몬을 주소가 consul.example.internal인 콘술 클러스터에 연결하고 현재 작업 디렉터리에서 upstream.template이라는 파일을 찾아 목표가 되는 파일을 템플릿으로 만듭니다. 생성된 파일은 /etc/nginx/conf.d/upstream.conf 경로에 저장되고 템플릿 파일이 변경될 때마다 엔진엑스를 리로드합니다. -template 플래그는 콜론으로 구분된 문자열 세 개를 입력받습니다. 먼저 템플릿 파일명과 생성된 파일을 내보낼 경로를 받고 마지막 인수로는 템플릿 생성 및 내보내기가 완료된 후 실행할 명령을 받습니다. 공백으로 구분되는 명령을 사용할 때는 예시 명령처럼 큰따옴표로 명령을 묶어줍니다. -consul 플래그는 데몬이 연결할 콘술 클러스터의 주소를 지정하는 데 사용합니다.  

콘술은 강력한 서비스 탐색 도구이자 설정 저장소입니다. 노드 정보를 디렉터리와 비슷한 구조에 키-값 형식으로 저장하고 RESTful API를 통해 접근합니다. 콘술은 또한 각 클라이언트에 DNS 인터페이스를 제공하고 클러스터에 연결된 노드를 도메인명으로 탐색할 수 있게 해줍니다. 콘술 클러스터를 활용하는 별도 프로젝트로 consul-template 데몬이 있습니다. 이 도구는 콘술 노드, 서비스 또는 키-값에 변경이 발생하면 새로운 파일을 템플릿으로 만듭니다. 이러한 동작은 엔진엑스 자동화 도구를 선택할 때 콘술을 고려하는 가장 큰 이유입니다. consul-template을 이용하면 템플릿 파일에 변경이 발생한 직후 데몬이 특정 명령을 수행하도록 할 수 있으며, 따라서 서비스 환경에 변화가 발생하면 새로운 엔진엑스 설정을 활성화하고 리로드할 수 있습니다. 콘술과 consul-template을 이용해 엔진엑스 설정이 지속적으로 변화하는 서비스 환경에 맞춰 동적으로 변경되게 할 수 있습니다. 인프라, 설정, 애플리케이션 정보는 중앙에 저장되며 consul-template은 변경 이벤트를 바탕으로 필요에 따라 템플릿을 다시 만들어냅니다. 이 기술을 바탕으로 엔진엑스는 서버 및 서비스 추가와 삭제, 애플리케이션 변경에 대응해 동적으로 재설정됩니다.  

+ 엔진엑스 플러스의 서비스 디스커버리 구현을 통해 부하분산 구현하기: https://developer.hashicorp.com/consul/tutorials/load-balancing/load-balancing-nginx-plus
+ 엔진엑스와 콘술 템플릿으로 부하분산 구현하기: https://developer.hashicorp.com/consul/tutorials/load-balancing/load-balancing-nginx
+ 콘술 공식 웹사이트: https://www.consul.io
+ 콘술 템플릿으로 서비스 구성하기: https://oreil.ly/g-OAb
+ 콘술 템플릿 깃허브 저장소: https://oreil.ly/dfHMm  

### 6. 인증  
<br/>

#### 6.0. 소개  
<br/>

엔진엑스는 클라이언트에 대한 인증을 수행할 수 있습니다. 클라이언트 요청을 엔진엑스가 인증함으로써 업스트림 서버에서 인증을 처리하며 발생하는 부하를 줄이고 동시에 인증받지 못한 요청이 애플리케이션 서버까지 도달하는 것을 막을 수 있습니다. 엔진엑스 오픈 소스 버전에서 사용할 수 있는 인증 모듈에는 HTTP 기본 인증(basic authentication)과 하위 요청(subrequest)을 통한 인증이 있습니다. 엔진엑스 플러스에서만 사용 가능한 JWT(JSON web token) 검증 모듈은 표준 오픈 아이디 커넥트(OpenID Connect, OIDC) 인증을 제공하는 서드파티 인증 사업자들을 엔진엑스로 통합합니다.  

#### 6.1. HTTP 기본 인증  
<br/>

다음과 같은 형식으로 파일을 생성합니다. 비밀번호는 이어서 설명하는 방법으로 암호화하거나 해시로 만듭니다.  

```
name1:password1
name2:password2:comment
name3:password3
```

각 행의 첫 번째 필드는 사용자 이름(username)이고 두 번째 필드는 비밀번호(password)입니다. 사용자에 대해 기록해둘 내용이 있으면 세 번째 필드를 사용하며 각 필드는 콜론으로 구분합니다. 엔진엑스는 몇 가지 비밀번호 형식을 지원합니다. 대표적으로 C언에서 제공하는 crypt() 함수로 암호화된 비밀번호가 있습니다. openssl을 통해 사용하는 passwd 명령도 내부적으로는 crypt() 함수를 이용해 구현돼 있습니다. openssl이 설치돼 있으면 다음 명령으로 비밀번호를 암호화합니다.  

```
openssl passwd MyPassword1234
```

명령을 실행하면 암호화된 문자열을 얻으며 엔진엑스의 비밀번호 파일에 이를 그대로 사용할 수 있습니다. HTTP 기본 인증을 활성화하려면 엔진엑스 설정 파일에서 auth_basic 지시자와 auth_basic_user_file 지시자를 사용합니다.  

```
location / {
    auth_basic              "Private site";
    auth_basic_user_file    conf.d/passwd;
}
```

auth_basic 지시자는 http, server, location 컨텍스트에서 사용할 수 있습니다. auth_basic 지시자에 문자열로 된 매개변수를 사용하면 인증받지 않은 사용자가 접근할 때 브라우저가 인증 팝업창을 띄우고 지정된 문자열을 보여줍니다. auth_basic_user_file 지시자에는 사용자 이름과 비밀번호가 저장된 파일의 경로를 지정합니다.  

설정에 문제가 없는지 확인하려면 curl 명령을 사용합니다. curl 명령의 -u나 --user 옵션을 사용해 사용자 이름과 비밀번호를 입력하고 Authorization 인증 헤더를 만듭니다.  

```
curl --user myuser:MyPassword1234 https://localhost
```

+ Dovecot  
유닉스 시스템을 위해 만들어진 오픈 소스 IMAP 혹은 POP3 서버  

HTTP 기본 인증을 위한 비밀번호를 만드는 방법과 그 형식은 보안의 정도에 따라 몇 가지로 나뉩니다. 아파치가 제공하는 htpasswd 명령으로도 비밀번호를 생성할 수 있는데 openssl과 htpasswd 명령 모두 엔진엑스가 이해할 수 있는 apr1 알고리즘을 사용해 비밀번호를 생성합니다. 비밀번호는 기업에서 사용하는 경량 디렉터리 접근 프로토콜(Lightweight Directory Access Protocol, LDAP)이나 Dovecot에서 채택한 Salted SHA-1 형식으로도 만들 수 있습니다. 그 외에도 엔진엑스는 여러 형식과 해싱 알고리즘을 제공하지만 대부분 보안이 취약하며 브루트포스 공격으로 탈취당하기 쉽습니다.  

HTTP 기본 인증을 이용해 엔진엑스 호스트 전체나 특정 가상 서버 혹은 특정 location 블록을 보호할 수 있습니다. 기본 인증은 웹 애플리케이션이 가진 자체 인증 체계를 대체하지는 않지만 공개되지 않은 정보를 안전하게 보호하는 데 도움을 줍니다. 기본 인증을 적용하고 인증에 성공하지 못한 사용자에게는 '401 Unauthorized' 응답과 함께 WWW-Authenticate 헤더를 회신합니다. 헤더값은 Basic realm="auth_basic" 지시자에 지정한 메시지"가 됩니다. 사용자 인증 요청은 사용자 이름과 비밀번호를 콜론으로 연결한 문자열 형태이며 엔진엑스로 전달되기 전에 base64로 인코딩되고 Authorization 요청 헤더값으로 지정됩니다. 서버는 헤더를 디코딩하고 auth_basic_user_file 지시자가 지정한 파일을 이용해 인증을 진행합니다. 사용자 이름과 비밀번호는 단순히 base64로 인코딩된 문자열로 전송되므로 HTTPs 사요이 권장됩니다.  

#### 6.2. 인증을 위한 하위 요청  
<br/>

요청된 리소스에 대해 응답하기 전에 http_auth_request_module을 사용해 인증 서비스로 요청을 보내고 요청자의 ID를 확인합니다.  

```
location /private/ {
    auth_request        /auth
    auth_request_set    $auth_status $upstream_status;
}

location = /auth {
    internal;
    proxy_pass              http://auth-server;
    proxy_pass_request_body off;
    proxy_set_header        Content-Length "";
    proxy_set_header        X-Original-URI  $request_uri;
}
```

auth_request 지시자의 매개변수로 내부 인증 시스템의 위치를 가리키는 URI를 지정합니다. auth_request_set 지시자는 인증을 위한 하위 요청의 응답으로 받은 값을 매개변수에 지정된 변수에 저장합니다.  

http_auth_request_module은 엔진엑스 서버가 처리하는 모든 요청에 대해 인증을 받도록 합니다. 사용자 요청을 처리해도 괜찮은지 확인하기 위해 하위 요청을 보내고 인증 시스템으로부터 인증을 받습니다. 하위 요청은 사용자 요청을 목적지 서버로 보내기 전에 엔진엑스가 내부 인증 시스템으로 보내 인증 결과게 대한 응답을 기다리는 인증 요청을 말합니다. auth 경로에 대해 구성된 location 블록은 HTTP 바디와 헤더를 포함한 원래 요청을 인증 서버로 보냅니다. 하위 요청에 대한 HTTP 응답 코드는 사용자 요청이 접근 허가를 받았는지 혹은 받지 않았는지 알려줍니다. 하위 요청이 200 응답을 받으면 인증이 성공한 것이고, 401이나 403 응답 코드를 받으면 인증이 실패한 것이며 동일한 응답 코드를 원래 요청에 반환합니다.  

사용 중인 인증 시스템에 바디값이 필요 없다면 예시처럼 proxy_pass_request_body 지시자를 off로 설정합니다. 이처럼 바디를 사용하지 않으면 인증 요청의 크기와 처리 시간이 줄어들고, 응답 바디가 없어지므로 Content-Length 헤더는 빈 값이 돼야 합니다. 여러분의 인증 서비스가 요청 URI를 알아야 한다면 커스텀 헤더를 정의해 값을 전달하고 인증 서비스가 검증하도록 합니다. 인증 서비스에 접근하는 하위 요청에서 특정 응답 헤더나 정보를 저장해둬야 한다면 auth_request_set 지시자를 사용해 응답 데이터를 새로운 변숫값으로 만듭니다.  

#### 6.3. JWT 검증하기(엔진엑스 플러스)  
<br/>

엔진엑스 플러스의 JWT 인증 모듈을 사용해 토큰의 시그니처(signature)를 검증하고 JWT 속성 정보(claim)와 헤더를 엔진엑스 변수로 가져옵니다.  

```
location /api/ {
    auth_jwt            "api";
    auth_jwt_key_file   conf/keys.json;
}
```

이 설정은 location 블록으로 분기된 요청에 대해 JWT 검증을 수행합니다. auth_jwt 지시자는 인증 헤더의 인증 범위(realm) 선언에 사용할 문자열을 매개변수로 사용하며 JWT를 저장할 매개변수를 추가로 지정할 수도 있습니다. JWT 표준에 따라 Authentication 헤더가 기본으로 사용됩니다. auth_jwt 지시자는 설정이 상속된 경우 상위 설정의 JWT 인증이 적용되지 않게 할 때도 사용합니다. 인증을 끄려면 auth_jwt 지시자의 매개변수로 off를 지정합니다. auth_jwt_key_file 지시자는 하나의 매개변수를 받으며 이 매개변수는 표준 JWK(JSON web key) 형식으로 만들어진 키 파일의 경로입니다.  

엔진엑스 플러스는 토큰 전체가 암호화되는 JSON 웹 암호화(Web Encryption)가 아닌 JSON 웹 시그니처(Web Signature) 형식 토큰 검증을 지원합니다. 엔진엑스 플러스는 HS256, RS256, ES256 알고리즘으로 서명된 시그니처를 검증할 수 있으며, 토큰 기반 검증을 수행함으로써 인증 서비스로 하위 요청을 만들어 보낼 때보다 시간과 리소스를 절약합니다. 엔진엑스 플러스는 암호화된 JWT 헤더와 페이로드를 판독하고 표준 HTTP 헤더와 속성 정보를 내장 변수에 할당해 엔진엑스에서 활용하도록 해줍니다. auth_jwt 지시자는 http, server, location, limit_except 컨텍스트에서 사용할 수 있습니다.  

+ JSON 웹 시그니처에 대한 RFC 표준: https://oreil.ly/N2llP
+ JSON 웹 알고리즘에 대한 RFC 표준: https://oreil.ly/1PV1N
+ JSON 웹 토큰에 대한 RFC 표준: https://oreil.ly/gBlUC
+ 엔진엑스 플러스 JWT 인증 셋업하기: https://oreil.ly/AdJGW
+ 엔진엑스 블로그 게시글 'JWT와 엔진엑스 플러스를 활용해 API 클라이언트 인증 셋업하기(Authenticating API Clients with JWT and NGINX Plus)': https://oreil.ly/5Yzjb  

#### 6.4. JSON 웹 키 생성하기(엔진엑스 플러스)  
<br/>

엔진엑스 플러스는 RFC 표준으로 제정된 JWK 형식을 사용합니다. 표준에 따르면 JWK 파일은 키 객체를 여러 개 포함하는 배열을 가질 수 있습니다.  

JWK를 생성하기 위한 라이브러리는 여러 프로그래밍 언어에서 제공되며 종류도 상당히 많습니다. 일정 주기로 JWK를 발급하고 갱신할 수 있도록 중앙화된 JWK 기관을 만들어 키 서비스로 제공하는 편이 좋습니다. 보안을 강화하기 위해서는 JWK의 송수신을 SSL/TLS 인증서를 사용해 보호할 필요가 있습니다. 키 파일도 적절한 사용자와 그룹에서만 접근할 수 있도록 권한을 관리해야 하며 가능한 한 서버의 메모리에 보관하는 편이 좋습니다. ramfs와 같은 메모리 파일시스템을 사용하면 쉽게 구현할 수 있습니다. 키를 주기적으로 갱신하는 것이 중요하므로 키 서비스가 공개키와 비밀키를 생성하고, 생성한 키를 API를 통해 애플리케이션과 엔진엑스에 제공하도록 하는 편이 좋습니다.  

+ JSON 웹 키에 대한 RFC 표준: https://oreil.ly/BrVBu  

#### 6.5. JSON 웹 토큰 검증하기(엔진엑스 플러스)  
<br/>

엔진엑스 플러스에서 제공하는 JWT 모듈을 location. server 블록에서 사용하고 auth_jwt 지시자가 $cookie_auth_token 변수에 저장된 토큰값을 검증하도록 합니다.  

```
location /private/ {
    auth_jwt            "Google Oauth" token=$cookie_auth_token;
    auth_jwt_key_file   /etc/nginx/google_certs.jwk;
}
```

이 설정에 따라 엔진엑스 플러스는 /private/ 경로로 접근하는 요청에 대해 JWT 검증을 하며 검증할 토큰은 auth_jwt 지시자를 사용해 $cookie_auth_token 변수를 참조합니다. 구글 OAuth 2.0 오픈아이디 커넥트는 기본 bearer 토큰을 사용하지 않고 auth_token 쿠키를 사용합니다. 따라서 엔진엑스가 기본 경로를 사용하지 않고 이 쿠리를 찾아 토큰값을 사용하도록 해야 합니다. auth_jwt_key_file 지시자는 임의의 경로를 사용합니다.  

예시 설정은 엔진엑스 플러스로 구글 OAuth 2.0 오픈아이디 커넥트의 JWT를 검증하는 방법을 보여줍니다. 엔진엑스 플러스의 JWT 인증 모듈은 JSON 웹 시그니처 규격에 대한 RFC를 준수하는 모든 JWT를 검증할 수 있으며, JWT를 사용하는 모든 싱글 사인온(Single sign-on, SSO) 시스템이 엔진엑스 플러스 계층에서 검증되도록 즉시 활성화됩니다. 오픈아이디 1.0 프로토콜은 신원 정보를 추가하는 OAuth 2.0 인증 프로토콜의 상위 계층이며 요청을 보낸 사용자의 신원을 증명하는 데 JWT를 사용합니다. 토큰의 서명을 통해 엔진엑스 플러스는 서명 이후 토큰이 변경된 적이 없음을 검증합니다. 이러한 방법으로 구글은 비동기 서명 방법을 제공하고 비공개 JWK를 안전하게 유지하면서 공개 JWK를 배포합니다.  

+ 엔진엑스 블로그 게시글 'JWT와 엔진엑스 플러스를 활용해 API 클라이언트 인증하기(Authenticating API Clients with JWT and NGINX Plus): https://oreil.ly/5Yzjb  

#### 6.6. JSON 웹 키 세트 획득 자동화와 캐싱(엔진엑스 플러스)  
<br/>

캐시 영역(cache zone)과 auth_jwt_key_request 지시자를 사용해 자동으로 키가 현행화되도록 합니다.  

```
proxy_cache_path /data/nginx/cache levels=1 keys_zone=foo:10m;

server {
    # ...

    location / {
        auth_jwt "closed site";
        auth_jwt_key_request    /jwks_uri;
    }

    location = /jwks_uri {
        internal;
        proxy_cache foo;
        proxy_pass  https://idp.example.com/keys;
    }
}
```

예시에서 auth_jwt_key_request 지시자는 엔진엑스 플러스가 internal로 선언된 하위 요청을 통해 JWKS를 가져오도록 합니다. 하위 요청은 신원 확인 서비스 제공자로 요청을 위임하기 위해 /jwks_uri로 보내집니다. 이 요청은 과부하를 막기 위해 10분간 캐시됩니다.  

auth_jwt_key_request 지시자는 엔진엑스 플러스 R17 버전에서 처음 도입됐습니다. 이 기능은 인증 요청이 발생하면 엔진엑스 플러스 서버가 가진 JWKS를 동적으로 업데이트합니다. 하위 요청을 통해 JWKS를 읽어들이며 이때 사용하는 서비스 제공자는 엔진엑스 플러스 서버 입장에서 로컬 네트워크 환경의 서버여야 합니다. 예시에서는 하위 요청을 처리하는 location 블록이 엔진엑스 플러스 내부에서 전달된 요청만 처리하도록 제한하고자 internal 지시자를 사용했습니다. 캐시를 선언해두면 JWKS가 꼭 필요할 때만 신원 확인 서비스로부터 읽어들이므로 서비스 제공자에 과부하가 걸리지 않습니다. auth_jwt_key_request 지시자는 http, server, location, limit_except 컨텍스트에서 사용할 수 있습니다.  

+ 엔진엑스 블로그 개시글 'JWT와 엔진엑스 플러스를 활용해 API 클라이언트 인증하기(Authenticating API Clients with JWT and NGINX Plus)': https://oreil.ly/5Yzjb
+ 엔진엑스 블로그 게시글 '엔진엑스 플러스 R26 발표: 새로운 기능 - 웹 키 세트 캐싱을 통한 빠른 JWT 검증(Faster JWT Validation with JSON Web Key Set Caching)': https://oreil.ly/3sMch  

#### 6.7. 오픈아이디 커넥트 SSO를 통한 사용자 인증(엔진엑스 플러스)  
<br/>

연동 작업에는 몇 가지 설정과 약간의 NGINX 자바스크립트 코드를 사용합니다. 우선 신원 확인 서비스 제공자(identity provider, IdP)가 오픈아이디 커넥트 1.0을 지원해야 합니다. 엔진엑스 플러스는 권한 부여 코드의 흐름에서 볼 때 OIDC로 요청을 전달하는 역할을 수행합니다.  

엔진엑스 사는 깃허브 공개 저장소에서 엔진엑스 플러스를 OIDC와 연동할 때 참고할 예시 설정과 코드를 소개합니다.  

접근이 제한된 리소스로 인증되지 않은 요청이 들어오면 엔진엑스 플러스는 IdP를 통해 요청에 대한 인증을 먼저 수행하도록 합니다. IdP들은 각자 로그인 절차를 수행하고 인증 코드를 엔진엑스 플러스로 보냅니다. 인증이 완료되면 엔진엑스 플러스는 인증 코드를 일종의 ID 토큰으로 활용해 IdP와 직접 통신합니다. 이 토큰은 JWT를 통해 검증되고 엔진엑스 플러스의 키-값 저장소에 보관됩니다. 키-값 저장소를 사용한다는 것은 고가용성 보장을 위해 설정된 엔진엑스 플러스 클러스터의 모든 인스턴스에서도 ID 토큰에 접근할 수 있음을 의미합니다. 이 과정에서 엔진엑스 플러스는 클라이언트에 대한 세션 쿠키를 생성해 키-값 저장소에서 토큰을 찾는 데 이용합니다. 마침내 클라이언트 요청은 세션 쿠키값과 함께 최초 요청한 리소스로 리다이렉트됩니다. 이후의 요청은 쿠키값을 통해 검증되며 필요시 엔진엑스 플러스 키-값 저장소에서 ID 토큰을 찾습니다.  

이러한 기능은 사이트마인더(SiteMinder)로 알려진 인증 기관(Certificate Authority, CA) 싱글 사인온이나 포지록(ForgeRock)의 오픈AM(OpenAM), 키클로크(Keycloak), 옥타(Okta), 원로긴(OneLogin), 핑 아이덴티티(Ping identity)와 같은 주요 신원 정보 제공 사업자와 연동해 사용할 수 있습니다. OIDC는 표준으로서 인증과 매우 밀접한 관계가 있습니다. 여기서 언급한 사업자들은 연동 가능한 수많은 사업자 중 일부임을 기억하기 바랍니다.  

+ 엔진엑스 블로그 게시글 '오픈아이디 커넥트와 엔진엑스 플러스를 활용해 애플리케이션 사용자 인증하기(Authenticating Users to Existing Application with OpenID Connect and NGINX Plus): https://oreil.ly/GGHY2
+ 오픈아이디 커넥트: https://openid.net/connect
+ 엔진엑스 오픈아이디 커넥트 깃허브 저장소: https://oreil.ly/sX86J  

### 7. 보안 제어  
<br/>

#### 7.0. 소개  
<br/>

보안은 여러 계층을 통해 보장되며 보안 수준을 강화하고 싶다면 다계층 보안 모델을 도입해야 합니다.  

#### 7.1. IP 주소 기반 접근 제어  
<br/>

보호해야 하는 리소스에 대한 접근을 제어하기 위해 http 접근 모듈과 stream 접근 모듈을 이용합니다.  

```
location /admin/ {
    deny 10.0.0.1;
    allow 10.0.0.0/20;
    allow 2001:0db8::/32;
    deny all;
}
```

이 location 블록은 사용자가 IPv4 주소를 사용하면 10.0.0.0/20 대역의 접근을 허용하며 IPv6 주소를 사용하면 2001:0db8::/32 대역의 접근을 허용합니다. IPv4 주소가 10.0.0.1이면 접근을 차단하며 그 외에 기술되지 않은 IPv4, IPv6 주소의 접근은 차단돼 403 응답을 받습니다. allow와 deny 지시자는 http, server, location과 TCP/UDP에 대한 stream, server 컨텍스트에서 사용할 수 있습니다. 정책이 여러 개 사용되면 위에서 아래로(top down) 내려가면서 순차적으로 정책 부합 여부를 판단합니다.  

인터넷에 공개된 귀중한 리소스와 서비스를 보호하려면 여러 계층에서 보안을 적용해야 합니다. 엔진엑스의 보안 기능은 이러한 계층형 보안의 한 축을 담당합니다. deny 지시자는 주어진 컨텍스트에서 사용자의 요청을 차단하며 allow 지시자는 차단 대상인 요청의 일부에 대해 요청을 허용합니다. 차단 및 허용 대상은 IP 주소를 기술하며 IPv4, IPv6 형식 단일 주소뿐아니라 CIDR 블록 방식으로도 대역을 지정할 수 있습니다. 예약 키워드 all을 사용해 모든 요청 대상으로 정책을 적용할 수 있으며 유닉스 소켓도 매개변수로 사용할 수 있습니다. 서버 리소스 보호가 필요할 때 일반적으로 내부의 특정 IP 대역을 허용하고 나머지 대역을 차단하는 정책을 사용합니다.  

#### 7.2. 크로스 오리진 리소스 공유(CORS)  
<br/>

CORS 접근을 허용하려면 사용자 요청의 메서드에 따라 응답 헤더를 변경합니다.  

```
map $request_method $cors_method {
    OPTIONS 11;
    GET      1;
    POST     1;
    default  0;
}

server {
    # ...
    location / {
        if ($cors_method = '1') {
            add_header 'Access-Control-Allow-Method' 'GET,POST,OPTIONS';
            add_header 'Access-Control-Allow-Origin' '*.example.com';
            add_header 'Access-Control-Allow-Headers'
                       'DNT,
                        Keep-Alive,
                        X-Request-With,
                        If-Modified-Since,
                        Cache-Control,
                        Content-Type';
        }
        if ($cors_method = '11') {
            add_header 'Access-Control-Max-Age' 1728000;
            add_header 'Content-Type' 'text/plain; charset=UTF-8';
            add_header 'Content-Length' 0;
            return 204;
        }
    }
}
```

예시는 map 지시자를 사용해 GET, POST 메서드를 그룹화해 처리합니다. OPTIONS 메서드는 프리플라이트(preflight) 요청으로 사용자에게 서버가 가진 CORS 정책을 응답합니다. 이 서버는 GET, POST, OPTIONS 메서드를 허용하며 Access-Control-Allow-Origin 헤더를 통해 http://example.com의 여러 하위 도메인에서 서버 리소스에 접근 가능함을 알려줍니다. 프리플라이트 요청을 매번 보내지 않고도 CORS 정책을 참고할 수 있도록 사용자 브라우저에 Access-Control-Max-Age 헤더에 172만 8000초(20일)를 설정해 정책을 캐시합니다.  

자바스크립트는 자신이 호스팅되는 도메인이 아닌 곳의 리소스를 요청할 때 CORS 정책이 필요합니다. 요청이 크로스 오리진 상황이라면(크로스 오리진 상황이라면 두 개 이상의 서로 다른 도메인에서 비동기로 리소스를 가져와 사용하는 상황입니다) 브라우저는 서버가 내려준 CORS 정책을 따라야 합니다. 브라우저는 적당한 CORS 헤더를 찾지 못하면 해당 리소스 사용을 중지합니다. 서버에서 제공하는 리소스를 하위 도메인에서 문제없이 사용하게 하려면 add_header 지시자로 필요한 CORS 헤더를 설정합니다. 요청이 GET, HEAD, POST 메서드와 Content-Type 헤더를 사용하고 그 외에 특별한 헤더가 없다면 브라우저는 요청을 서버로 보내고 Access-Control-Allow-Origin 응답 헤더만 확인합니다. 다른 요청에 대해서는 브라우저가 프리플라이트 요청을 보내 리소스에 대한 CORS 정책을 확인하고 따릅니다. 헤더가 적절히 설정되지 않았다면 브라우저는 리소스를 사용하지 않고 오류를 내보냅니다(CORS 정책 위반으로 리소스 사용이 중단됐는지 확인하려면 각 브라우저가 제공하는 개발자 도구의 콘솔(console) 화면을 사용합니다). 

#### 7.3. 클라이언트 측 암호화  
<br/>

ngx_http_ssl_module이나 ngx_stream_ssl_module과 같은 SSL 모듈을 사용해 트래픽을 암호화합니다.  

```
http { # 아래 지시자는 모두 stream 컨텍스트에서도 사용할 수 있습니다
    server {
        listen 8443 ssl;
        ssl_certificate /etc/nginx/ssl/example.crt;
        ssl_certificate_key /etc/nginx/ssl/example.key;
    }
}
```

이 설정은 서버가 8443 포트로 들어오는 요청에 대해 SSL/TLS를 사용해 암호화하도록 합니다. ssl_certificate 지시자는 인증서와 중간 체인 인증서(intermediate chain certificate)가 저장된 파일 경로를 정의합니다. ssl_certificate_key 지시자는 엔진엑스가 클라이언트 요청을 복호화하고 응답을 암호화하는 데 사용할 비밀키 파일을 정의합니다. 사용 중인 엔진엑스 버전이 배포된 시점에 따라 다양한 SSL/TLS 협상(negotiation) 설정 기본값이 있습니다.  

전송 중인 정보를 암호화할 때는 가장 흔히 보안 전송 계층을 사용합니다. TLS 프로토콜은 SSL 프로토콜보다 우선순위가 높습니다. SSL 프로토콜의 세 가지 버전 모두 안전하지 않다고 알려져 있기 때문입니다. 프로토콜 이름은 달라졌지만 여전히 TLS는 보안 소켓 계층을 만들며 엔진엑스는 TLS를 활용해 서버와 클라이언트 사이에 주고받는 정보를 보호합니다. 다시 말해, 사용자와 비즈니스를 보호해줍니다. 인증 기관을 통해 서명된 인증서를 사용할 때는 서버 인증서(leaf certificate/server certificate)와 인증 기관의 중간 체인 인증서를 하나로 합쳐 사용할 필요가 있습니다. 이렇게 인증서를 하나의 파일로 합칠 때 유의할 점은 서버 인증서가 파일 앞쪽에 위치하고 체인 인증서가 뒤에 나와야 한다는 점입니다. 간혹 인증 기고간이 중간 체인 증서를 여러 개 제공하는 경우가 있습니다. 이때 각 체인 인증서에 순서가 정해져 있으므로 병합해 사용할 때 유의합시다.  

+ 모질라가 제공하는 보안 및 서버 측 TLS 문서: https://mzl.la/2OU4x50
+ 모질라 SSL 설정 생성기: https://oreil.ly/xoyCM
+ SSL Labs의 SSL 서버 설정 시험: https://oreil.ly/aVWE2  

#### 7.4. 고급 클라이언트 측 암호화  
<br/>

http와 stream의 엔진엑스 SSL 모듈은 수신된 요청과 SSL/TLS 연결 협상(handshake)을 제어합니다. 인증서와 키 파일은 변수나 파일 경로 값을 통해 엔진엑스 설정에 사용할 수 있으며 엔진엑스는 설정된 내용에 따라 사용 가능한 프로토콜, 암호화 스위트(cipher suite), 키 형식을 클라이언트에 제공합니다. 클라이언트와 엔진엑스 서버는 연결 맺는 과정에 사용 가능한 가장 높은 수준의 보안 표준을 사용합니다. 엔진엑스는 클라이언트와 서버의 SSL/TLS 연결 협상 결과를 일정 시간 동안 캐시해 빠른 응답을 제공하는 데 사용할 수 있습니다.  

다음 설정은 클라이언트와 서버 간 SSL/TLS 연결 협상이 얼마나 복잡해질 수 있는지 보이고자 일부러 복잡하게 만든 것입니다. 예시에서 사용한 지시자는 모두 stream 컨텍스트에서도 사용할 수 있습니다.  

```
http { # 아래 지시자는 모두 stream 컨텍스트에서도 사용할 수 있습니다
    server {
        listen 8443 ssl;
        # 허용할 TLS 버전과 암호화 알고리즘을 설정합니다
        ssl_protocols TLSv1.2 TLSv1.3;
        ssl_ciphers HIGH:!aNULL:!MD5;

        # RSA 인증서 파일 경로를 지정합니다
        ssl_certificate /etc/nginx/ssl/example.crt;
        # RSA 암호화 키 파일 경로를 지정합니다
        ssl_certificate /etc/nginx/ssl/example.pem;

        # EV(Elliptic Curve) 인증서를 변수에서 불러옵니다
        ssl_certificate $ecdsa_cert;
        # EV(Elliptic Curve) 키를 파일 경로가 담긴 변수를 참조해 읽어옵니다
        ssl_certificate_key data:$ecdsa_key_path;

        # 클라이언트-서버 간의 SSL/TLS 연결 협상 결과를 캐시합니다
        ssl_session_cache shared:SSL:10m;
        ssl_session_timeout 10m;
    }
}
```

이 서버는 TLS 1.2나 1.3 버전을 사용할 수 있습니다. ssl_ciphers 지시자는 TLS 표준이 제시하는 높은 수준의 암호화 알고리즘을 사용하도록 HIGH(엔진엑스에서 사용하는 OpenSSL 버전에 따라 HIGH로 지정되는 암호화 스위트는 달라질 수 있습니다)로 지정하고 aNULL(인증 기능이 없는 암호화 알고리즘으로 중간자 공격(man in the middle attach, MITM))과 MD5는 사용하지 않도록 명시적으로 느낌표를 붙여 지정합니다.  

설정에서는 인증서 키 쌍 두 개를 사용합니다. 지시자로 전달하는 값들을 통해 엔진엑스에 인증서 키값을 제공하는 두 가지 방법을 알 수 있습니다. 전달하는 값은 기본적으로 인증서 파일에 대한 경로로 해석되지만 data: 접두어를 사용하면 변수에 담긴 값을 직접 사용합니다. 여러 가지 인증서 키 형식을 함께 사용하면 더 많은 클라이언트에 대해 호환성을 제공할 수 있습니다. 이 경우 클라이언트가 지원할 수 있고 서버가 받아줄 수 있는 가장 강력한 표준이 TLS 연결 협상에 사용합니다.  

SSL/TLS 키가 data 접두어를 직접 그 값을 사용하도록 지정됐다면, 엔진엑스 설정에 따라 키 내용이 로그에 기록되거나 노출될 가능성이 있습니다. 따라서 키값을 변수에 직접 담아 사용한다면 서버의 변경과 접근에 대한 보안이 충분히 보장되는 강력한 정책을 적용해야 합니다.  

SSL 세션 캐시(session cache)와 타임아웃 지시자는 엔진엑스 워커 프로세스가 지정된 시간 동안 세션 매개변수를 캐시하고 저장하도록 합니다. 엔진엑스 워커 프로세스는 단일 인스턴스 내에서 정보를 공유하지만 서로 다른 장비 간에는 공유하지 않습니다. 세션 캐시는 예시에 언급되지 않은 옵션이 있는데, 이는 성능 및 보안 이슈 발생 시 도움이 되며 여러 옵션을 복합적으로 연결해 사용할 수 있습니다. 하지만 기본값 없이 사용된 옵션은 내장 세션 캐시 기능을 꺼버릴 수 있으므로 주의합니다.  

예시에서 엔진엑스는 클라이언트에 TLS 1.2와 1.3 옵션을 제공하며 높은 수준으로 평가되는 암호화 알고리즘과 RSA, 타원곡선 암호(Elliptic Curve Cryptography, ECC) 형식의 키를 제공합니다. 클라이언트가 지원하는 강력한 프로토콜과 암호화 알고리즘, 키 형식은 협상의 결과입니다. 예시 설정은 캐시 영역으로 할당된 10MB 메모리가 허용하는 한 엔진엑스가 SSL/TLS 연결 정보를 최대 10분간 유지하도록 합니다.  

여러 시험 결과에 따르면 ECC 인증서는 암호화 강도가 비슷한 RSA 인증서보다 빠릅니다. 키 크기가 작으므로 동일한 리소스의 서버에서 더 많은 SSL/TLS 연결과 더 빠른 연결 협상을 제공할 수 있습니다. 이는 여러분이 새로운 기술의 이점을 누리면서 오래된 클라이언트에도 정상적인 서비스를 제공하게 해줍니다.  

엔진엑스는 예시에서 언급된 클라이언트와 엔진엑스 자신 사이 구간에 흐르는 트래픽을 암호화하고 업스트림 서버로의 연결 또한 암호화합니다.  

#### 7.5. 업스트림 암호화  
<br/>

필요한 SSL 요구사항을 지정하려면 HTTP 프록시 모듈의 SSL 지시자를 사용합니다.  

```
location / {
    proxy_pass https://upstream.example.com;
    proxy_ssl_verify on;
    proxy_ssl_verify_depth;
    proxy_ssl_protocols TLSv1.2;
}
```

예시에서 proxy 지시자들은 엔진엑스가 준수해야 하는 SSL 규칙을 정의합니다. 엔진엑스는 업스트림 서비스의 서버 인증서와 인증서 체인이 두 단계까지 유효한지 확인합니다.proxy_ssl_verify 지시자가 활성화됐으면 엔진엑스는 업스트림 서버가 제공하는 서버 인증서에 대해서만 유효성을 확인합니다. 체인 인증서까지 검증하도록 설정하려면 proxy_ssl_verify_depth 지시자를 사용합니다. proxy_ssl_protocols 지시자는 TLS 1.2 버전만 SSL 연결 설정에 사용하도록 설정합니다. 기본적으로 엔진엑스는 업스트림 서비스의 인증서와 연결할 때 사용한 TLS 버전을 확인하지 않습니다.  

HTTP 프록시 모듈에서는 매우 다양한 지시자를 활용할 수 있으며 업스트림 트래픽을 암호화하려면 proxy_ssl_verify 옵션을 활성화해야 합니다. HTTPS를 통해 요청을 프록시하려면 간단히 proxy_pass 지시자에 전달하는 값에 HTTPS 프로토콜을 사용하도록 지정합니다. 하지만 이것만으로는 업스트림 서버가 사용하는 인증서에 대한 검증을 수행하지 않습니다. 업스트림 서버와의 통신 구간의 보안 수준을 높이려면 proxy_ssl_certificate이나 proxy_ssl_certificate_key와 같은 지시자를 사용해 보안 요건을 지정합니다. 추가로 proxy_ssl_crl 지시자나 더는 유효하지 않은 인증서를 식별할 폐지 인증서 목록을 활용할 수 있습니다. 이와 같이 SSL 프록시 지시자를 통해 데이터 센터 내부 네트워크나 공용 인터넷 구간으로의 통신 채널을 견고하게 만듭니다.  

#### 7.6. location 블록 보호하기  
<br/>

secure link 모듈과 secure_link_secret 지시자를 사용해 secure link를 가진 사용자만 리소스에 접근하도록 허용합니다.  

```
location /resources {
    secure_link_secret mySecret;
    if ($secure_link = "") { return 403; }

    rewrite ^ /secured/$secure_link;
}

location /secured/ {
    internal;
    root /var/www;
}
```

이 설정은 공개된 location 블록과 내부에서만 접근 가능한 location 블록을 만듭니다. /resources 경로에 대해 설정된 공개 location 블록은 요청 URI가 secure_link_secret 지시자에 설정된 비밀값으로 검증 가능한 md5 해시값을 갖고 있지 않으면 '403 Forbidden'을 응답합니다. $secure_link 변수는 URI에 포함된 해시값이 검증되기 전까지는 아무런 값을 갖지 않습니다.  

리소스를 비밀값으로 보호하면 파일의 안전이 보장됩니다. 비밀값은 URI와 함께 사용하며 URI에는 비밀값을 md5 해시로 변환한 후 해시값을 16진수 다이제스트(hex digest)로 계산한 값을 사용합니다. 해시는 링크에 포함되고 엔진엑스에게 유효성을 평가받습니다. 엔진엑스는 해시값 뒤에 이어진 URI를 보고 요청된 파일의 경로를 파악하며 secure_link_secret 지시자를 통해 제공된 비밀값도 알고 있습니다. 엔진엑스는 md5 해시값을 빠르게 검증하고 실제 리소스 경로를 $secure_link 변수에 할당합니다. 해시가 검증되지 않으면 변수는 빈 문자열 값을 갖게 됩니다. 참고로 secure_link_secret 지시자에 전달하는 인수는 변수가 아닌 고정된 문자열이어야 합니다.  

#### 7.7. 비밀값으로 보안 링크 생성하기  
<br/>

엔진엑스의 secure link 모듈은 URI 경로와 비밀값을 연결한 문자열로 생성한 md5 해시의 16진수 다이제스트를 인식합니다. 이 절에서는 /var/www/secured/index.html 파일을 보호하기 위한 보안 링크를 만들어봅니다. 먼저 openssl 명령으로 md5 해시에 대한 16진수 다이제스트를 생성하는 방법을 살펴봅시다.  

```
echo -n 'index.htmlmySecret' | openssl md5 -hex
```

명령은 보호할 리소스 이름인 index.html과 비밀값 mySecret을 연결한 문자열을 openssl의 매개변수로 전달합니다. openssl은 문자열을 md5로 해시한 후 16진수 다이제스트값을 계산해 출력합니다.  

다음은 파이썬 표준 라이브러리인 hashlib을 사용해 파이썬으로 작성한 해시 다이제스트 생성 코드입니다.  

```python
import hashlib
hashlib.md5.(b'index.htmlmySecret').hexdigest()
```

이렇게 만든 해시 다이제스트값을 URL에 추가해 사용해봅시다. 도메인은 www.example.com이며 /var/www/secured/index.html 파일에 접근하기 위해 /resources location 블록 조건을 사용하도록 URL을 구성합니다.  

다이제스트값은 다양한 언어를 사용해 여러 방법으로 생성할 수 있습니다. 다이제스트값 생성에 사용할 문자열을 만들 때는 주의할 점이 몇 가지 있습니다. URI가 비밀값 앞에 위치해야 하며 문자열 중간에 줄바꿈 문자(carriage return)를 포함하지 않아야 합니다. md5 해시를 생성한 후 16진수 다이제스트값을 추출해 사용합니다.  

#### 7.8. 기간 제한 링크로 location 블록 보호하기  
<br/>

sucure_link 모듈에 포함된 지시자로 만료 일자를 지정하고 보안 링크에 포함된 변수를 사용합니다.  

```
location /resources {
    root /var/www;
    secure_link $arg_md5,$arg_expires;
    secure_link_md5 "$secure_link_expires$uri$remote_addrmySecret";
    if ($secure_link = "") { return 403; }
    if ($secure_link = "0") { return 410; }
}
```

secure_link 지시자는 쉼표는 구분된 매개변수 두 개를 사용합니다. 첫 번째 매개변수는 md5 해시값을 담는 변수이며 예시에서는 쿼리 인수의 md5 값을 사용합니다. 두 번째 매개변수는 링크 만료 시간을 담는 변수이며 유닉스 에폭(epoch) 시간 형식으로 표기됩니다. 두 번째 매개변수는 링크 만료 시간을 담는 변수이며 유닉스 에폭(epoch) 시간 형식으로 표기됩니다. secure_link_md5 지시자는 매개변수를 한 개 사용하며 md5 해시를 생성할 때 사용한 문자열의 형식을 선언합니다. 다른 보안 링크 설정과 마찬가지로 해시가 검증되지 않으면 $secure_link 변수는 빈 값이 됩니다. 해시가 검증되더라도 만료 시간이 초과됐다면 $secure_link 변숫값은 0이 됩니다.  

기간 제한 링크를 사용하는 보안 방법은 secure_link_secret 지시자로 location 블록을 보호하는 설정보다 더 유연하고 깔끔합니다. 이 절에서 살펴본 지시자를 이용하면 엔진엑스에서 사용 가능한 다양한 변수로 해시 문자열을 생성할 수 있습니다. 해시 문자열을 생성하는 데 사용자 단위 변수를 사용하면 중요한 리소스에 대한 보안 링크를 공유하기가 어려워지므로 보안 수준이 향상됩니다. $remote_addr, $http_x_forwarded_for 변수나 애플리케이션이 생성한 세션 쿠키값을 사용하기를 권장합니다. secure_link 지시자의 인수는 쿼리 매개변수 이름과 관계없이 어느 것이든 사용할 수 있습니다. 요청을 허용하는 조건은 '접근 권한이 있는가?", "만료 시간이 되기 전에 접근했는가?"입니다. 접근 권한이 없으면 '403 Forbidden' 응답을 반환하고 만료 시간이 지났으면 접근 권한이 있더라도 '410 Gone' 응답을 반환합니다. '410 Gone' 응답 코드는 링크 만료라는 조건이 있으므로 해당 상황에 적절합니다.  

#### 7.9. 기간 제한 링크 생성하기  
<br/>

유닉스 에폭 형식으로 된 만료 시간 타임스탬프값을 생성합니다. 유닉스 시스템과 맥 운영체제에서 타임스탬프를 생성하려면 각각 다음처럼 date 명령을 사용합니다.  

```
// 유닉스 시스템
date -d "2030-12-31 00:00" +%s --utc
// 출력 >> 1924905600

// 맥 운영체제
date -j -f "%Y-%m-%d %T" "2030-12-31 09:00:00" +%s
// 출력 >> 1924905600
```

다음으로 엔진엑스 설정의 secure_link_md5 지시자에 정의된 규격에 맞춰 해시 대상 문자열을 만듭니다. secure_link_md5 지시자에는 $secure_link_expires$uri$remote_addrmySecret를 지정했습니다. 따라서 문자열은 1924905600/resources/index.html127.0.0.1mySecret이 됩니다. secure_link_md5 지시자에서 사용하는 md5 해시는 md5 해시의 16진수 다이제스트값과는 약간 다릅니다. 바이너리 형식으로 표시된 md5 해시이고 base64 인코딩돼 있으며 더하기(+) 기호는 하이픈(-)으로, 슬래시(/) 기호는 언더스코어(_)로 바뀌고 등호(=)는 삭제됩니다. 다음은 유닉스 시스템에서 secure_link_md5를 만드는 명령이며 맥 운영체제에서도 동일하게 사용합니다.  

```
echo -n '1924905600/resources/index.html127.0.0.1mySecret' | openssl md5 -binary | openssl base64 | tr +/ -_ | tr -d =
```

다음은 파이썬 코드로 구현한 실전에 가까운 예시입니다. 링크가 생성 시점으로부터 한 시간 후에 만료되도록 상대적인 만료 시간을 지정하며 파이썬 2.7과 3.x 버전에서 공통으로 제공하는 표준 라이브러리를 사용합니다.  

```python
from datetime import datetime, timedelta from base64 import b64encode
import hashlib

# 환경 변수 선언
resource = b'/resources/index.html' remote_addr = b'127.0.0.1'
host = b'www.example.com' mysecret = b'mySecret'

# 만료 시점에 대한 타임스탬프값 계산
now = datetime.utfnow()
expire_dt = now + timedelta(hours=1)
expire_epoch = str.encode(expire_dt.strftime('%s'))

# 문자열을 md5로 해싱
uncoded = expire_epoch + resource + remote_addr + mysecret
mdShashed = hashlib.md5(uncoded).digest()

# base64로 인코딩하고 일부 문자를 교체
b64 = b64encode(mdShashed)
unpadded_b64url = b64.replace(b'+', b'-').replace(b'/', b'_').replace(b'=', b'')

# 만들어진 값을 사용해 URL 링크 생성
linkformat = "{}{}?md5={}?expires={}"
securelink = linkformat.format(host.decode(), resource.decode(), unpadded_b64url.decode(), expire_epoch.decode())
print(securelink)
```

이러한 방식으로 보안 링크를 URL에서 사용 가능한 특별한 형식으로 생성합니다. 비밀키는 클라이언트로 전송되지 않는 변숫값을 활용함으로써 보안을 제공합니다. location 블록을 보호하기 위해 변수를 필요한 개수만큼 사용할 수 있습니다. md5 해시와 base64 인코딩은 커의 모든 언어에서 지원되는 기술이며 가볍게 사용할 수 있습니다.  

#### 7.10 HTTPS 리다이렉션  
<br/>

모든 HTTP 트래픽을 HTTPS로 보내려면 URL을 재작성합니다.  

```
sever {
    listen 80 default_server;
    listen [::]:80 default_server;
    server_name _;
    return 301 https://$host$request_uri;
}
```

예시는 엔진엑스에 설정된 모든 호스트명에 대해 IPv4와 IPv6 주소를 가리지 않고 80 포트로 요청을 받습니다. return 구문은 클라이언트로 '301 Permanent Redirect' 응답을 보내 동일한 호스트명과 URI에 대해 다시 HTTPS로 요청하도록 합니다.  

HTTP를 사용해야 하는 이유가 특별히 없다면 요청이 항상 HTTPS를 사용하도록 리다이렉트하는 편이 좋습니다. 혹은 클라이언트와 서버 간에 주고받는 민감한 데이터만 HTTPS로 리다이렉트할 수도 있습니다. location 블록을 사용해(예를 들어, 로그인 경로인 /login에 대해 location 블록을 적용) HTTP 요청을 HTTPS를 사용하도록 리다이렉트합니다.  

#### 7.11. HTTPS 리다이렉션 - SSL 오프로딩 계층이 있는 경우  
<br/>

엔진엑스가 실제 사용자의 요청을 수신하는 경우가 아니라면 X-Forwarded-Proto 헤더를 통해 사용자의 프로토콜을 확인할 수 있으며 이 값을 활용해 리다이렉트를 합니다.  

```
server {
    listen 80 default_sever;
    listen [::]:80 default_server;
    server_name _;

    if ($http_x_forwarded_proto = 'http') {
        return 301 https://$host$request_uri;
    }
}
```

예시는 언뜻 보면 HTTP 리다이렉션과 비슷합니다. 하지만 이 설정에 사용한 if 문은 X-Forwarded-Proto 헤더값이 http인 경우에만 301 리다이렉트 응답을 합니다. 이 헤더는 실제 사용자가 요청에 사용한 프로토콜 값을 담고 있습니다.  

종종 SSL/TLS 연결을 엔진엑스 앞에 위치한 계층에서 종료(SSL 오프로딩)시키고 엔진엑스로는 HTTP를 사용해 요청하는 경우가 있습니다. 이는 엔진엑스가 HTTPS를 처리하는 데 드는 컴퓨팅 비용을 절약하기 위함입니다. 한편 보안 강화를 위해 모든 클라이언트가 HTTPS로 인해 HTTPS로 리다이렉트하도록 응답하지 못할 수도 있습니다. 다행히 해당 계층에서 프록시 헤더는 설정할 수 있다고 가정합시다. 이러한 상황은 대표적으로 AWS ELB를 사용할 때 발생합니다. ELB는 추가 비용 없이 SSL/TLS 오프로딩 기능을 제공합니다. 이때 예시와 같은 엔진엑스 설정을 사용하면 ELB가 리다이렉트 응답을 직접 하지는 못하더라도 엔진엑스의 응답을 전달해 사용자가 다시 HTTPS로 요청을 보내도록 할 수 있습니다. 다소 꼼수 같아 보이는 방법이지만 HTTP 트래픽을 보다 안전하게 만들기 위해 널리 사용됩니다.  

#### 7.12. HSTS  
<br/>

Strict-Transport-Security 헤더를 설정해 HSTS(HTTP Strict Transport Security) 확장을 사용합니다.  

```
add_header Strict-Transport-Security max-age=31536000;
```

이 설정은 Strict-Transport-Security 헤더를 유효 기간 1년(31,536,000초)으로 지정해 응답 헤더를 전달합니다. 브라우저는 이 도메인에 대해 HTTP 요청이 발생하면 내부 리다이렉트를 통해 모든 요청이 항상 HTTPS를 이용하도록 합니다.  

일부 애플리케이션에서는 중간자 공격에 의해 탈취된 HTTP 요청 하나 때문에 회사가 존폐의 기로에 설 수도 있습니다. POST 요청의 폼 데이터에 담긴 민감한 정보가 HTTP로 전송된다면 엔진엑스의 HTTPS 리다이렉트 응답은 도움이 되지 않습니다. HTTPS로 리다이렉트되기 전에 평문으로 데이터가 존생돼 이미 모든 상황이 끝났을 수 있기 때문입니다. 자발적으로 설정해 사용해야 하는 HSTS 보안 확장 헤더는 브라우저가 근본적으로 HTTP로 요청을 보내지 못하게 함으로써 요청이 암호화되지 않은 상태로 전송되는 상황을 방지합니다.  

+ HSTS에 대한 RFC 표준: https://oreil.ly/oLaZc
+ OWASP의 HSTS 치트 시트: https://oreil.ly/AVn-g  

#### 7.13. 다중 계층 보안  
<br/>

satisfy 지시자를 사용해 모든 보안 검증을 통과해야만 요청을 허용할지 혹은 일부 보안 검증만 통과해도 유효한 요청으로 볼지 설정합니다.  

```
location / {
    satisfy any;

    allow 192.168.1.0/24;
    deny all;

    auth_basic              "closed site";
    auth_basic_user_file    conf/htpasswd;
}
```

이 설정은 루트 경로에 대한 사용자 요청이 설정된 보안 검증 방법 중 하나 이상을 만족하면 유효한 요청으로 판단합니다. 예를 들어, 사용자 IP 주소가 192.168.1.0/24 대역에서 접근하거나 서버의 conf/htpasswd 파일에 설정된 계정 및 비밀번호와 일치하면 유효한 요청으로 판단합니다. satisfy 지시자는 매개변수로 any 혹은 all 값을 가집니다.  

satisfy 지시자는 웹 애플리케이션에 여러 보안 및 인증 절차를 동시에 적용하는 훌륭한 방법입니다. satisfy 지시자에 any 매개변수를 설정하면 사용자가 보안 요소를 적어도 한 개 이상을 충족하는지 확인합니다. 반면에 all 매개변수를 사용하면 정의된 보안 요소를 모두 만족해야만 유효한 요청으로 처리합니다. satisfy 지시자는 http_access_module 뿐 아니라 http_auth_basic_module, http_auth_request_module, http_auth_jwt_module 등 다양한 지시자와 함께 사용할 수 있습니다. 보안은 다양한 계층을 통해 적용돼야만 진정한 보안이라 할 수 있으며 satisfy는 이를 달성하는 데 도움이 됩니다. 높은 수준의 보안 정책을 요구하는 location, server 블록에 satisfy 지시자를 적용할 수 있습니다.  

#### 7.14. 다중 계층 DDoS 방어(엔진엑스 플러스)  
<br/>

엔진엑스 플러스를 사용해 클러스터 레벨의 빈도 제한(rate limit)과 자동화된 차단리스트를 적용합니다.  

```
# 클러스터 단위로 빈도 제한을 적용합니다.
limit_req_zone $remote_addr zone=per_ip:1M rate=100r/s sync;
limit_req_status 429;

# TTL이 10분인 클러스터 단위의 sinbin 저장 영역을 만들고
# sinbin 저장 영역에 사용자 IP를 저장합니다
keyval_zone zone=sinbin:1M timeout=600 sync;
keyval $reomte_addr $in_sinbin zone=sinbin;

server {
    listen 80;
    location / {
        if ($in_sibin) {
            set $limit_rate 50; # IP별 대역폭 제한 설정
        }

        # IP 단위로 제한을 적용합니다
        limit_req zone=per_ip;

        # 빈도를 초과한 요청은 @send_to_sinbin으로 보냅니다
        # 문제없는 요청은 my_backend로 보냅니다
        error_page 429 = @send_to_sinbin;
        proxy_pass http://my_backend;
    }

    location @send_to_sinbin {
        # 초과된 요청을 보낸 IP에 대해 sinbin 저장소에 플래그를 설정합니다
        rewrite & /api/3/http/keyvals/sinbin break;
        proxy_method POST;
        proxy_set_body '{"$remote_addr":"1"}';
        proxy_pass http://127.0.0.1:80;
    }

    location /api/ {
        # API 접근을 제어합니다
        api write= on;
    }
}
```

예시는 DDoS 공격에 유연하게 대응하고 공격을 경감하기 위해 동기화된 키-값 저장소를 사용해 IP 단위로 빈도를 제한합니다. limit_req_zone과 keyval_zone 지시자에 설정된 sync 매개변수는 액티브-액티브(active-active)방식으로 엔진엑스 플러스 클러스터를 구성하는 여러 장비 간에 공유 메모리 영역을 동기화하도록 합니다. 이를 통해 어떤 엔진엑스 노드가 수신하든 관계없이 요청을 초당 100개 이상 보내는 클라이언트를 식별합니다. 요청 빈드 제한을 초과하면 엔진엑스 플러스 API를 통해 클라이언트의 IP 주소를 sinbin 키-값 저장소에 추가합니다. 이때 sinbin 키-값 저장소는 클러스터 단위로 동기화된 저장소입니다. IP 주소가 저장소에 추가되고 나서 들어온 요청은 어떤 엔진엑스 플러스 노드가 수신하든 관계없이 매우 낮은 대역폭으로 제한이 적용됩니다. 대역폭을 제한하면 사용자가 DDoS 경감 솔루션이 동작함을 알아차리기 어렵고 요청은 거절됩니다. 저장소에 추가된 IP 주소는 10분 후 자동으로 삭제되고 이후에는 제한이 풀립니다.  

#### 7.15. 앱 프로텍트 WAF 모듈 설치와 설정(엔진엑스 플러스)  
<br/>

사용 중인 플랫폼에 맞춰 공식 문서(https://oreil.ly/jEOqg)에 있는 엔진엑스앱 프로텍트 WAF 모듈 설치 가이드를 따라 설정을 진행합니다. 특히 앱 프로텍트 WAF 모듈 서명을 별도 저장소로부터 설치하는 부분을 잊지 맙시다.  

메인 컨텍스트에서 load_module 지시자를 사용해 앱 프로텍트 WAF 모듈이 로드됐는지 확인하고 이름이 app_protect_로 시작하는 지시자들을 사용해 모듈을 활성화합니다.  

```
user nginx;
worker_processes auto;

load_module modules/ngx_http_app_protect_module.so;

# ... 여러 메인 컨텍스트 지시자가 이곳에 위치합니다

http {
    app_protect_enable on;
    app_protect_policy_file "/etc/nginx/AppProtectTransparentPolicy.json";
    app_protect_security_log_enable on;
    app_protect_security_log "/etc/nginx/log-default.json"
    syslog:server=127.0.0.1:515;

    # ... 여러 http 컨텍스트 지시자가 이곳에 위치합니다
}
```

app_protect_enable 지시자에 on 매개변수를 사용해 현재 컨텍스트에서 모듈을 사용하도록 활성화합니다. 이어지는 app_protect_&#42; 지시자들은 http, server, location 컨텍스트에서 사용할 수 있습니다. app_protect_policy_file 지사자는 앱 프로텍트 정책 파일이 저장된 경로를 가리키며 파일이 존재하지 않으면 기본 정책을 적용합니다. 나머지 두 지시자는 보안 로드를 활성화하고 저장하는 방식을 설정합니다. 예시에서는 로그 저장을 위해 로컬 운영체제의 시스로그(syslog) 리스너를 사용하도록 설정합니다. app_protect_security_log 지시자는 매개변수를 두 개 사용합니다. 첫 번째는 로깅 설정에 대한 값을 정의하는 JSON 파일이고 두 번째는 실제 로그 스트림을 저장할 저장소 혹은 목적지 정보입니다.  

앱 프로텍트 WAF 정책 파일을 만들어 /etc/nginx/AppProtectTransparentPolicty.json에 저장합니다.  

```
{
    "policy": {
        "name": "transparent_policy",
        "template": { "name": "POLICY_TEMPLATE_NGINX_BASE" },
        "applicationLanguage": "utf-8",
        "enforcementMode": "transparent"
    }
}
```

이 정책 파일은 엔진엑스의 기본 앱 프로텍트 WAF 정책 템플릿을 사용하며 정책 이름을 transparent_policy로 지정합니다. enforcementMode를 transparent로 설정해 엔진엑스 플러스가 차단 조건에 맞는 요청을 발결하더라도 차단하지 않고 로그만 남기도록 해둡니다. transparent 모드는 정책을 실제 서비스 트래픽에 적용하기 전에 시험해보는 데 매우 유용합니다.  

시험에서 문제가 없었고 실제로 요청을 차단하려면 enforcementMode를 blocking으로 변경합니다. 이 정책 파일은 /etc/nginx/AppProtectBlockingPolicy.json로 저장합시다. 정책 파일을 변경하려면 엔진엑스 플러스 설정의 app_protect_policy_file 지시자를 갱신합니다.  

```
{
    "policy": {
        "name": "blocking_policy",
        "template": { "name": "POLICY_TEMPLATE_NGINX_BASE" },
        "applicationLanguage": "utf-8",
        "enforcementMode": "blocking"
    }
}
```

앱 프로텍트 WAF 모듈이 제공하는 보안 기능을 활성화하려면 찾고자 하는 보안 위반 사항에 대한 처리 방법을 violations 항목에 정의합니다.  

```
{
    "policy": {
        "name": "blocking_policy",
        "template": { "name": "POLICY_TEMPLATE_NGINX_BASE" },
        "applicationLanguage": "utf-8",
        "enforcementMode": "blocking",
        "blocking-settings": {
            "violations": [
                {
                    "name": "VIOL_JSON_FORMAT",
                    "alarm": true,
                    "block": true
                },
                {
                    "name": "VIOL_PARAMETER_VALUE_METACHAR",
                    "alarm": true,
                    "block": false
                }
            ]
        }
    }
}
```

예시는 정책 파일에 두 가지 위반 사항에 대한 정책을 추가합니다. 추가된 항목 중 VIOL_PARAMETER_VALUE_METACHAR 위반은 요청을 차단하지 않고 경고만 보내는 반면, VIOL_JSON_FORMAT 위반은 경고와 차단을 모두 수행한다는 점에 주목합니다. 이를 통해 enforcementMode에 정의된 차단(blocking) 정책을 덮어쓸 수 있습니다. 다만 enforcementMode가 transparent로 지정돼 있으면 violcations에 지정된 규칙보다 enforcementMode가 우선순위를 갖게 되니 주의합니다.  

이제 엔진엑스 플러스를 정책 적용에 대한 로그 파일을 남기도록 /etc/nginx/log-default.json을 설정합니다.  

```
{
    "filter":{
        "request_type":"all"
    },
    "content":{
        "format":"default",
        "max_request_size":"any"
        "max_message_soze:"5k"
    }
}
```

이 로그 설정은 엔진엑스 플러스 설정에 app_protect_security_log 지시자를 추가해 사용할 수 있으며 앱 프로텍트 WAF 모듈의 동작에 대한 로그를 남기는 데 필요합니다.  

앱 프로텍트 WAF 모듈을 사용하면 엔진엑스 플러스의 웹 방화벽이 가진 공격 룰 정의(definition)가 모두 활성화됩니다. 공격 룰 정의는 F5(엔진엑스의 모회사로 보안 어플라이언스, 네트워크 장비, 클라우드 보안 서비스 등을 제공)에서 제공하는 보안 제품인 Advanced F5 Application Security에서 제공되며 실제 필드에서 시험되고 검증된 광범위한 웹 방화벽 공격 시그니처(attack signature)이므로 신뢰도가 높습니다. 엔진엑스 플러스 설치 시 공격 시그니처를 추가하면 엔진엑스 플랫폼의 민첩함과 F5 Application Security의 높은 보안성을 동시에 활용할 수 있습니다.  

모듈이 설치되고 활성화된 후 대부분의 설정은 정책 파일을 통해 진행됩니다. 이 절에서 살펴본 정책 파일들은 차단, 모니터링, transparent 모드를 구성하는 방법과 violations를 사용해 어떻게 설정을 적용하고 오버라이드하는지 보여줍니다. 참고로 violations를 사용해 어떻게 설정을 적용하고 오버라이드하는지 보여줍니다. 참고로 violations는 엔진엑스 플러스가 제공하는 여러 공격 보호 방법 중 하나이며 HTTP 표준 준수(HTTP Compliance), 회피 기술(Evasion Technique), 공격 시그니처(Attach Signature)[OWASP가 선정한 사위 10개 공격 시그니처에 대한 방어 정책을 활성화], 서버 기술(Server Technology)[특정 운영체제나 애플리케이션 혹은 서버에 대한 공격 시그니처의 집합], 데이터 가드(Data Guard)[신용카드 번호나 미국의 사회 안전 보장 번호 같은 내용이 응답에 포함되는지 확인하고 마스킹(masking)하는 방어 정책으로 기본은 비활성화], 등 다양한 보호 방법이 제공됩니다. 앱 프로텍트 WAF 모듈의 로그를 남기는 데는 엔진엑스 플러스 로깅 형식을 사용하며 로그는 파일로 생성하거나 로컬 환경의 /dev/stderr로 보냅니다. 혹은 원격지에 구성된 별도의 로그 수신 서비스를 사용할 수도 있습니다.  

엔진엑스 컨트롤러(NGINX Controller) ADC를 사용한다면 엔진엑스 컨트롤러 앱 시큐리티(App Security) 컴포넌트를 통해 엔진엑스 앱 프로텍트 WAF 기능을 활성화할 수 있으며 웹 인터페이스를 통해 웹 방화벽의 지표를 시각화할 수 있습니다.  

+ 엔진엑스 앱 프로텍트 WAF 모듈 관리자 가이드: https://oreil.ly/JEOqg
+ 엔진엑스 앱 프로텍트 WAF 모듈 설정 가이드: https://oreil.ly/eoeq7
+ 엔진엑스 컨트롤러 앱 시큐리티 가이드: https://oreil.ly/pBZyh
+ 엔진엑스 앱 프로텍트 DoS 배포 가이드: https://oreil.y/dEtWU  

### 8. HTTP/2  
<br/>

#### 8.0 소개  
<br/>

HTTP/2는 HTTP 프로토콜의 주요 개정판입니다. 변경 사항은 대부분 단일 TCP 연결을 통한 모든 요청과 응답의 멀티플렉싱(multiplexing) 같은 전송 계층 변화에 집중돼 있습니다. HTTP 헤더 압축을 통해 트래픽을 보다 효율적으로 전송하고 각 요청에 중요도를 부여할 수 있게 됐으며, 그 외에도 서버가 요청받지 않은 리소스도 클라이언트로 보낼 수 있도록 서버 푸시(server push)에 대한 지원이 추가됐습니다.  

#### 8.1. 기본 설정  
<br/>

엔진엑스 서버 설정에서 HTTP/2를 활성화합니다.  

```
server {
    listen 443 sll http2 default_server;
    ssl_certificate server.crt;
    ssl_certificate_key server.key;
}
```

HTTP/2를 활성화하기 위해 listen 지시자에 http2 매개변수를 추가합니다. HTTP/2 프로토콜에 반드시 SSL/TLS로 보안된 연결을 사용해야 하는 것은 아니지만 많은 HTTP/2 클라이언트가 HTTP/2 사용 시 반드시 암호화된 연결을 사용하도록 하고 있습니다. 또한 TLS 1.2를 지원하는 몇몇 암호화 알고리즘이 HTTP/2 프로토콜에서 허용되지 않는다는 단점도 있습니다. 다행히 엔진엑스가 기본으로 사용하는 암호화 알고리즘은 HTTP/2의 차단 목록에 포함되지 않습니다. TLS의 애플리케이션 계층 프로토콜 협상(Application-Layer Protocol Negotiation, ALPN)은 클라이언트와 서버 사이의 추가적인 라운드 트립 타임(round trip time, RTT)을 줄이기 위해 애플리케이션 계층에서 프로토콜 협상을 하도록 해줍니다. 준비한 HTTP/2 셋업에 문제가 없는지 검증하려면 크롬이나 파이어폭스에 플러그인을 설치하거나 명령줄 도구인 nghttp를 이용해 웹 사이트가 HTTP/2를 사용하는지 확인합니다.  

+ HTTP/2 프로토콜 RFC 표준에 기재된 차단 암호화 스위트 목록: https://oreil.ly/T6mD1
+ HTTP/2와 SPDY 프로토콜 사용 유무를 보여주는 크롬 브라우저 플러그인: https://chorme.google.com/webstore/detail/http-indicator/hgcombcacfkptfiphlmnhpppcjgmbl
+ HTTP/2 사용 유무를 보여주는 파이어폭스 브라우저 애드온: https://mzl.la/2A4LT4o  

#### 8.2. gRPC  
<br/>

엔진엑스를 이용해 gRPC 연결을 프록시합니다.  

```
server {
    listen 80 http2;
    location / {
        grpc_pass grpc://backend.local:50051;
    }
}
```

이 설정에서 엔진엑스는 암호화되지 않은 HTTP/2 트래픽을 80포트로 수신하고, 50051 포트를 사용하는 backend.local 서버로 요청을 프록시합니다. grpc_pass 지시자는 엔진엑스가 사용자 요청을 gRPC 호출로 다루도록 합니다. 서버 이름 앞에 grpc:// 문자열은 붙이지 않아도 무방하지만, 그러면 백엔드 서버와의 통신이 암호화되지 않았음을 직접적으로 나타내게 됩니다.  

클라이언트와 엔진엑스 구간에서 TLS 암호화를 활용하면서 사용자 요청을 애플리케이션 서버로 보내기 전에 TLS 세션을 종료시키려면 SSL과 HTTP/2를 활성화합니다.  

```
server {
    listen 443 ssl http2 default_server;
    ssl_certificate     server.crt;
    ssl_certificate_key server.key;
    location / {
        grpc_pass grpc://backend.local:50051;
    }
}
```

이 설정은 엔진엑스에서 TLS 세션을 종료시키고 암호화되지 않은 HTTP/2 연결을 사용해 업스트림 애플리케이션으로 gRPC 통신을 수행합니다.  

엔진엑스가 애플리케이션 서버로 향하는 gRPC 통신에 종단간(end-to-end) 트래픽 암호화를 제공하도록 하려면 grpc_pass 지시자가 grpcs://를 사용하도록 수장하면 됩니다. HTTPS에서처럼 보안 통신을 나타내는 s를 추가했다는 점을 기억합시다.  

엔진엑스는 패키지, 서비스, 메서드가 포함된 gRPC URI에 따라 서로 다른 백엔드 서비스로 요청을 전달할 수 있습니다. 이때 location 지시자를 활용합니다.  

```
location /mypackage.service1 {
    grpc_pass grpc://$grpc_service1;
}
location /mypackage.service2 {
    grpc_pass grpc://$grpc_service2;
}
location / {
    root /usr/share/nginx/html;
    index index.html index.htm;
}
```

예시 설정은 location 지시자를 사용해서 수신하는 HTTP/2 트래픽을 경로에 따라 서로 다른 gRPC 서비스로 전달하며 정적인 콘텐츠는 별도의 location 분기를 통해 제공합니다. mypackage.service1에 대한 메서드 호출은 grpc_service1 변숫값을, mypackage.service2에 대한 메서드 호출은 grpc_service2 변숫값을 이용해 목적지를 설정합니다. 각 변수는 백엔드 서버의 호스트명이나 IP 주소 그리고 포트 번호를 포함합니다. 마지막 location 블록은 / 경로에 대한 요청을 처리하며 HTTP 호출과 정적인 콘텐츠 요청을 담당합니다. 마지막 location 블록은 / 경로에 대한 요청을 처리하며 HTTP 호출과 정적인 콘텐츠 요청을 담당합니다. 이는 엔진엑스가 어떻게 동일한 HTTP/2 엔드포인트와 경로에서 gRPC인 요청과 gRPC가 아닌 요청을 처리하는지 보여줍니다.  

gRPC 요청에 대한 부하분산은 gRPC가 아닌 HTTP 트래픽에 대한 부하분산과 비슷하게 설정합니다.  

```
upstream grpcservers {
    server backend1.local.50051; server backend2.local.50051;
}

server {
    listen 443 ssl http2 default_server;
    ssl_certificate     server.crt;
    ssl_certificate_key server.key;
    location / {
        grpc_pass grpc://grpcservers;
    }
}
```

upstream 블록은 gRPC에 대해서도 HTTP 트래픽에 대한 방식과 동일하게 동작합니다. 단, grpc_pass 지시자를 통해 upstream을 참조한다는 차이가 있습니다.  

엔진엑스는 gRPC 호출 수신, 프록시, 부하분산, 경로 지정, 암호화 종료 등을 할 수 있습니다. gRPC 모듈은 엔진엑스가 gRPC 호출 헤더를 설정 및 변경하거나 버리도록 하고 요청에 대한 타임아웃과 업스트림에 대한 SSL/TLS 명세를 설정합니다. gRPC 통신은 HTTP/2 프로토콜을 통해 이뤄지므로 엔진엑스가 gRPC가 아닌 웹 트래픽을 같은 엔드포인트에서 받도록 설정할 수 있습니다.  

#### 8.3. HTTP/2 서버 푸시  
<br/>

엔젠엑스의 HTTP/2 서버 푸시 기능을 사용합니다.  

```
server {
    listen 443 ssl http2 default_server;
    ssl_certificate     server.crt;
    ssl_certificate_key server.key;
    root /usr/share/nginx/html;
    location = /demo.html {
        http2_push /style.css;
        http2_push /image1.jpg;
    }
}
```

HTTP/2 서버 푸시를 사용하려면 서버가 HTTP/2를 사용하도록 설정합니다. http2_push 지시자를 사용해 엔진엑스가 특정 파일을 선점적으로 클라이언트에 보내도록 할 수 있습니다. 매개변수로는 전달할 파일의 전체 URI 경로를 받습니다.  

엔진엑스는 프록시된 애플리케이션 서버의 응답이 Link 헤더를 갖고 있으면 리소스를 자동으로 클라이언트로 푸시할 수 있습니다. Link 헤더는 엔진엑스가 지정된 리소스를 프리로드(preload)하도록 해줍니다. 기능을 사용하려면 엔진엑스 설정에 http2_push_preload on을 추가합니다.  

### 9. 정교한 스트리밍  
<br/>

#### 9.0. 소개  
<br/>

#### 9.1. MP4와 FLV 서비스하기  
<br/>

http 컨텍스트의 location 블록을 이용해 .mp4 또는 .flv 비디오 파일을 서비스합니다. 엔진엑스는 프로그레시브 다운로드(progressive download)나 HTTP 의사스트리밍(pseudostreaming)을 통해 스트리밍하며 탐색(seeking)을 지원합니다.  

```
http {
    server {
        # ...

        location /videos/ {
            mp4;
        }
        location = \.flv$ {
            flv;
        }
    }
}
```

예시에서 첫 번째 location 블록은 videos 디렉터리에 저장된 파일이 MP4 형식이고 프로그레시브 다운로드를 통해 스트리밍할 수 있음을 엔진엑스 알려줍니다. 두 번째 location 블록은 엔진엑스가 .flv 확장자를 가진 파일을 FLV 형식으로 인식하고 HTTP 의사스트리밍 지원을 통해 스트리밍하도록 합니다.  

엔진엑스를 통해 비디오나 오디오 파일을 스트리밍하려면 간단히 지시자 하나만 사용하면 됩니다. 프로그레시브 다운로드를 클라이언트는 미디어 파일 다운로드가 끝나기 전에 재생을 시작할 수 있습니다. 엔진엑스는 비디오와 오디오 파일에서 다운로드가 완료되지 않은 지침에 대해서도 탐색 기능을 제공합니다.  

#### 9.2. HLS 스트리밍(엔진엑스 플러스)  
<br/>

+ H.264/AAC로 인코딩돼 MP4 형식으로 만들어진 파일을 HTTP 라이브 스트리밍으로 스트리밍하기  

엔진엑스 플러스의 HLS 모듈을 활용해 실시간으로 파일을 작게 쪼개고(segmentation), 패킷으로 만들며(packetization), 멀티플렉싱(multiplexing)하고, HLS의 규격에서 사용하는 미디어 파일 조각의 버퍼링과 같은 인수를 지정합니다.  

```
location /his/ {
    his; # HLS 모듈을 사용합니다

    # HLS 형식 파일이 저장된 경로를 지정합니다
    alias /var/www/video;

    # HLS 매개변수를 선언합니다
    hls_fragment            4s;
    hls_buffers             10 10m;
    hls_mp4_buffer_size     1m;
    hls_mp4_max_buffer_size 5m;
}
```

예시의 location 블록에 따라 엔진엑스는 /var/www/video 경로에 4초 단위로 나뉘어 저장된 HLS 미디어 파일을 스트리밍합니다. HLS 버퍼는 10MB 크기로 10개 생성합니다. 초기 MP4 버퍼 크기는 1MB로 지정하며 최대 5MB까지 허용합니다.  

엔진엑스 플러스의 HLS 모듈을 사용해 MP4 미디어 파일을 실시간으로 트랜스코딩(transcoding)하고 멀티플렉싱할 수 있습니다. 여러 지시자를 통해 미디어 파일을 어떻게 쪼개고 버퍼에 담을지 제어하고, location 블록은 미디어 파일을 HLS 핸들러를 통해 HLS로 스트리밍할 수 있도록 설정합니다. HLS 미디어 조각 파일은 초 단위로 설정하며 엔진엑스는 지정한 시간 길이를 참조해 파일을 나눕니다. hls_buffers 지시자에는 버퍼의 개수와 크기를 지정해서 버퍼에 쌓아둘 데이터의 크기를 설정합니다. 클라이언트는 hls_mp4_buffer_size 지시자에 지정한 크기만큼 조각 파일을 받은 후에 미디어 파일 재생을 시작할 수 있습니다. 하지만 상황에 따라 비디오 파일에 대한 메타데이터가 초기 버퍼 크기보다 클 수 있는 이때는 버퍼를 더 크게 설정해야 합니다. 버퍼 크기는 hls_mp4_max_buffer_size 지시자에 지정한 상한선을 넘을 수 없습니다. 엔진엑스는 이러한 버퍼링 관련 변수들을 사용해 사용자 경험을 최적화하며 각 변수에 대한 최적값은 시청자 규모와 미디어 파일의 특성에 따라 달라집니다. 예를 들어, 미디어 파일이 크고 시청자가 빠른 인터넷 회선을 사용한다면 최대 버퍼 크기를 늘리거나 미디어 파일 조각을 크게 만들 필요가 있습니다. 이를 통해 시정자는 미디어 파일의 메타데이터 정보를 문제없이 다운로드하고 더 크게 만들어진 파일을 받을 수 있습니다.  

#### 9.3. HDS 스트리밍(엔진엑스 플러스)  
<br/>

+ 어도비(Adobe)의 HDS 형식으로 작게 나뉜 미디어 콘텐츠 지원하기  

엔진엑스 플러스의 F4F(fragmented FLV files) 모듈을 사용해 어도비의 가변 스트리밍 형식인 HDS로 만들어진 콘텐츠를 지원합니다.  

```
location /video/ {
    alias /var/www/transformed_video;
    f4f;
    f4f_buffer_size 512k;
}
```

예시는 엔진엑스 플러스가 F4F 모듈을 활용해 미리 작은 파일 조각으로 나뉘어 디스크에 저장된 미디어 파일을 사용자에게 제공하도록 합니다. 인덱스 파일(f4x)을 읽을 때 사용하는 버퍼는 512KB로 설정합니다.  

엔진엑스 플러스의 F4F 모듈은 이미 작게 나뉜 미디어 파일을 사용자에게 제공합니다. 설정하려면 간단히 F4F 핸들러를 HTTP location 블록 안에 배치합니다. f4f_buffer_size 지시자는 가공된 미디어 콘텐츠의 인덱스 파일(f4x)에 대한 버퍼 크기를 설정합니다.  

#### 9.4. 대역폭 제한하기(엔진엑스 플러스)  
<br/>

+ 시청 경험을 해치지 않는 선에서 사용자가 미디어 콘텐츠를 내려받는 네트워크 대역폭을 제한하기  

엔진엑스 플러스가 제공하는 MP4 미디어 파일에 대한 비트레이트 제한 기능을 사용합니다.  

```
location /video/ {
    mp4;
    mp4_limit_rate_after 15s;
    mp4_limit_rate       1.2;
}
```

이 설정은 콘텐츠를 내려받는 사용자가 비트레이트 제한이 적용되기 전 15초간 대역폭 제한 없이 콘텐츠를 다운로드하도록 합니다. 15초가 지나면 미디어 콘텐츠 비트레이트의 120%까지만 대역폭을 사용하도록 하며, 이를 통해 재생 속도보다 빠른 다운로드 속도를 제공합니다.  

엔진엑스 플러스의 비트레이트 제한 기능은 서버가 제공하는 미디어 콘텐츠를 기반으로 동적으로 대역폭을 제한하고 사용자 경험을 해치지 않는 속도로 파일을 다운로드하도록 합니다. MP4 핸들러는 특정 location 블록이 MP4 미디어 파일을 스트리밍하도록 합니다. mp4_limit_rate_after와 같은 지시자는 엔진엑스가 특정 시간(초 단위)이 지난 후에만 전송률을 제한하도록 합니다. 또 다른 전송률 제한 지시자 mp4_limit_rate는 전송률을 미디어 콘텐츠의 비트레이트에 따라 상대적으로 조정하도록 합니다. 예를 들어, mp4_limit_rate 지시자에 1을 지정하면 콘텐츠의 비트레이트와 동일한 전송률로 콘텐츠를 전송합니다. 따라서 mp4_limit_rate 지시자를 1보다 큰 값으로 지정해 사용자가 충분한 분량의 미디어 파일을 미리 버퍼에 저장하게 함으로써 미디어 재생에 불편함이 없도록 해야 합니다.  

### 10. 클라우드 환경 배포  
<br/>

#### 10.0. 소개  
<br/>

#### 10.1. AWS 환경에서 자동 프로비저닝 구현하기  
<br/>

아마존 일래스틱 컴퓨트 클라우드(Amazon Elastic Compute Cloud, EC2)의 UserData와 미리 만들어둔 아마존 머신 이미지(Amazon Machine Image, AMI)를 활용합니다. 엔진엑스와 필요한 패키지들이 설치된 AMI를 만듭니다. EC2의 UserData를 이용하면 런타임 시 환경에 맞는 설정을 할 수 있습니다.  

AWS 환경에 서버를 프로비저닝할 때는 다음 세 가지 패턴을 고려합니다.  

+ 부팅 시 프로비저닝하기  
일반적인 리눅스 운영체제 이미지로 서버를 시작한 후 부팅 시 설정 관리나 셸 스크립트를 이용해 엔진엑스를 설치하고 설정합니다. 이 방식은 느리고 오류가 발생할 가능성이 많습니다.

+ 완전히 준비된 AMI 사용하기  
서버에 엔진엑스와 관련된 패키지를 완전히 설치 및 설정한 뒤 AMI를 생성합니다. 이 방식은 부팅 속도가 매우 빠르며 원하는 형상으로 만들어져 있어 정확합니다. 하지만 상대적으로 유연하지 못하고 이미지가 많아지면 관리가 어려워집니다.

+ 부분적으로 준비된 AMI 사용하기  
앞서 설명한 두 가지를 섞어놓은 방식으로 소프트웨어가 설치된 상태로 AMI가 만들어졌고 부팅 시 완경 설정이 완료됨을 의미하며 완전히 준비된 AMI를 사용하는 패턴보다 유연하고 부팅 시 프로비저닝하는 방식보다 빠릅니다.  

부분적으로 준비된 것이든 완전히 준비된 것이든 AMI를 생성하고 나면 생성 과정 자체를 자동화하고 싶을 겁니다. 다음과 같은 도구는 AMI 생성 파이프라인을 만드는 데 유용합니다.  

+ 설정 관리 도구 활용하기  
설정 관리 도구는 서버의 목표 상태를 코드로 정의합니다. 목표 상태란 어떤 엔진엑스 버전을 설치하고 구동할지, 어떤 사용자 계정으로 구동할지, 사용할 DNS 리졸버의 주소는 무엇이며 어떤 업스트림 서버로 요청을 프록시할지 등입니다. 설정 관리 도구를 위한 코드는 소프트웨어 개발 프로젝트처럼 소스 코드가 통제되고 버저닝합니다. 널리 사용하는 설정 관리 도구는 셰프, 앤서블 등이 있습니다.  

+ 하시코프에서 만든 패커  
패커(packer)는 어떤 가상화 환경이나 클라우드 플랫폼에서든 설정 관리 도구 실행을 자동화하며 코드가 성공적으로 실행되고 나면 서버의 이미지 파일을 생성합니다. 패커는 기본적으로 여러분이 선택한 플랫폼에 가상 머신을 생성하고 가상 머신에 SSH로 접근해 프로비저닝한 뒤 이미지를 만듭니다. 패커를 이용해 설정 관리 도구를 실행하고 서버의 이미지 파일을 지정한 규격으로 만들 수 있습니다.  

부팅 시 환경 설정을 프로비저닝하려면 아마존 EC2 UserData를 활용해 인스턴스가 처음 부팅될 때 필요한 명령을 수행합니다. 부분적으로 준비된 AMI를 사용한다면 패커가 부팅 시 서버 실행 환경과 관련된 항목들을 설정하도록 합니다. 실행 환경 기반의 설정은 요청을 수신할 서버의 이름, 사용할 DNS 리졸버, 프록시할 도메인명 혹은 사용할 업스트림 서버 풀 등이 될 수 있습니다. UserData는 base64로 인코딩된 문자열로, 서버가 최초 부팅될 때 다운로드되고 실행됩니다. UserData는 base64로 인코딩된 문자열로, 서버가 최초 부팅될 때 다운로드되고 실행됩니다. UserData는 AMI가 부팅될 때 사용되는 다른 환경 파일과 마찬가지로 매우 단순하며 AMI에서 사용 가능한 프로그래밍 언어로 작성한 스크립트로 만들어집니다. UserData를 배시(bash) 스크립트로 만들어 특정 변수를 선언하거나 값을 받아오고, 설정 관리 도구로 값을 전달하는 것은 매우 일반적인 사용 방법입니다. 설정 관리 도구는 시스템이 바르게 설정됐는지 확인하고, 환경 변숫값을 통해 설정 파일을 템플릿하고, 서비스를 리로드합니다. UserData의 내용이 실행되고 나면 엔진엑스 서버는 매우 신뢰할 수 있는 방식으로 설정됩니다.  

#### 10.2. AWS ELB를 쓰지 않고 엔진엑스 노드로 라우팅하기  
<br/>

+ 엔진엑스 앞에 로드 밸런서를 두지 않고 고가용성을 보장하기 위해 엔진엑스 페일오버(failover) 설정을 만들거나 여러 엔진엑스 노드로 트래픽을 분산하기  

AWS의 라우트53(Route 53) DNS 서비스를 이용해 여러 엔진엑스 노드로 요청을 분산하거나 헬스 체크 설정을 통해 구성된 엔진엑스 페일오버 서버로 요청을 분산합니다.  

DNS는 오랫동안 여러 서버 간 부하를 균형 있게 분산해왔으며 인프라 환경이 클라우드로 변화함에도 변함없이 그 역할을 수행합니다. AWS의 라우트53 서비스는 DNS와 관련된 여러 기능을 제공하며, 기능은 API로 제어됩니다. 라우트53은 일반적인 DNS 트릭을 모두 사용할 수 있습니다. 예를 들어, 단일 A 레코드에서 IP 주소를 여러 개 사용하거나 가중치를 부여한 A 레코드를 쓸 수 있습니다. 이러한 방법은 엔진엑스 노드를 여러 개 운영할 때 모든 노드가 부하를 균등하게 맡아 처리하게끔 하는 데 유용합니다. 단일 A 레코드에 여러 IP 주소가 사용될 때는 라운드 로빈 알고리즘을 사용합니다. 가중치가 들어간 분산 방법은 A 레코드로 등록된 AP 주소 각각에 가중치를 부여함으로써 부하가 균등하지 않게 분산되도록 합니다.  

라우트53은 헬스 체크라는 흥미로운 기능도 제공합니다. 라우트53이 서버와 TCP 연결을 맺거나 HTTP/HTTPS 요청을 보내 서버 상태를 모니터링하도록 설정할 수 있습니다. 헬스 체크는 IP 주소나 호스트명, 포트, URI 경로, 시험 간격, 모니터링, 지리적 위치 등을 활용해 설정합니다. 라우트53은 특정 IP 주소에 대해 헬스 체크 시험이 실패하기 시작하면 DNS 요청에 대한 응답에서 해당 IP 주소에 대해 헬스 체크 시험이 실패하기 시작하면 DNS 요청에 대한 응답에서 해당 IP 주소를 제외합니다. 고가용성이 필요하다면 주 IP 주소에 대한 헬스 체크 시험 실패 시 두 번째 IP 주소를 사용하도록 라우트53을 설정합니다.  

라우트53은 지역 기반 라우팅 기능을 제공해 사용자가 가장 가까운 엔진엑스 노드를 사용하고 낮은 지연 시간으로 서버에 접근하도록 해줍니다. 지역 기반으로 라우팅하면 사용자는 물리적으로 가장 가까우면서 문제가 없는 서버로 연결됩니다. 액티브-액티브 설정으로 여러 인프라를 구성해 사용 중이라면 헬스 체크로 문제가 확인되면 자동으로 다른 지역에 있는 서버를 사용합니다.  

라우트53을 이용해 오토스케일링(Auto Scaling) 그룹(AWS의 자동화 기능으로, 서버의 지정된 수치를 초과하거나 하회하면 자동으로 서버를 추가 배포하거나 배포한 서버를 종료)으로 구성된 엔진엑스 노드로 트래픽을 보내는 경우 DNS 레코드를 생성하고 삭제하는 작업을 자동화하고 싶을 겁니다. 엔진엑스 노드가 확장될 때 엔진엑스 서버를 라우트53에 추가하고 삭제하는 작업을 자동화하려면 아마존의 오토스케일링 수명 주기 후크(lifecycle hook)를 이용해 엔진엑스 서버가 직접 IP 주소를 라우트53에 추가 및 삭제하도록 스크립트를 동작시키거나 아마존 람다(Amazon Lamda) 제품을 이용해 스크립트를 수행합니다. 스크립트들은 아마존 명령줄 인터페이스(command-line interface, CLI)나 아마존 소프트웨어 개발 키트(software development kit, SDK)를 이용해 라우트53 API를 호출해서 엔진엑스 서버 IP 주소를 추가 및 삭제하고, 서버가 부팅되거나 종료되기 전에 헬스 체크를 추가 및 삭제합니다.  

+ AWS 라우트53과 엔진엑스 플러스로 글로벌 서버 부하분산 구현하기: https://oreil.ly/IlhWg  

#### 10.3. NLB 샌드위치  
<br/>

AWS가 제공하는 네트워크 로드 밸런서(Network Load Balancer, NLB)를 생성합니다. 콘솔을 통해 NLB를 만들면 새로운 타깃 그룹을 생성하라는 메시지가 나옵니다. 이때 타깃 그룹을 생성하지 않으면 별도로 타깃 그룹을 생성한 뒤 NLB의 리소너로 연결해야 합니다. 오픈 소스 엔진엑스가 설치된 EC2 인스턴스를 실행하는 시작 설정(launch configuration)이 구성된 오토스케일링 그룹을 생성합니다. 오토스케일링 그룹은 타깃 그룹과 연결하는 설정을 가지며 설정은 오토스케일링 그룹에 생성된 서버가 최초 기동될 때 서버를 자동으로 타깃 그룹에 등록합니다. 타깃 그룹은 NLB의 리소너로 참조됩니다. 업스트림 애플리케이션 서버를 또 다른 NLB와 타깃 그룹에 등록하고 엔진엑스가 이 NLB로 요청을 프록시하도록 설정합시다.  

NLB 샌드위치(NLB sandwich)는 오픈 소스 엔진엑스 서버를 NLB에 연결된 오토스케일링 그룹에 넣고 애플리케이션 서버의 오토스케일링 그룹을 또 다른 NLB에 배치하는 패턴입니다. NLB를 모든 서버 레이어 사이에 위치시키는 이유는 오토스케일링 그룹과 궁합이 잘 맞기 때문입니다. 오토스케일링 그룹은 그룹에 속한 서버의 헬스 체크를 수행해 트래픽을 건강한 노드로만 전달할 뿐 아니라, 자동으로 새로운 노드를 등록하며 종료되는 서버를 그룹에서 제외합니다.  

애플리케이션 서버가 엔진엑스를 빈번히 호출한다면 앞서 만든 엔진엑스용 NLB와 별개로 내부용 엔진엑스 NLB를 만들어야 합니다. 애플리케이션 서버가 앞서 만든 NLB를 통해 엔진엑스를 호출하면 네트워크를 잠시 벗어났다 다시 돌아오므로 불필요한 트래픽을 발생시킵니다. 반면에 내부용 엔진엑스 NLB를 구성하면 애플리케이션 서버와 엔진엑스 오토스케일링 그룹이 속한 네트워크를 벗어나지 않은 상태에서 요청을 수행하고 응답을 받습니다. 이는 엔진엑스가 애플리케이션 내 네트워크 트래픽의 중심이 되도록 합니다. NLB 샌드위치는 탄력적인 로드 밸런서 샌드위치(elastic load balancer sandwich)라고도 불리지만 ELB와 ALB가 7계층의 로드 밸런서인 반면 NLB는 4계층의 로드 밸런서이므로 기술적으로는 NLB 샌드위치라는 용어가 더 적합합니다. 7계층 로드 밸런서는 사용자 요청을 프록시 프로토콜(PROXY protocol)을 통해 변형하는데, 이는 엔진엑스의 기능과 중복됩니다. NLB 샌드위치는 엔진엑스 오픈 소스 버전을 사용할 때만 필요하며 엔진엑스 플러스를 사용한다면 내장된 기능을 사용할 수 있습니다.  

#### 10.4. AWS 마켓플레이스를 통해 엔진엑스 구축하기(엔진엑스 플러스)  
<br/>

#### 10.5. 애저 환경에서 엔진엑스 가상 머신 이미지 생성하기  
<br/>

리눅스 기반 운영체제 중 하나를 선택해 가상 머신을 생성합니다. 가상 머신이 부팅되면 서버에 로그인해 엔진엑스나 엔진엑스 플러스를 설치합니다. 오픈 소스로 공개된 코드를 다운로드해 빌드할지 혹은 선택한 리눅스 배포판이 제공하는 패키지 관리자를 통해 설치할지는 취향대로 선택합니다. 설치가 완료되면 필요한 엔진엑스 설정 작업을 진행하고 새로운 가상 머신 이미지를 만듭니다. 가상 머신 이미지를 만들려면 우선 가상 머신을 일반화(generalize)합니다. 일반화하려면 에러를 통해 가상 머신을 배포할 때 생성된 사용자를 제거하고, SSH를 통해 서버에 접속하고 다음 명령을 실행합니다.  

이 명령은 가상 머신이 생성될 때 애저가 만든 사용자 계정을 제거합니다. -force 옵션을 사용하면 삭제에 대한 확인(confirmation) 절차가 생략됩니다. 엔진엑스나 엔진엑스 플러스 설치와 설정이 끝나고 사용자 계정을 삭제했으면 서버에서 로그아웃합니다.  

애저 CLI를 이용해 애저 계정에 접속해서 애저 리소스 매니저(Azure Resource Manager, ARM) 모드를 사용하고 있는지 확인한 후 가상 머신 할당을 취소합니다.  

```
azure vm deallocate -g <ResourceGroupName> -n <VirtualMachineName>
```

가상 머신 할당이 취소되면 azure vm generalize 명령을 이용해 일반화합니다.  

```
azure vm generalize -g <ResourceGroupName> -n <VirtualMachineName>
```

가상 머신이 일반화되고 나면 이미지를 생성할 수 있습니다. 다음 명령은 이미지를 만들고 ARM 템플릿을 생성해 이미지를 사용하게 해줍니다.  

```
azure vm capture <ResourceGroupName> <VirtualMachineName> <ImageNamePrefix> -t <TemplateName>.json
```

명령을 수행하면 창에 이미지가 생성됐고 지정된 위치에 ARM 템플릿이 만들어졌다는 메시지가 나옵니다. 이 ARM 템플릿을 이용하면 새로 생성한 이미지를 기반으로 가상 머신을 생성할 수 있습니다. 템플릿을 사용하려면 먼저 새로운 네트워크 인터페이스를 만듭니다.  

```
azure network nic create <ResourceGroupName> <NetworkInterfaceName> <Region> --subnet-name <SubnetName> --subnet-vnet-name <VirtualNetworkName>
```

명령을 수행하면 새로운 네트워크 인터페이스가 생성되고 자세한 정보가 출력됩니다. 출력된 정보의 첫째 줄은 생성된 네트워크 인터페이스의 ID이며 ARM 템플릿에서 이 값을 활용합니다. ID를 복사해두고 다음 명령을 실행해 ARM 템플릿 기반의 디플로이먼트(deployment)를 만듭니다.  

```
azure group deployment create <ResourceGroupName> <DeploymentName> -f <TemplateName>.json
```

명령을 실행하고 화면 내용에 따라 가상 머신의 이름(vmName), 관리자 계정(adminUserName), 관리자 비밀번호(adminPassword), 네트워크 인터페이스의 ID(networkInterfaceId) 등을 입력합니다. 눈치 챘겠지만 조금 전에 복사해둔 ID로 네트워크 인터페이스 ID를 입력하면 됩니다. 입력한 변수들은 ARM 템플릿에 매개변수로 전달되고 여러분이 생성한 커스텀 엔진엑스 혹은 커스텀 엔진엑스 플러스 이미지로 가상 머신을 생성하는 데 사용됩니다. 필요한 매개변수가 모두 입력되면 애저는 커스텀 이미지로부터 가상 머신을 생성하기 시작합니다.  

애저 플랫폼에서 커스텀 이미지를 생성하면 미리 설정된 엔진엑스와 엔진엑스 플러스를 필요한 수만큼 사용할 수 있습니다. 애저 ARM 템플릿은 동일한 서버를 빠르게 안전하게 배포하도록 도와주며 필요시 반복해서 사용 가능합니다. 템플릿에서 가상 머신 이미지의 경로를 확인할 수 있으며 경로를 이용해 설정이 다른 가상 머신이나 다른 인프라 구성을 위한 가상 머신 스케일 세트를 만들 수 있습니다.  

+ 애저 크로스 플랫폼 CLI 설치하기: https://oreil.ly/cKEyU
+ 애저 크로스 플랫폼 CLI 로그인하기: https://oreil.ly/Dh2uI
+ 가상 머신 혹은 VHD 이미지 만들기: https://oreil.ly/VSwSh  

#### 10.6. 애저 환경에서 엔진엑스 스케일 세트를 통해 부하분산하기  
<br/>

내부용 혹은 외부용 애저 로드 밸런서를 생성합니다. 엔진엑스 가상 머신 이미지나 마켓플레이스의 엔진엑스 플러스 이미지를 애저 가상 머신 스케일 세트(Virtual Machine Scale Set, VMSS)로 배포합니다. 로드 밸런서와 VMSS를 배포한 뒤에는 로드 밸런서의 백엔드 서버 풀로 VMSS를 할당합니다. 트래픽을 수용할 포트와 프로토콜에 대한 부하분산 정책을 설정하고 트래픽을 백엔드 서버 풀로 전달합니다.  

고가용성을 확보하거나 피크 시간대의 부하를 과도한 리소스 투입 없이 처리하기 위해 보통 엔진엑스를 확장합니다. 애저 환경에서는 VMSS를 통해 이 작업을 수행합니다. 애저 로드 밸런서를 사용하면 확장이 필요할 때 엔진엑스 노드를 리소스 풀에 추가하거나 삭제하기가 쉬우며, 백엔드 서버 풀의 상태를 확인하고 문제없는 노드로만 트래픽을 보낼 수 있습니다. 내부 네트워크를 통해 들어오는 트래픽만 처리하려면 내부용 애저 로드 밸런서를 엔진엑스 앞에서 운용합니다. 엔진엑스가 VMSS 내의 애플리케이션 앞에 위치한 내부용 로드 밸런서로 트래픽을 프록시하도록 설정하면 로드 밸런서가 백엔드 서버 풀에 서버를 쉽게 추가하거나 삭제할 수 있습니다.  

#### 10.7. 애저 마켓플레이스의 이미지로 서버 배포하기  
<br/>

애저 마켓플레이스에서 엔진엑스 플러스 가상 머신 이미지를 배포합니다.  

(1) 애저 대시보드에서 'New' 아이콘을 선택하고 검색창에 'NGINX'를 검색합니다. 검색 결과가 화면에 보일 때까지 기다립니다.
(2) 화면에 출력된 목록에서 엔진엑스 사에서 배포한 엔진엑스 플러스 가상 머신 이미지를 선택합니다.
(3) 배포 모델을 선택하라는 질문이 나오면 'Resource Manager' 옵션을 선택하고 'Create' 버튼을 누릅니다.
(4) 이어서 가상 머신 이름, 디스크 형식, 기본 사용자 계정 이름과 비밀번호 혹은 SSH 키 쌍의 공개키 정보, 사용하려는 리소스 그룹과 위치 정보를 입력합니다.
(5) 입력 항목을 모두 채웠으면 'OK' 버튼을 눌러 입력된 내용을 확인합니다.
(6) 가상 머신 크기를 선택하고 'Select' 버튼을 누릅니다.
(7) 앞서 선택한 리소스 그룹의 기본 설정값을 변경할 수 있습니다. 필요시 값을 변경하고 'OK' 버튼을 누릅니다.
(8) 2~7단계에서 입력한 내용에 문제가 없는지 확인합니다. 설정한 내용을 ARM 템플릿 양식으로 다운로드하면 추후 규격이 동일한 리소스를 JSON 템플릿을 활용해 쉽게 생성할 수 있습니다.
(9) 템플릿을 확인하고 다운로드했으면 'OK' 버튼을 눌러 구매 화면으로 이동합니다. 구매 화면에서는 지정한 가상 머신의 스펙을 사용할 때 지불해야 하는 비용을 확인합니다. 'Purchase' 버튼을 누르면 구매가 완료되고 엔진엑스 플러스 서버가 곧 부팅됩니다.  

애저와 엔진엑스는 애저를 통해 몇 가지 설정값을 입력하는 것만으로 엔진엑스 플러스 가상 머신을 쉽게 만들도록 해줍니다. 애저 마켓플레이스는 사용한 라이선스만큼 비용을 지불하는 구조로 엔진엑스 플러스를 사용하는 훌륭한 방법입니다. 이 방법으로 엔진엑스 플러스의 여러 기능을 사용해보거나 이미 구입한 엔진엑스 플러스 서버의 용량이 부족할 때 요청 기반으로 서버를 증설할 수 있습니다.  

#### 10.8. 구글 컴퓨트 엔진에서 엔진엑스 배포하기  
<br/>

구글 컴퓨트 엔진에서 새로운 가상 머신을 시작합니다. 가상 머신 이름과 머신 타입, 부팅 디스크를 선택합니다. 신원 및 접근 관리(identity and access management, IAM), 방화벽, 필요한 고급 옵션을 설정합니다. 설정이 끝나면 가상 머신을 생성합니다.  

가상 머신이 생성되면 SSH나 구글 클라우드 셸을 이용해 서버에 접속합니다. 생성한 가상 머신의 운영체제가 제공하는 패키지 매니저를 통해 엔진엑스나 엔진엑스 플러스를 설치합니다. 엔진엑스를 필요에 따라 설정하고 리로드합니다.  

엔진엑스는 구글 컴퓨트 엔진이 제공하는 시작 스크립트(startup script)로도 설치할 수 있습니다. 시작 스크립트로 설치하면 가상 머신을 생성할 때 고급 설정을 할 수 있습니다.  

구글 컴퓨트 엔진은 즉시 설정 가능한 가상 머신을 제공합니다. 가상 머신은 띄우기가 매우 쉽고 다양하게 활용 가능하며 구글 컴퓨트 엔진은 가상화된 클라우드 환경에서 네트워크와 컴퓨팅을 제공합니다. 구글 컴퓨트 가상 머신을 활용하면 언제 어디서든 엔진엑스 서버가 제공하는 모든 기능을 활용할 수 있습니다.  

#### 10.9. 구글 컴퓨트 이미지 생성하기  
<br/>

가상 머신 인스턴스에 엔진엑스를 설치하고 설정한 뒤 부팅 디스크의 자동 삭제 상태를 false로 변경합니다. 디스크의 자동 삭제 상태를 설정하려면 가상 머신을 수정해야 하는데, 디스크 설정 하위에 위치한 수정 페이지에서 'Delete boot disk when instance is deleted'라고 적힌 체크 박스를 해제하고 가상 머신 설정을 저장합니다. 인스턴스에 대한 자동 삭제 상태를 false로 변경했으면 인스턴스를 삭제합니다. 삭제할 때 부팅 디스크를 삭제하는 체크 박스는 선택하지 않도록 주의합니다. 이 절차를 통해 가상 머신과 연결되지 않은 엔진엑스가 설치된 부팅 디스크를 확보할 수 있습니다.  

인스턴스가 삭제되고 가상 머신에 연결되지 않은 부팅 디스크를 확보했으면 구글 컴퓨트 엔진에서 사용할 수 있는 이미지를 생성합니다. 구글 컴퓨트 엔진 콘솔의 이미지 섹션에서 'Create Image' 메뉴를 선택하고 생성할 이미지의 이름, 패밀리, 설명, 암호화 형식, 소스 형식을 설정합니다. 소스 형식은 디스크이며 앞서 가상 머신에서 분리한 부팅 디스크를 선택하면 됩니다. 'Create' 버튼을 누르면 구글 컴퓨트 엔진이 소스 옵션으로 지정된 부팅 디스크로부터 이미지를 생성합니다.  

구글 클라우드 이미지(Google cloud image)를 이용해 앞서 생성한 서버와 동일한 부팅 디스크를 갖는 가상 머신을 생성할 수 있습니다. 새로운 가상 머신 인스턴스 생성 시 사용한 이미지는 앞서 만든 가상 머신의 설정값을 그대로 가지므로 이 이미즈를 통해 생성된 모든 인스턴스는 동일하다고 봐도 무방합니다. 가상 머신 부팅 시 동적으로 패키지를 설치하면서 사설 저장소에 대한 버전 잠금을 사용하지 않으면 패키지의 버전이나 업데이트가 상용 서비스 환경에서 실행되기 전에 검증되지 못할 수 있습니다. 가상 머신 이미지를 활용하면 서버에서 실해되는 모든 패키지가 시험한 버전 그대로 사용되도록 보장되므로 서비스 신뢰도가 높아집니다.  

+ 사용자 커스텀 이미지 작성, 삭제 및 사용 중지하기: https://oreil.ly/JtnYE  

#### 10.10. 구글 앱 엔진 프록시 생성하기  
<br/>

구글 컴퓨트 클라우드에서 엔진엑스를 사용합니다. 구글 컴퓨트 엔진에서 가상 머신을 생성하거나 엔진엑스가 설치된 가상 머신 이미지를 생성하고, 이렇게 만들어진 이미지를 부팅디스크로 사용하는 인스턴스 템플릿을 만듭니다. 인스턴스 템플릿을 생성했으면 템플릿을 활용해 인스턴스 그룹을 생성합니다.  

엔진엑스가 여러분의 구글 앱 엔진 엔드포인트로 요청을 프록시하도록 설정합니다. 구글 앱 엔진은 퍼블릭 인터넷에 노출되는 리소스이므로 엔진엑스가 HTTPS를 사용해 프록시해야 합니다. 엔진엑스에서 HTTPS 연결이 종결되지 않아야 하며 엔진엑스와 구글 앱 엔진 간 통신의 보안이 보장돼야 합니다. 구글 앱 엔진은 DNS 관점에서 단일 엔드포인트를 제공하므로 엔진엑스 오픈 소스 버전 사용 시 업스트림 블록보다는 proxy_pass 지시자를 사용함으로써 업스트림 서버로 요청을 전달할 때 DNS 질의 를 하지 않아 발생하는 문제점을 줄일 필요가 있습니다. 구글 앱 엔진으로 요청을 프록시할 때는 엔드포인트를 엔진엑스에서 변수로 설정하고 proxy_pass 지시자에서 이 변수를 사용해 모든 요청에 대해 DNS 주소를 확인합시다. 엔진엑스가 DNS 주소를 확인하도록 하려면 resolver 지시자를 활용하고 여러분의 환경에 맞는 DNS 리졸버를 사용합시다. 구글은 애니캐스트(Anycast) 기반 DNS 서비스인 8.8.8.8을 누구든 사용할 수 있게 열어뒀습니다. 엔진엑스 플러스를 사용한다면 resolver 지시자를 upstream 블록에 포함된 server 지시자 안에서 사용할 수 있으며 연결에 대한 킵얼라이브(keepalive)는 물론이고 구글 앱 엔진으로 프록시할 때 업스트림 모듈이 제공하는 모든 이점을 누릴 수 있습니다.  

엔진엑스 설정을 구글 스토리지에 저장하고 인스턴스를 새로 생성해 부팅 시 설정을 다운로드하고 싶을 수도 있습니다. 이러한 방법을 이용하면 설정 내용을 포함하는 새로운 이미지를 힘들지 않아도 됩니다. 다만 엔진엑스 서버 기동 시간이 다소 길어질 수 있다는 점은 기억하기 바랍니다.  

직접 소유한 도메인을 사용하거나 애플리케이션이 HTTPS를 사용하도록 강제하고 싶을 때 엔진엑스를 구글 앱 엔진 앞에서 동작하도록 할 수 있습니다. 하지만 구글 앱 엔진은 여러분이 소유한 SSL 인증서를 업로드해 사용하도록 허용하지 않습니다. 따라서 appspot.com이 아닌 다른 도메인을 통해 애플리케이션을 제공하려면 엔진엑스가 새로운 도메인으로 들어 오는 요청을 처리하고 구글 앱 엔진으로 프록시하도록 설정합니다. 엔진엑스는 자신과 사용자 사이의 트래픽은 물론이고 자신과 구글 앱 엔진 사이의 트래픽도 암호화할 수 있습니다.  

엔진엑스로 구글 앱 엔진 앞에 놓는 또 다른 상황으로, 여러 구글 앱 엔진 애플리케이션을 같은 도메인으로 서비스하고 엔진엑스가 사용자 요청의 URI를 기반으로 구글 앱 엔진에 요청을 전달하는 경우가 있습니다. 마이크로서비스는 근래에 인기 있는 아키텍처이며 엔진엑스 같은 프록시가 트래픽을 라우팅하는 경우에 널리 사용합니다. 구글 앱 엔진은 애플리케이션 배포를 용이하게 하며 엔진엑스와 결합돼 완전한 애플리케이션 배포 플랫폼으로도 활용됩니다.  

### 11. 컨테이너와 마이크로서비스  
<br/>

#### 11.0. 소개  
<br/>

컨테이너(container)는 애플리케이션 계층에 추상화된 계층을 제공해 애플리케이션 동작에 필요한 패키지와 의존성의 설치를 배포 단계가 아닌 빌드 프로세스 단계로 옮겨줍니다. 이에 따라 엔지니어는 일련의 코드를 실행 환경에 상관없이 일정한 형태로 실행하고 배포할 수 있습니다. 컨테이너를 실행 단위로 격상시킴으로써 복잡해진 의존성과 설정으로 인한 위험을 줄일 수 있고, 따라서 많은 조직이 컨테이너를 통해 애플리케이션을 실행할 때는 일반적으로 프록시나 로드 밸런서를 비롯해 가능한 한 많은 애플리케이션 스택을 컨테이너화합니다. 엔진엑스와 엔진엑스 플러스는 쉽게 컨테이너화해 배포할 수 있으며 컨테이너화된 애플리케이션을 사용자에게 전달하기 위한 기능을 많이 제공합니다. 이 장에서는 엔진엑스와 엔진엑스 플러스 컨테이너 이미지를 만들고 컨테이너 환경에서 더 잘 동작하게 해주는 기능과 생성한 이미지를 쿠버네티스(Kubernetes)와 오픈시프트(OpenShift) 환경으로 배포하는 방법을 살펴봅니다.  

컨테이너화를 할 때는 보통 서비스를 작은 애플리케이션 여러 개로 쪼갭니다. 쪼개진 요소 각각은 API 게이트웨이(API Gateway)를 통해 다시 연결됩니다. 엔진엑스 서비스 메시는 서비스들 사이의 연결을 최적화하고 보호하기 위한 컨테이너 환경 인프라스트럭처 패턴입니다.  

컨테이너 환경에서 엔진엑스나 엔진엑스 플러스를 실행할 때는 아키텍처 관점 고려 사항 몇 가지를 검토해야 합니다. 서비스를 컨테이너화하면서 도커 로그 드라이버(Docker log driver)를 쓰려면 로그를 /dev/stdout으로 내보내고 오류 로그는 /dev/stderr로 내보냅니다. 이와 같이 로그를 도커 로그 드라이버로 보내고 동시에 로깅 서버로 전달합니다.  

컨테이너 환경에서 엔진엑스 플러스를 사용할 때 어떤 부하분산 방법을 사용할지도 생각해봐야 합니다. least_time 부하분산 알고리즘은 컨테이너 환경을 고려해 설계됐습니다. 낮은 응답 시간에 우선순위를 두므로 엔진엑스 플러스는 수산하는 요청을 평균 응답 시간이 가장 빠른 업스트림 서버로 보냅니다. 모든 업스트림 서버가 성능이 비슷하고 부하가 적절히 분산되는 환경이라면 엔진엑스 플러스는 네트워크 지연 시간이 짧거나 가장 가까운 네트워크로 판단되는 서버를 선택해 최적화합니다.  

#### 11.1. 엔진엑스를 API 게이트웨이로 사용하기  
<br/>

+ 수신한 API 요청을 요구사항에 따라 검증, 인증, 조작한 후 업스트림 서버로 라우팅하기  

엔진엑스나 엔진엑스 플러스를 API 게이트웨이로 사용합니다. API 게이트웨이는 업스트림 서버의 애플리케이션 프로그래밍 인터페이스(application programming interface, API)에 대한 진입점을 제공합니다.  

API 게이트웨이를 설정하려면 server 블록을 정의하는 멸도의 설정 파일을 생성합니다. 파일 이름은 /etc/nginx/api_gateway.conf 정도면 무난합니다.  

```
server {
    listen 443 ssl;
    server_name api.company.com;
    default_type application/json;
}
```

몇 가지 기본적인 오류 코드에 대한 동작을 server 블록에 추가합니다.  

```
proxy_intercept_errors on;

error_page 400 = @400;
location @400 {
    return 400 '{"status":400,"message":"Bad request"}\n';
}

error_page 401 = @401;
location @401 {
    return 400 '{"status":401,"message":"Unauthorized"}\n';
}

error_page 403 = @403;
location @403 {
    return 403 '{"status":403,"message":"Forbidden"}\n';
}

error_page 404 = @404;
location @404 {
    return 404 '{"status":404,"message":"Resource not found"}\n';
}
```

이 설정은 /etc/nginx/api_gateway.conf 파일의 server 블록에 직접 추가해도 되지만 별도의 파일로 만들어 include 지시자로 불어오는 방법도 좋습니다.  

생성한 API 게이트웨이 설정은 include 지시자를 사용해 주 설정 파일인 nginx.conf의 http 컨텍스트로 불러옵니다.  

```
include /etc/nginx/api_gateway.conf;
```

이제 업스트림 서버의 엔드포인트를 정의합니다.  

```
upstream service_1 {
    server 10.0.0.12:80;
    server 10.0.0.13:80;
}

upstream service_2 {
    server 10.0.0.14:80;
    server 10.0.0.15:80;
}
```

요구사항에 따라 전체 서비스를 정의한 파일을 인라인으로 불러오거나 서비스 단위로 불러옵니다. 어떤 경우에는 서비스가 프록시하는 location의 엔드포인트가 될 수도 있습니다. 이때는 엔드포인트의 이름을 변수에 저장해두고 설정 전반에서 사용하는 편이 좋습니다.  

각 서비스에 대한 server 블록에 내부 라우팅할 수 있는 location 블록을 만듭니다.  

```
location = /_service_1 {
    internal;
    # 서비스에 대한 공통 설정을 추가합니다
    proxy_pass http://service_1/$request_uri;
}
location = /_service_2 {
    internal;
    # 서비스에 대한 공통 설정을 추가합니다
    proxy_pass http://service_2/$request_uri;
}
```

서비스들에 대해 내부 라우팅할 수 있는 location 블록을 정의하면 서비스에 관계없이 공통적으로 필요한 설정은 반복해서 정의하지 않아도 됩니다.  

여기서 중요한 것은 대상 서비스별로 지정된 URI 경로들을 처리할 수 있도록 location 블록을 만드는 일입니다. 이 블록은 요청이 적합한 업스트림 경로로 라우팅되도록 합니다. 이처럼 API 게이트웨이는 단순히 경로 기반으로 요청을 라우팅할 수 있을 뿐만 아니라 API URI별로 특정한 규칙을 갖도록 자세하게 정의할 수도 있습니다. 나중에 각 조직이나 서비스를 위한 개별 파일 구조를 만들고 싶어지면 엔진엑스의 include 지시자로 설정 파일을 불러오기만 하면 됩니다.  

API 게이트웨이를 위한 새로운 디렉터리를 만들어봅시다.  

```
mkdir /etc/nginx/api_conf.d
```

설정 구조에 적합한 위치에 만들어진 파일에 location 블록을 정의해 서비스의 규격을 만듭니다. rewrite 지시사를 사용해, 요청을 서비스로 프록시하도록 정의한 location 블록으로 요청을 보냅니다. 다음 명령에서 rewrite 지시자는 엔진엑스가 변경된 URI로 다시 요청을 처리하도록 합니다. 정의한 규칙은 특정 API 리소스에 사용 가능한 HTTP 메서드를 제한하고 앞서 정의한 서비스용 내부 공통 프록시 location 블록으로 요청을 보냅니다.  

```
location /api/service_1/object {
    limit_except GET PUT { deny all; }
    rewrite ^ /_service_1 last;
}
location /api/service_1/object/[^/]*$ {
    limit_except GET POST { deny all; }
    rewrite ^ /_service_1 last;
}
```

이 과정을 각 서비스에 대해 적용하고 파일이나 디렉터리 구조와 같은 논리적인 분기를 도입함으로써 사용 사례를 효율적으로 조직화할 수 있습니다.  

location 블록이나 upstream 블록에 대해 개별 파일이 사용됐다면 블록들이 server 컨텍스트에 포함돼 있는지 확인합니다.  

```
server {
    listen 443 ssl;
    server_name api.company.com;

    default_type application/json;

    include api_conf.d/*.conf;
}
```

개인적인 리소스를 보호하려면 간단히 사전에 공유된 API 키를 사용하거나 여러 방법으로 인증을 활성화합니다. 다만 다음 예시에서 사용한 map 지시자는 http 컨텍스트에서만 유효하다는 점에 유의하기 바랍니다.  

```
map $http_apikey $api_client_name {
    default "";
    "j7UqLLB+yRv2VTCXXDZ1M/N4" "client_one";
    "6B2kbyrrTiINBS8JhSAxb63R" "client_two";
    "KcVgIDSY4Nm46m3tXVY3vbgA" "client_three";
}
```

엔진엑스로 백엔드의 서비스를 공격으로부터 보호합니다. http 컨텍스트에서 요청 제한을 위한 공유 메모리 영역을 정의합니다.  

```
limit_req_zone $http_apikey zone=limitbyapikey:10m rate=100r/s;
limit_req_status 429;
```

주어진 컨텍스트를 빈도 제한과 인증으로 보호합니다.  

```
location /api/service_2/object {
    limit_req zone= limitbyapikey;

    # 다음 if 문들을 별도 파일로 옮기고 include 지시자를 사용할 수도 있습니다
    if ($http_apikey = "") {
        return 401;
    }
    if ($api_client_name = "") {
        return 403;
    }
    limit_except GET PUT { deny all; }
    rewrite ^ /_service_2 last;
}
```

API 게이트웨이로 시험 요청을 보내 설정이 의도대로 동작하는지 확인합니다.  

```
curl -H "apikey: 6B2kbyrrTiIN8S8JhSAxb63R" https://api.company.com/api/service_2/object
```

API 게이트웨이는 API에 대한 진입점을 제공합니다. 다소 모호하고 당연하게 느껴질 수 있으니 좀 더 자세히 이야기해봅시다. 서로 다른 서비스 간의 통신은 서비스의 여러 계층에서 일어납니다. 독립된 두 서비스가 서로 통신하려면 API 버전에 대한 제약 관계가 있어야 합니다. 계약 관계는 서비스의 호환성을 보장하며 API 게이트웨이는 계약 관계를 대신해 인증, 권한 부여, 변형, 서비스 간 요청 전달 등을 수행합니다.  

이 절에서는 엔진엑스를 API 게이트웨이로 사용해 요청을 허가 및 인증하고 특정한 서비스로 보내 사용을 제한했습니다. 이 전략은 단일 API가 여러 서비스 사이에 나뉘는 마이크로서비스 아키텍처에 널리 쓰입니다.  

API 게이트웨이를 만드는 데 정답은 없습니다. 사용 사례에 따라 다양하고 무한한 해법이 있습니다.  

API 게이트웨이는 운영 조직과 애플리케이션 팀이 진정한 데브옵스(DevOps) 조직을 만드는 데 필요한 협업 공간을 제공합니다. 애플리케이션 개발은 주어진 사용자 요청이 유효한지 판단하는 매개변수를 정의하고, 이러한 요청을 처리하는 일은 보통 IT(네트워크, 인프라, 보안, 미들웨어 팀)라 부르는 조직에서 관리합니다. 이때 API 게이트웨이는 운영 조직과 애플리케이션 팀을 연결해주는 인터페이스로 동작합니다. API 게이트웨이를 만들려면 양쪽에서 요구사항을 받아야 하며 요구사항을 설정하는 것은 형상 관리 도구와 같은 것으로 관리돼야 합니다. 근래에 많은 소스 코드 저장소는 코드 소유자(code owner) 개념이 있어, 특정 파일에 대한 작업 시 특정 사람의 승인을 받도록 합니다. 이러한 방식을 통해 팀들이 협업하면서도 변경이 발생하는 부분을 검증합니다.  

API 게이트웨이를 다룰 때는 URI 경로를 염두에 둬야 합니다. 예시 설정에서는 전체 URI 경로가 업스트림 서버로 전달됩니다. 이는 service_1에 대한 예시는 /api/service_1/&#42; 경로에 대한 요청을 다뤄야 함을 의미합니다. 이처럼 경로 기반으로 라우팅할 때는 애플리케이션 간에 경로가 충돌하지 않도록 합니다.  

경로 충돌이 발생하는 경우 몇 가지 회피 방법이 있습니다. 코드를 수정해서 충돌을 해결하거나 충돌이 발생하는 애플리케이션에 URI 접두어를 추가해 서로 다른 컨텍스트를 통해 처리되도록 합니다. 하지만 직접 개발한 소프트웨어가 아니면 경로를 수정할 수 없으므로 요청 URI에 대한 업스트림 설정을 다시 할 수밖에 없습니다. 다만 애플리케이션이 HTTP 응답 본문에 링크를 제공하는 경우 정규 표현식을 사용해 바디의 링크값을 변경해 사용자에게 제공할 수도 있습니다. 물론 이 방법은 권장하지 않습니다.  

+ 엔진엑스 플러스를 API 게이트웨이로 배포하기(Deploying NGINX Plus as an API gateway): https://oreil.ly/75l-m  

#### 11.2. DNS의 SRV 레코드 활용하기(엔진엑스 플러스)  

엔진엑스 플러스가 SRV 레코드를 부하분산 풀로 활용하도록 upstream 블록의 server 지시자에 service 매개변숫값을 http로 지정합니다.  

```
http {
    resolver 10.0.0.2 valid= 30s;
    upstram backend {
        zone backends 64k;
        server api.example.internal service=http resolve;
    }
}
```

이 기능은 엔진엑스 플러스에서만 제공됩니다. 예시 설정은 엔진엑스 플러스가 IP 주소가 10.0.0.2인 DNS 서버로 질의를 보내고 server 지시자 한 개를 사용해 업스트림 서버 풀을 셋업하도록 합니다. server 지시자는 resolver 매개변수를 사용해 DNS 레코드의 TTL 값을 참조해서 DNS 질의를 주기적으로 다시 수행할 수 있습니다. 혹은 http 블록 앞쪽에 있는 resolver 지시자에 valid 매개변수를 사용해 DNS 레코드에 지정된 TTL 값을 무시하고 질의를 갱신할 주기를 지정할 수 있습니다. service=http 매개변수는 지정된 서버 도메인이 SRV 레코드이며 업스트림 서버로 사용할 IP 주소와 포트의 목록을 담고 있음을 엔진엑스에 알려줍니다. 엔진엑스는 이전까지 server 지시자를 통해 업스트림 서버를 여러 개 지정해 부하분산했던 것처럼 SRV 레코드에 지정된 IP 주소와 포트 목록에 대해 부하분산을 합니다.  

클라우드 기반 인프라에 대한 수요와 적용이 늘어나면서 동적인 인프라가 점차 인기를 얻고 있습니다. 오토스케일링 환경에서 서비스는 부하에 따라 서버 수를 늘리거나 줄이는 방식으로 로드 밸런서가 필요합니다. DNS의 SRV 레코드를 사용하면 풀에 추가하거나 제거할 수 있는 로드 밸런서가 필요합니다. DNS의 SRV 레코드를 사용하면 풀에 추가하거나 제거할 대상이 되는 서버 목록을 관리하는 책임에서 자유로워집니다. 이러한 형태의 설정은 컨테이너 환경을 사용할 때 굉장히 매력적인 방법입니다. 애플리케이션이 컨테이너 환경에서 동작하는 경우 동일한 IP 주소를 사용하거나 다양한 포트를 사용할 때가 많기 때문입니다. DNS 질의는 기본적으로 UDP 프로토콜을 사용하며 DNS 응답의 크기는 512B로 제한되므로 많은 IP 정보를 전달받기 힘들 수 있다는 점에 유의합시다. 근데 널리 사용되는 DNS 소프트웨어는 대부분 TCP와 UDP 모두 기본으로 사용합니다. 다만 인프라스트럭처가 구성돼 있는 네트워크 환경에서 DNS의 기본 포트인 53번에 대해 TCP, UDP 프로토콜이 모두 허용돼 있는지는 확인해봐야 합니다.  

#### 11.3. 공식 엔진엑스 이미지 사용하기  
<br/>

#### 11.4. 엔진엑스 도커 파일 생성하기  
<br/>

#### 11.5. 엔진엑스 플러스 도커 이미지 생성하기  
<br/>

ngx_http_perl_module로 환경 변수를 읽어 엔진엑스에서 변수로 사용합니다.  

```
daemon off;
env APP_DNS;
include /usr/share/nginx/modules/*.conf;
# ...

http {
    perl_set $upstream_app 'sub { return $ENV{"APP_DNS"}; }';
    server {
        # ...
        location / {
            proxy_pass https://$upstream_app;
        }
    }
}
```

perl_set을 사용하려면 ngx_http_perl_module이 설치돼 있어야 합니다. 모듈은 동적으로 불러오거나 소스 코드를 통해 엔진엑스를 빌드할 때 정적인 모듈로 추가합니다. 기본적으로 엔진엑스는 실행 중인 환경으로부터 환경 변수를 삭제한 후 구동되므로, 삭제하지 않고 사용할 환경 변수를 env 지시자로 미리 선언해야 합니다. perl_set 지시자는 매개변수를 두 개 사용합니다. 첫 번째는 환경 변수수값을 저장할 엔진엑스 변수이며 두 번째는 환경 변수를 읽어오는 데 사용할 펄(perl) 코드입니다.  

다음 도커 파일은 패키지 관리자를 사용해 ngx_http_perl_module을 설치하고 모듈을 동적으로 불러옵니다. 센트OS의 패키지 관리자로 모듈을 설치하면 모듈은 /usr/lib64/nginx/modules/ 경로에 설치되고 모듈을 동적으로 불러오는 설정은 /usr/share/nginx/modules/ 경로에 저장됩니다.  

도커가 환경 변수를 사용하는 전형적인 시나리오는 컨테이너의 운영 방식을 변경하는 경우입니다. 엔진엑스 설정에서 환경 변수를 사용함으로써 엔진엑스 도커 파일이 다양한 실행 환경에서 동작하도록 할 수 있습니다.  

#### 11.7. 쿠버네티스 인그레스 컨트롤러  
<br/>

#### 11.8. 프로메테우스 익스포터 모듈  
<br/>

#### 11.9. mTLS를 이용한 엔진엑스 서비스 메시 구성  
<br/>

mTLS 동작 검증을 위해 nginx-meshctl 도구를 사용해 mTLS를 퍼미시브 모드로 활성화합니다.  

```
nginx-meshctl deploy ... --mtls-mode permissive
```

디스크에 저장된 루트 인증 기관 인증서 경로를 기술한 YAML 설정을 만들어 적절한 PKI(Public Key Infrastructure) 쳬계를 구성합니다. SPIRE(SPIFFE Runtime Environment의 약어로, X.509 인증서를 활용해 신원 확인을 제공하는 SPIFFE 프레임워크의 런타임 구현체)는 이 구성을 업스트림 인증 기관 식별에 활용합니다.  

```
apiVersion: v1
upstreamAuthority: disk
config:
    cert_file_path: /path/to/rootCA.crt
    key_file_path: /path/to/rootCA.key
```

AWS 환경에서 배포를 수행한다면 AWS 시크릿 매니저(Secret Manager) 플러그인을 사용해 루트 인증 기관 인증서와 개인키를 AWS 시크릿 매니저에게 가져오도록 구성합니다.  

```
apiVersion: "v1"
upstreamAuthority: "awssecret"
config:
    region: "us-east-1"
    cert_file_arn: "arn:aws:secretsmanager:us-east-1:123456789012:secret:/certificate-authority/test-certificate"
    key_file_arn: "arn:aws:secretsmanager:us-east-1:123456789012:secret:/certificate-authority/test-key"
```

SPIRE가 사용해야 하는 업스트림 인증 기관을 알 수 있도록 nginx-meshcli 도구를 사용해 mTLS 설정을 배포합니다.  

```
nginx-meshctl deploy ... --mtls-upstream-ca-conf /apth/to/upstream-authority.yaml
```

배포가 정상적으로 이뤄졌는지 검증합니다.  

```
kubectl get pods -n nginx-mesh
```

mTLS 설정이 성공적으로 배포되고 애플리케이션 동작에 이상이 없다고 확인되면 mTLS 모드를 스트릭트(strict)로 변경하는 편이 좋습니다.  

```
nginx-meshctl deploy ... --mtls-mode strict
```

서비스 메시는 분산 애플리케이션 사이의 통신을 다루기 위해 설계된 전담 인프라스트럭처 계층입니다. 엔진엑스 서비스 메시는 쿠버네티스 환경에서 서비스 레벨의 사이드카(sidecar) 패턴을 활용합니다. 엔진엑스 사이드카는 서비스 간의 통신, 모니터링, 보안을 담당합니다. 엔진엑스 서비스 메시와 nginx-meshctl 도구는 아주 직관적인 방식으로 여러분의 환경에 서비스 메시를 배포합니다. 사이드카 주입만으로 각 서비스에 대한 엔진엑스 사이드카를 자동으로 설정할 수 있어, 인프라스트럭처 계층을 밑바닥부터 구현하고 설정할 필요가 없습니다. 여러분이 할 일은 단지 기능 활성화뿐이므로 시간을 더 중요한 서비스 업무에 할애할 수 있습니다.  

이 절에서는 mTLS를 활성화하는 방법에 집중했습니다. mTLS는 클라이언트와 서버 간의 동작하지 않는 경우 원래의 통신 방법으로 통신할 수 있도록 했습니다. 인증서와 비밀키의 분배와 서명을 담당하는 SPIRE 서비스는 기본적으로 자체 서명 인증서를 사용하도록 꽤 있습니다. 신뢰할 수 있는 외부 인증 기관(CA)의 인증서와 비밀키를 사용하면 mTLS 설정이 더 강력해집니다.  

+ 엔진엑스 블로그 게시글 '엔진엑스 서비스 메시의 mTLS 아키텍처(The mTLS Architecture in NGINX Service Mesh): https://oreil.ly/CWEUB
+ mTLS를 이용해 서비스 메시 트래픽 보호하기: https://oreil.ly/VJDge
+ 기업을 위한 서비스 메시 아키텍처 구현(The Enterprise Path to Service Mesh Architecture): https://www.nginx.com/resources/library/the-entreprise-path-to-service-mesh-architectures  

### 12. 고가용성 보장을 위한 설정  
<br/>

#### 12.0. 소개  
<br/>

내장애성(fault-tolerant) 아키텍처는 시스템을 동일하면서도 독립적인 스택으로 나눠줍니다. 엔진엑스는 같은 로드 밸런서는 부하를 분산해 배치된 시스템들이 골고루 환용되도록 합니다. 고가용성(high-availability)의 핵심 개념은 여러 활성 노드로 부하를 분산하거나 액티브-패시브(active-passive) 구성으로 노드 간에 페일오버(failover)하는 것입니다. 고가용성 애플리케이션은 단일 장애점(single point of failure, SPOF)이 없어야 하며, 이는 모든 구성 요소가 고가용성의 핵심 개념을 하나 이상 사용해야 하고 로드 밸런서 역시 고가용성을 보장해야 함을 의미합니다. 즉, 엔진엑스 역시 고가용성을 보장하는 설정으로 준비돼야만 합니다. 고가용성을 보장하려면 엔진엑스를 여러 개의 활성 노드 집합으로 설정하거나 액티브-패시브 페일오버 방식으로 설정합니다.  

#### 12.1. 엔진엑스 플러스 HA 모드  
<br/>

엔진엑스 플러스 저장소에서 nginx-ha-keepalived 패키지를 설치해 keepalived를 활용한 엔진엑스 플러스 HA 모드를 사용합니다. 리눅스 기반 시스템에서 쉽게 부하분산과 고가용성을 제공할 수 있도록 만들어진 라우팅 소프트웨어로 여러 배포판에서 패키지로 제공됩니다. 자세한 내용은 https://www.keepalived.org를 참고하기 바랍니다.  

nginx-ha-keepalived 패키지는 keepalived를 기반으로 동작하며 클라이언트에 제공되는 가상 IP 주소(Virtual IP address)를 관리합니다. 그 외에 다른 프로세스가 엔진엑스 서버에서 구동돼 엔진엑스 플러스와 keepalived가 동작하고 있는지 확인합니다. keepalived는 가상 라우터 장애 복구 프로토콜(Virtual Router Redundancy Protocol, VRRP)을 활용하는 프로세스로, 하트비트(heartbeat)라는 작은 메시지를 지속적으로 백업 서버에 보냅니다. 백업 서버는 하트비트를 3회 연속 수신하지 못하면 페일오버를 준비하고 가상 IP 주소를 자신에게 할당해 프라이머리 서버가 됩니다. nginx-ha-keepalived가 제공하는 페일오버 기능은 직접 설정한 페일오버 조건을 감시하도록 설정할 수도 있습니다.  

#### 12.2. DNS를 이용한 로드 밸런서 부하분산  
<br/>

도메인에 IP 주소를 여러 개 추가함으로써 DNS 질의에 대한 응답으로 각 엔진엑스 서버를 라운드 로빈 방식으로 돌아가며 사용합니다.  

로드 밸런서를 여러 개 운영할 때 DNS를 이용해 부하를 분산할 수 있습니다. 단일 FQDN은 여러 개의 A 레코드 혹은 AAAA 레코드를 가질 수 있습니다. DNS는 등록된 IP 주소 여러 개를 돌아가면서 사용하며, 레코드에 가중치를 적용한 라운드 로빈 방식을 사용할 수도 있습니다. 이러한 기술은 상당히 잘 동작합니다. 하지만 특정 엔진엑스 서버에 문제가 발생하면 해당 서버의 IP 주소를 DNS에서 제외해야 합니다. 아마존 라우트53이나 DynDNS 같은 DNS 서비스는 이러한 문제를 완화하는 헬스 체크와 페일오버 기능을 제공합니다. DNS를 이용해 엔진엑스에 대한 부하분산을 한다면, 문제가 생긴 엔진엑스 서버를 제외하는 데 엔진엑스에서 업스트림 서버를 제외할 때와 동일한 절차를 활용하는 편이 좋습니다. 먼저, 문제가 생긴 서버로 새로운 연결을 만들지 않도록 DNS에서 해당 서버의 IP를 제외하고, 서버를 중지시키기 전에 모든 연결이 종료되도록 합니다.  

#### 12.3. EC2의 부하분산  
<br/>

엔진엑스 서버들로 오토스케일링 그룹을 설정하고 오토스케일링 그룹을 NLB의 타깃 그룹으로 지정해 엔진엑스가 AWS NLB 뒤에 위치하도록 설정합니다. 물론 AWS 콘솔이나 CLI 혹은 API를 사용해 엔진엑스 서버를 NLB의 타깃 그룹으로 직접 지정할 수도 있습니다.  

keepalived를 기반으로 동작하는 엔진엔스 플러스의 고가용성 기능은 유동적으로 할당되는 가상 IP 주소를 지원하지 않습니다. 따라서 탄력적인 IP 주소(Elastic IP, EIP)를 사용하지 않는 EC2와 같이 IP 주소 할당이 유동적인 AWS 환경에서는 사용하기가 어렵습니다. 하지만 엔진엑스 플러스가 AWS 환경에서 고가용성 환경을 구성할 수 없다는 뜻은 아닙니다. AWS에서 동작하는 HA 환경을 구성할 수 있습니다. 아마존이 제공하는 AWS NLB는 가용성 영역(availability zone)이라는 물리적으로 분리된 데이터 센터 간에 부하를 분산해주며 능동적인 헬스 체크와 DNS CNAME으로 사용 가능한 엔드포인트를 제공합니다. AWS 환경에서 엔진엑스의 고가용성을 확보하는 데는 일반적으로 엔진엑스를 NLB 뒤쪽에 위치시키는 방법을 사용합니다. 엔진엑스 서버들은 필요에 따라 NLB의 타깃 그룹에 자동으로 추가되거나 그룹에서 제외될 수 있습니다. 중요한 점은 NLB는 엔진엑스를 대체할 수 없다는 점입니다. 엔진엑스는 다양한 부하분산 방식, 빈도 제한, 캐싱, 7계층 라우팅 등 NLB가 제공하지 않는 여러 기능을 제공합니다. 또 다른 AWS 로드 밸런서인 ALB를 사용하면 URI 경로와 호스트 헤더를 기반으로 7계층에서 부하를 분산할 수 있지만 엔진엑스처럼 WAF 캐싱, 대역폭 제한, HTTP/2 서버 푸시와 같은 기능은 제공하지 않습니다. NLB가 여러분의 비즈니스 요구사항에 맞지 않는다면 다른 옵션이 몇 가지 있습니다. 그중 하나가 DNS 솔루션이며 AWS의 라우트53은 헬스 체크, DNS 페일오버 등의 기능을 제공합니다.  

#### 12.4. 엔진엑스 플러스 설정 동기화하기  
<br/>

엔진엑스 플러스에서 제공하는 설정 동기화 기능을 사용합니다. 기능을 사용하려면 다음 절차가 필요합니다. 먼저 엔진엑스 플러스 패키지 저장소로부터 nginx-sync 패키지를 설치합니다.  

```
// RHEL이나 센트OS 운영체제에서 설치하기
sudo yun install nginx-sync
// 우분투나 데이반에서 설치하기
sudo apt-get install nginx-sync
```

패키지를 설치했으면 프라이머리 역할을 수행할 서버가 다른 서버들에 루트로 SSH 접근을 할 수 있도록 권한을 부여합니다. 루트 권한을 위한 SSH 인증키 쌍을 만들고 공개키를 추출합니다.  

```
sudo ssh-keygen -t rsa -b 2048
sudo cat /root/.ssh/id_rsa.pub

ip addr
```

ip addr 명령은 서버의 네트워크 인터페이스 정보를 보여줍니다. 첫 번째 결과에 나온 루프백 인터페이스 정보는 무시해도 괜찮습니다. IP 주소는 이어지는 인터페이스 정보의 inet 항목에서 확인할 수 있습니다.  

앞서 추출해둔 공개키를 프라이머리가 아닌 각 노드 루트 계정의 authorized_keys 파일에 배포하고 프라이머리 서버에서 접근할 때만 해당 키로 접근 권한을 확인하도록 지정합니다.  

```
sudo echo 'from="192.168.1.2" ssh-rsa AAAAB3Nz4rFgt....vga0 root@node1'
```

다음 명령으로 /etc/ssh/sshd_config 파일을 변경하고 모든 서버의 sshd의 설정을 리로드합니다.  

```
sudo echo 'PermitRootLogin without-password' >> /etc/ssh/sshd_config
sudo service sshd reload
```

이제 프라이머리 서버의 루트 사용자가 각 노드에 ssh로 접근할 때 비밀번호 없이 인증되는지 확인합니다.  

```
sudo ssh root@node2.example.com
```

프라이머리 서버에 다음 내용의 설정 파일 /etc/nginx-sync.conf를 만듭니다.  

```
NODES="node2.example.com node2.example.com node4.example.com"
CONFPATHS="/etc/nginx/nginx.conf /etc/nginx/conf.d"
EXCLUDE="default.conf"
```

이 설정은 엔진엑스 설정 동기화를 위해 설정한 세 공통 매개변수 NODES, CONFIGPATHS, EXCLUDE를 보여줍니다. NODES 매개변숫값은 문자열로 구성된 호스트명이나 IP 주소를 공백으로 구분한 값이며, 이들은 프라이머리 서버가 설정이 변경되면 설정을 보낼 노드입니다. CONFIGPATHS 매개변수는 동기화해야 하는 파일이나 디렉터리를 나타냅니다. 마지막으로 EXCLUDE 매개변수는 동기화 대상에서 제외할 파일을 지정합니다. 예시에서 프라이머리 서버는 엔진엑스 기본 설정 파일과 /etc/nginx/conf.d 디렉터리의 변경 사항을 호스트명이 node2.example.com, node3.example.com, node4.example.com인 서버로 전달합니다. 동기화 프로세스에서 default.conf 파일을 발견하더라도 이 파일은 EXCLUDE 매개변수에 지정돼 있으므로 각 서버로 전송되지 않습니다.  

고급 설정 매개변수를 사용해 엔진엑스 바이너리나 RSYNC 바이너리, SSH 바이너리, diff 바이너리, lockfile 위치, 백업 디렉터리 등의 위치를 지정할 수 있습니다. 템플릿에서 지정된 파일에 sed 명령을 활용하는 매개변수도 있습니다. 고급 설정 매개변수에 대한 자세한 내용은 설정 공유에 대한 공식 문서를 참고하기 바랍니다.  

다음 명령으로 설정을 시험합니다.  

```
nginx-sync.sh -h # 사용법을 확인합니다.
nginx-sync.sh -c node2.example.com # 프라이머리 서버 설정과 node2를 비교합니다.
nginx-sync.sh -C # 프라이머리 서버 설정을 모든 서버와 비교합니다.
nginx-sync.sh # 설정을 동기화하고 엔진엑스를 리로드합니다.
```

엔진엑스 플러스 전용 기능을 사용하면 여러 엔진엑스 플러스 서버를 고가용성 설정으로 운영하는 환경에서 프라이머리 서버의 설정만 변경하고 내용을 클러스터의 각 서버에 동기화할 수 있습니다. 이 절차를 자동화하면 설정을 전송할 때 실수가 발생할 위험이 줄어듭니다. nginx-sync.sh 애플리케이션은 잘못된 설정이 각 서버에 동기화되지 않도록 몇 가지 방안을 제공합니다. 예를 들어, 프라이머리 서버에서 설정을 시험하고, 각 서버의 설정 백업본을 만들고, 서버들은 리로드하기 전에 시험합니다. 설정을 동기화하는 데는 도커나 설정 관리 도구를 이용하는 방법이 권장되지만, 이러한 방법을 사용할 수 없거나 준비가 되지 않았을 때는 엔진엑스 플러스의 설정 동기화 기능이 유용합니다.  


#### 12.5. 상태 공유와 영역 동기화(엔진엑스 플러스)  
<br/>

공유 메모리 영역 동기화를 설정하고, 엔진엑스 플러스 공유 메모리 영역 설정 시 sync 매개변수를 사용합니다.  

```
stream {
    resolver 10.0.0.2 valid= 20s;
    server {
        listen 9000;
        zone_sync;
        zone_sync_server nginx-cluster.example.com:9000 resolve;
        # 보안 관련 설정
    }
}
http {
    upstream my_backend {
        zone my_backend 64k;
        server backends.example.com resolve;
        sticky learn zone=sessions:1m
               create=$upstream_cookie_session
               lookup=$cookie_session
               sync;
    }
    server {
        listen 80;
        location / {
            proxy_pass http://my_backend;
        }
    }
}
```

zone_sync 모듈은 엔진엑스 플러스만의 기능으로, 엔진엑스 플러스가 제대로 된 클러스터를 만들도록 해줍니다. 모듈을 사용하려면 설정처럼 stream 서버 블록에 zone_sync를 사용합니다. 예시의 zone_sync_server 지시자로 정의된 클러스터 내 서버들과 통신합니다. zone_sync_server 지시자에 도메인명을 설정해 동적인 클러스터에서 여러 IP 주소를 리졸빙해 쓰게 하거나 zone_sync_server를 여러 개 이용해 정적으로 여러 IP 주소를 사용함으로써 단일장애점이 생기는 것을 막을 수 있습니다. 영역 종기화 서버에 대한 접근은 제한해야 하며, 접근하는 서버를 인증하는 데는 특정한 SSL/TLS 지시자를 사용합니다. 엔진엑스 플러스를 클러스터로 설정할 때 장점은 공유 메모리 영역을 동기화해 빈도를 제한하고, 스티키런(sticky-learn) 세션을 통해 부하를 분산하고, 키-값 저장소를 함께 사용할 수 있다는 점입니다. 예시에서는 스티키런 지시자에 sync 매개변수를 사용합니다. 예시에서 사용자는 session이라는 쿠키값을 기준으로 업스트림 서버에 연결됩니다. 영역 동기화 모듈이 없는 상태에서 사용자 요청이 다른 엔진엑스 플러스 서버로 보내지만 사용자들은 세션 정보를 잃게 됩니다. 즉, 영역 동기화 모듈을 사용하면 모든 엔진엑스 플러스 서버는 각 세션이 연결된 업스트림 서버를 인지할 수 있습니다.  

#### 13. 고급 활동 모니터링  
<br/>

#### 13.1. 오픈 소스 엔진엑스의 Stub Status 활성화하기  
<br/>

엔진엑스 http 컨텍스트에 위치한 location 블록에서 stub_status 모듈을 활성화합니다.  

```
location /stub_status {
    stub_status;
    allow 127.0.0.1;
    deny all;
}
```

상태 정보에 대한 요청으로 설정에 문제가 없는지 시험합니다.  

```
curl localhost/stub_status
```

stub_status 모듈은 엔진엑스 오픈 소스 버전이 제공하는 몇 가지 기본적인 지표 모니터링을 활성화합니다. 모듈이 응답하는 정보는 활성 연결 수뿐 아니라 총 연결 수, 처리 완료된 연결 수, 요청에 대한 응답 수 등을 제공해 사용자 요청에 대한 인사이트를 줍니다. stub_status 모둘은 읽기 및 쓰기 작업 중인 연결 수, 대기 상태인 연결 등에 대한 정보도 보여줍니다. 이 정보는 stub_status 지시자가 정의된 server 컨텍스트에 한정된 것이 아니라 전체 서비스에 대한 정보입니다. 즉, 전체 서비스에 대한 정보를 취합할 수 있으며, stub_status 지시자가 지정된 블록의 상위 server 블록에 제한되는 것은 아닙니다. 종종 보안을 목적으로 로컬 네트워크에서 돌어오는 요청 외에는 접근을 제한하는 것과 같은 맥락입니다. stub_status 모듈은 활성 연결 수를 내장 변수로 제공해 로그나 다른 엔진엑스 설정에서 사용하도록 해주며 내장 변수 이름은 $connections_active, $connections_reading, $connections_wrting, $connections_waiting입니다.  

#### 13.2. 모니터링 대시보드 활성화하기(엔진엑스 플러스)  
<br/>

실시간 활동 모니터링 대시보드를 활용합니다.  

```
server {
    # ...
    location /api {
        api [write=on];
        # API 접근을 제한하는 지시자들이 위치합니다
        # 자세한 내용은 7장을 참고합니다
    }
    location = /dashboard.html {
        root    /usr/share/nginx/html;
    }
}
```

이 엔진엑스 플러스 설정을 통해 엔진엑스 플러스 상태 모니터링 대시보드를 이용합니다. 먼저 API와 상태 대시보드를 제공하기 위해 HTTP 서버를 생성합니다. 대시보드는 /usr/share/nginx/html 경로에 위치한 정적 콘텐츠를 사용하며, /api/ 경로로 API를 호출해 실시간으로 서버 상태를 추출해 보여줍니다.  

엔진엑스 플러스는 고급 상태 모니터링 대시보드를 제공합니다. 이 대시보드는 활성 연결 수, 가동 시간, 업스트림 서버 풀에 대한 정보 등 엔진엑스 시스템의 세부 상태를 보여줍니다.  

엔진엑스 컨트롤러를 이용하면 여러 지역에 배치된 엔진엑스 플러스 서버 클러스터를 애플리케이션에 대한 정보와 지표를 단일 인터페이스를 통해 보여줍니다.  

대시보드의 랜딩 페이지는 전체 시스템의 개요를 보여줍니다. 화면 상단에서 첫 번째 탭 'HTTP 존(HTTP Zone)'을 선택해 엔진엑스 설정에 지정된 HTTP 서버의 응답 코드 분포, 총 요청량과 초당 들어오는 요청량, 트래픽 스루풋(throughput)과 같은 자세한 상태를 확인합니다. 'HTTP 업스트림(HTTP Upstream)' 탭은 업스트림 서버의 상태 정보를 보여줍니다. 서버가 살아 있는지, 얼마나 많은 요청이 처리되고 있는지, 응답 코드 분포가 어떠한지, 헬스 체크 요청은 얼마나 성공하고 실패하는지와 같은 정보가 포함됩니다. 'TCP/UDP 존(TCP/UDP Zone)' 탭은 TCP, UDP 프로토콜을 통해 흐르는 트래픽 양과 연결 수를 보여줍니다. 'TCP/UDP 업스트림(TCP/UDP Upstream)' 탭은 TCP/UDP 업스트림 풀에 있는 서버 중 얼마나 많은 서버가 정상적으로 서비스를 제공하고 있는지에 대한 정보와 헬스 체크 요청 성공 및 실패에 대한 상세 내용 그리고 응답 시간을 알려줍니다. '캐시(Cache)' 탭은 캐시 저장을 위해 사용 중인 스토리지의 용량(캐시를 통해 제공된 트래픽, 캐시로 기록된 용량 혹은 캐시되지 않고 서비스된 전송량)과 캐시 적중률을 보여줍니다. 이처럼 엔진엑스 상태 대시보드는 운영 중인 애플리케이션과 트래픽 흐름을 모니터링하는 중요한 도구입니다.  

+ 엔진엑스 플러스 상태 대시보드 데모: https://oreil.ly/20j1Q
+ F5 엔진엑스 컨트롤러 제품 소개: https://oreil.ly/ty2Iu  

#### 13.3. 엔진엑스 플러스 API로 지표 수집하기  
<br/>

지표 수집을 위해 RESTful API를 사용합니다. 다음 예시는 API 호출 결과를 파이프를 통해 json_pp로 전달해 읽기 편한 방식으로 출력합니다.  

```
curl "https://demo.nginx.com/api/3" | json_pp
```

예시의 curl 명령은 엔진엑스 플러스 API의 최상위 엔드포인트를 호춣하며, API 호출을 통해 확인할 수 있는 항목을 보여줍니다.  

예를 들어, 엔진엑스 플러스 서버에 대한 정보를 얻으러면 /api/{version}/nginx URI를 사용합니다.  

```
curl "https://demo.nginx.com/api/3/nginx" | json_pp
```

API 응답에서 필요한 값만 얻으려면 다음과 같이 URI에 인수를 포함해 호출합니다.  

```
curl "https://demo.nginx.com/api/3/nginx?fields=version,build" | json_pp
```

연결에 대한 통계를 확인하려면 /api/{version}/connections URI를 사용합니다.  

```
curl "https://demo.nginx.com/api/3/connections" | json_pp
```

요청에 대한 통계를 확인하려면 /api/{version}|/http/requests URI를 사용합니다.  

```
curl "https://demo.nginx.com/api/3/http/requests" | json_pp
```

특정 서버 존에 대한 통계를 확인하려면 /api/{version}/http/server_zones/{httpServerZoneName} URI를 활용합니다.  

```
curl "https://demo.nginx.com/api/3/http/server_zones/hg.nginx.org" | json_pp
```

이처럼 API는 대시보드에서 확인 가능한 모든 정보를 제공합니다. 깊이가 있지만 논리적인 패턴을 따르므로 사용하기는 어렵지 않습니다.  

엔진엑스 인스턴스 매니저 API를 이용하면 동시에 여러 엔진엑스 플러스 서버로 지표 요청 쿼리를 보내고 응답을 수집할 수 있습니다. 컨트롤러가 제공하는 지표는 여러분의 지표를 조금 다르게 애플리케이션 중심으로 보도록 해줍니다.  

+ 엔진엑스 HTTP API 모듈 공식 문서: https://oreil.ly/qyKjs
+ 엔진엑스 API REST UI: https://demo.nginx.com/swagger-ui
+ 메트릭스 API 사용 가이드: https://oreil.ly/uM5Ul  

### 14. 디버깅과 트러블슈팅  
<br/>

#### 14.0. 소개  
<br/>

+ 오픈트레이싱(OpenTracing)  
CNCF 인큐베이팅 과제 중 하나로, 복잡하게 얽힌 내부와 외부의 서비스에 대해 일원화된 추적(tracing) 규칙을 정의해 각 요청의 흐름을 추적하고, 여기서 기록된 로그를 통해 전반적인 서비스 상태를 추적하는 도구입니다. 최근 오픈트레이싱은 오픈텔레메트리 과제와 병합돼 관찰 가능성(observability)을 위한 프로젝트로 계속 업데이트되고 있습니다. 자세한 내용느 https://opentelemetry.io/docs/migration/opentracing을 참고하기 바랍니다.  

#### 14.1. 접근 로그 설정하기  
<br/>

접근 로그 형식을 다음과 같이 설정합니다.  

```
http {
    log_format geoproxy
               '[$time_local] $remote_addr '
               '$realip_remote_addr $remote_usr '
               '$proxy_protocol_server_addr $proxy_protocol_server_port '
               '$request_method $server_protocol '
               '$scheme $server_name $uri $status '
               '$request_time $body_bytes_sent '
               '$geoip_city_country_code3 $geoip_region '
               '"$geoip_city" $http_x_forwarded_for '
               '$upstream_status $upstream_response_time '
               '"$http_referer" "$http_user_agent"';
    # ...
}
```

이 로그 형식 설정은 이름이 geoproxy이며 엔진엑스의 강력한 로깅 기능을 보이고자 여러 개의 내장 변수를 로그 남기고 있습니다. $time_local로 서버가 요청을 받은 시점의 로컬 시간을 남기고, $remote_user로 연결 맺은 IP 주소를 확인하며, geoip_proxy나 realip_header가 식별한 값을 가진 $realip_remote_addr를 이용해 실제 클라이언트의 IP 주소 정보를 엔진엑스의 로그로 남깁니다.  

$proxy_protocol_server_로 시작하는 변수들은 proxy_protocol 매개변수가 server 컨텍스트의 수신 설정에서 사용됐을 때 프록시 프로토콜 헤더로부터 획득한 정보를 담고 있습니다. HTTP, HTTPS와 같은 스킴(scheme)과 요청 메서드, 프로토콜을 로그에 남기며, 기본 인증을 사용한다면 $remote_user 변수로 인증에 사용된 사용자명을 확인할 수 있습니다. $server_name 값을 로그에 남겨 사용자 요청이 엔진엑스 설정의 어떤 server_name 분기를 통해 처리됐는지 알 수 있으며, URI의 응답 코드도 각각에 대한 변수를 이용할 수 있습니다.  

요청 처리 시간은 밀리초 단위로 기록되며 클라이언트에 응답한 응답 바디의 크기도 로그에 기록됩니다. 사용자 IP에 대한 국가, 지역, 도시 정보는 $geoip_로 시작하는 변수로 확인합니다. X-Forwarded-For 헤더값이 저장된 $http_x_forwarded_for 변수를 로그에 남겨 사용자 요청이 프록시를 경유한 요청인지 확인합니다. upstream 모듈을 사용하는 경우 업스트림 서버의 응답 코드나 응답을 받기까지 걸린 시간을 확인하는 몇몇 내장 변수가 활성화됩니다. 마지막으로 $http_referer와 $http_user_agent 변수를 사용해 클라이언트가 사용한 브러우저 정보를 확인하고 어느 웹사이트를 통해 요청을 보냈는지 확인합니다.  

log_format 지시자는 http 컨텍스트에서만 유효합니다. 이스케이프(escape) 문자열 처리를 위해 escape 매개변수를 사용하며 변수에 담긴 문자열이 문제없이 처리되도록 매개변수에 default, json, none 값을 지정할 수 있습니다. none은 이스케이프 문자열 처리를 비활성화하며 default는 큰따옴표("), 역슬래시(&#92;) 및 아스키코드 기준으로 32보다 작거나 126보다 큰 문자를 '&#92;Xxx' 형태로 이스케이프 처리합니다. 이스케이프 문자열 처리에 대한 매개변수를 지정하지 않으면 하이픈(-)을 사용합니다. json 이스케이핑을 지정하면 JSON 규격에서 사용할 수 없는 문자는 모두 이스케이프 처리됩니다.  

이렇게 만든 로그 형식을 사용하기 위해 access_log 지시자로 로그 파일 생성 경로를 지정하고 사용할 로그 형식 이름으로 geoproxy를 매개변수로 지정합니다.  

```
server {
    access_log /var/log/nginx/access.log geoproxy;
    # ...
}
```

access_log 지시자는 로그 파일의 경로와 형식을 매개변수로 사용합니다. 이 지시자는 여러 컨텍스트에서 사용 가능한데, 각 컨텍스트에서 서로 다른 경로에 로그 파일을 만들 수 있으며 서로 다른 형식을 지정할 수 있습니다. 그리고 buffer, flush, gzip 매개변수를 사용해 수집된 로그를 언제 로그 파일에 기록할지와 로그 파일을 gzip으로 압출할지를 결정합니다. 필요시 if 매개변수를 사용해 로그 기록 조건을 지정합니다. if 조건문에 0이나 빈 문자열이 들어오면 로그를 남기지 않습니다.  

엔진엑스의 로그 모듈은 다양한 시나리오에 적절한 로그 형식으로 로그 파일을 만듭니다. 다양한 컨텍스트를 사용하는 시나리오에서 각 모듈이 제공하는 내장 변수를 로그에 활용할 수 있도록 상황에 따라 다른 로그 형식을 사용하면 좋습니다. 로그는 적절한 형식을 엔진엑스 설정에 지정해 JSON이나 XML 형식으로 남길 수도 있습니다. 로그를 통해 트래픽 패턴을 이해하고 클라이언트가 누구이며 어디에 있는지 등 정보를 확인할 수 있습니다. 접근 로그는 특정 URI나 업스트림 서버의 문제와 응답 지연 등을 파악하는 데 유용하며, 실제 사용자의 사용 패턴을 확인하고 재현하는 데도 활용됩니다. 즉, 로그는 트러블슈팅, 디버깅, 애플리케이션과 서비스 분석에 무한한 활용 가능성이 있습니다.  

#### 14.2. 오류 로그 설정하기  
<br/>

error_log 지시자로 오류 로그 파일의 경로와 로그 레벨을 정합니다.  

```
error_log /var/log/nginx/error.log warn;
```

error_log 지시자의 매개변수 중 로그 파일의 경로는 필수지만, 로그 레벨은 옵션이며 기본 값은 error입니다. error_log는 if 구문을 제외한 모든 컨텍스트에서 사용할 수 있습니다. 로그 레벨에 설정할 수 있는 값은 debug, info, notice, warn, error, crit, alert, emerg 등 여덟 가지이며 나열한 순서는 문제의 심각도 순입니다(오른쪽으로 갈수록 심각함), 단 debug 로그 레벨은 엔진엑스가 --with-debug 플래그를 사용해 실행됐을 때만 사용 가능합니다. 일반적으로 debug 로그 레벨은 로그를 상당히 많이 남깁니다. 따라서 다른 로그 레벨로 이슈를 확인하기 어려울 때만 제한적으로 사용하는 편이 좋습니다.  

오류 로그는 엔진엑스 설정이 의도한 대로 동작하지 않을 때 가장 먼저 살펴봐야 하는 로그입니다. 특히 FastCGI와 같은 애플리케이션 서버에서 오류 발생 시 단서를 찾는 데 매우 유용한 정보입니다. 오류 로그를 통해 문제가 발생한 연결을 디버깅할 수 있으며 연결을 처리한 엔진엑스 워커, 메모리 할당 정보, 사용자 IP, 서버에 이르는 낮은 수준의 문제점 확인까지 할 수 있습니다. 오류 로그는 로그 형식 지정이 불가능합니다. 대신 특정 형식으로 된 날짜, 로그 레벨, 오류 메시지로 구성된 로그를 제공합니다.  

#### 14.3. 로그를 시스로그로 전달하기  
<br/>

error_log 지시자와 access_log 지시자를 사용해 로그를 시스로그 리스너로 전달합니다.  

```
error_log syslog:server=10.0.1.42 debug;
access_log syslog:server=10.0.1.42,tag=nginx,severify=info geoproxy;
```

각 지시자에 사용된 syslog 매개변수는 몇 가지 옵션을 콜론으로 연결해 지정할 수 있습니다. IP 주소나 DNS 레코디명 혹은 유닉스 소켓 정보처럼 연결에 필요한 정보를 server 플래그로 지정할 수 있으며 facility, severity, tag, nohostname 같은 옵션 플래그도 사용 가능합니다. server 옵션에는 IP 주소나 DNS 레코드명과 함께 포트 번호를 지정할 수 있으며, 포트를 지정하지 않으면 UDP 프로토콜로 514 포트로 사용합니다. facility 옵션은 RFC 표준에 정의된 시스로그의 23가지 퍼실리티(facility) 중 하나를 지정하는 데 사용하며 기본값을 23번째 값인 local7입니다. tag 옵션을 사용해 로그 메시지를 식별하는 태그값을 설정할 수 있으며 기본값은 nginx입니다. severity 옵션은 로그의 심각도를 나타내는 데 사용하며 기본값은 info입니다. severity 역시 시스로그 규격의 severity 정의를 따릅니다. nohostname 플래그를 사용해 시스로그 메시지 헤더의 호스트명 필드를 쓰지 않도록 할 수 있으며 별도의 값을 지정하지 않고 플래그만으로 사용합니다.  

시스로그는 로그를 전송하는 표준 프로토콜이며 전송된 로그는 단일 서버 혹은 복수의 서버에 저장됩니다. 중앙화된 저장소나 서버로 로그를 전송하면 여러 대의 호스트에서 구동되는 다수의 서비스 인스턴스를 사용하는 환경에서 디버깅을 쉽게 할 수 있습니다. 이 과정을 로그 집계(aggregating logs)라 부르기도 합니다. 로그 집계를 통해 각 서비를 돌아다니지 않고 여러 로그를 함께 볼 수 있으며 타임스탬프를 이용해 수집한 로그 파일을 확인할 수 있습니다. 널리 알려진 로그 집계 시스템으로는 ELK(일래스틱서치(Elasticsearch), 로그스태시(Logstash), 키바나(Kibana)) 스택이 있습니다. 엔진엑스는 access_log와 error_log 지시자를 사용해 로그를 시스로그 리스터로 쉽게 전달하도록 합니다.  

#### 14.4. 요청 추적하기  
<br/>

request 식별을 위한 변수를 설정하고 변숫값을 애플리케이션에 전달해 로그에 남기도록 합니다.  

```
log_format trace '$remote_addr - $remote_user [$time_local] '
                 '"$request" $status $body_bytes_sent '
                 '"$http_referer" "$http_user_agent" '
                 '"$http_x_forwarded_for" $request_id';

upstream backend {
    server 10.0.0.42;
}

server {
    listen 80;
    # 클라이언트 요청에 대한 응답 헤더에 X-Request_ID를 추가합니다
    add_header X-Request-ID $request_id;
    location / {
        proxy_pass http://backend;
        location / {
            proxy_pass http://backend;
            # 업스트림 서버의 애플리케이션으로 X-Request-ID를 전달합니다
            proxy_set_header X-Request-ID $request_id;
            access_log /var/log/nginx/access_trace.log trace;
        }
    }
}
```

예시 설정은 trace라는 log_format을 정의합니다. 로그에 $request_id 변숫값을 남기도록 포맷을 정의하며, 이 변숫값은 proxy_set_header 지시자를 통해 X-Request-ID 헤더값으로 지정되고 요청을 업스트림 애플리케이션으로 보낼 때 전달합니다. $request_id 값은 클라이언트는 응답을 보낼 때도 add_header 지시라를 이용해 X-Request-ID 응답 헤더값으로 전달됩니다.  

&#36;request_id 변수는 엔진엑스 플러스 R10 버전과 오픈 소스 엔진엑스 1.11.0 버전부터 제공됩니다. 변수에는 임의로 생성된 32바이트 16진수 값이 할당되며, 이 값은 각 요청을 나타내는 교유값으로 사용할 수 있습니다. 값을 클라이언트와 애플리케이션을 전달함으로써 서비스를 구성하는 여러 요소가 남기는 로그에 공통 식별자로 사용할 수 있습니다. 클라이언트 입장에서는 고유한 식별 문자열을 응답 헤더를 통해 받게 되고, 요청과 관련된 로그 탐색 시 이 값을 사용합니다. 요청 전반에 걸친 로그들의 관계를 찾으려면 애플리케이션이 요청 헤더에서 이 값을 찾아 로그에 기록하도록 합니다. 결과적으로 이 엔진엑스 기능을 통해 애플리케이션의 전체 스택에 걸쳐 요청을 추적할 수 있습니다.  

#### 14.5. 엔진엑스를 위한 오픈트레이싱  
<br/>

오픈트레이싱과 호환되는 서버가 준비돼 있는지 확인하고 엔진엑스 또는 엔진엑스 플러스 노드 환경에 맞는 오픈트레이싱 클라이언트를 설치합니다.  

오픈트레이싱 호환 서버를 사용하기 위한 플러그인 설정 파일이 필요합니다. 이 절에서는 대표적인 오픈트레이싱 클라이언트인 Jaeger와 Zipkin의 플러그인 설정 방법을 살펴봅니다.  

다음 예시는 Jaeger 플러그인 설정으로, /etc/jaeger/jaeger-config.json 경로에 위치한 내용입니다.  

```
{
    "service_name": "nginx",
    "sampler": {
        "type": "const",
        "param": 1
    },
    "reporter": {
        "localAgentHostPort": "Jaeger-server-IP-address:6831"
    }
}
```

Zipkin 플러그인을 사용한다면 /etc/zipkin/zipkin-config.json 경로에 다음 내용으로 설정합니다.  

```
{
    "service_name": "nginx",
    "collector_host": "Zipkin-server-IP-address",
    "collector_port": 9411
}
```

엔진엑스 플러스를 사용한다면 엔진엑스 플러스 저장소에서 오픈트레이싱 모듈을 다운로드해 설치할 수 있으며 자세한 내용은 오픈트레이싱 관리자 가이드(https://oreil.ly/coRQC)에 기술돼 있습니다.  

엔진엑스 오픈 소스 버전을 사용한다면 엔진엑스 오픈트레이싱 모듈 릴리스 페이지(https://oreil.ly/9LYf3)에서 엔진엑스를 운영하는 환경과 시스템에 맞는 오픈트레이싱 동적 모듈을 찾아 엔진엑스 소스 코드와 함께 빌드해 사용할 수 있습니다. 도커를 사용하는 방법도 있습니다. 도커 이미지 저장소인 도커 허브를 통해 opentracing/nginx-opentracing 이미지를 다운로드해 사용하고 사전 설정 작업 없이 바로 시험해볼 수 있습니다.  

엔진엑스 플러스 설치를 포함해 오픈트레이싱 모듈처럼 동적으로 로드되는 모듈을 사용할 때는 엔진엑스가 파일시스템에서 모듈을 찾을 수 있도록 엔진엑스 설정 파일에 load_module 지시자를 통해 모듈을 지정합니다. 다시 한번 강조합니다만 load_module 지시자는 최상위 컨텍스트, 즉 메인 컨텍스트에서만 사용 가능합니다.  

```
load_module moduels/ngx_http_opentracing_module.so;
```

엔진엑스 노드에 설치된 오픈트레이싱 클라이언트 설정에 문제가 없고, 엔진엑스 모듈이 제대로 실행됐으며, 오픈트레이스 호환 서버가 동작하기 시작했다면 엔진엑스는 요청 추적을 시작할 수 있습니다. 다음 예시 설정은 추적기(tracer)를 로드해 엔진엑스가 각 요청에 태그하도록 합니다. Jaeger와 Zipkin 추적기 플러그인을 불러오는 지시자를 포함하며 앞서 설명한 추적기별 설정을 사용합니다. 사용하는 플러그인에 따라 주석 처리된 설정 행을 주석 해제해 시험해보기 바랍니다.  

```
# 추적기를 로드합니다
#opentracing_load_tracer /usr/local/libjaegertracing_plugin.so
#                        /etc/jaeger/jaeger-config.json;
#opentracing_load_tracer /usr/local/lib/libzipkin_opentracing_plugin.so
#                        /etc/zipkin/zipkin-config.json;

# 모든 요청에 대해 추적을 활성화합니다
opentracing on;

# 엔진엑스 변숫값을 취하는 태그를 설정합니다
opentracing_tag bytes_sent $bytes_sent;
opentracing_tag http_user_agent $http_user_agent;
opentracing_tag request_time $request_time;
opentracing_tag upstream_addr $upstream_addr;
opentracing_tag upstream_bytes_received $upstream_bytes_received;
opentracing_tag upstream_cache_status $upstream_cache_status;
opentracing_tag upstream_connect_time $upstream_connect_time;
opentracing_tag upstream_header_time $upstream_header_time;
opentracing_tag upstream_queue_time $upstream_queue_time;
opentracing_tag upstream_response_time $upstream_response_time;

server {
    listen 9001;
    location / {
        # 오픈트레이싱 Spans의 기본 작업 이름은 location 블록 이름을 따라갑니다
        # 이름을 임의로 지정하려면 아래 설정을 주석 해제해 사용합니다
        # opentracing_operation_name $uri;

        # 활성 Span 컨텍스트를 업스트림 서버까지 전파하도록 합니다
        # 이를 통해 요청에 대한 추적이 백엔드 서버까지 이어지게 합니다
        opentracing_propagate_context;

        # 애플리케이션 서버의 경로 예시입니다
        proxy_pass http://10.0.0.2:8080;
    }
}
```

오픈트레이싱 셋업은 별것 아닌 듯해도 분산 서버 환경에서 성능과 트랜잭션을 모니터링하는 데 매우 중요하고 의미 있는 작업입니다. 앞서 살펴본 오픈트레이싱 플러그인들은 개발 및 운영 팀이 발생한 문제의 근본 원인을 찾고 데이터 기반 문제 확인 과정에 필요한 의존성 분석을 호율적으로 수행하도록 해줍니다. 엔진엑스는 API 게이트웨이로 사용되며 요청을 라우팅하고 애플리케이션 간 인증을 수행합니다. 따라서 복잡한 시스템 환경에서 요청을 추적하는 데 필요한 필수 정보를 갖고 있을 수밖에 없습니다.  

엔진엑스는 사용 가능한 모든 변수를 요청 태깅에 쓸 수 있으며, 따라서 추적 시스템 운영자와 관리자는 요청의 동작 행태를 완전히 이해할 수 있습니다. 이 절에 살펴본 간단한 예시는 프록시를 통해 처리되는 요청에 대해 오픈트레이싱을 사용하는 방법을 보여줍니다.  

opentracing_tag 지시자를 http, server, location 컨텍스트에서 사용할 수 있다는 점에 착안하면 엔진엑스를 통해 상당히 많은 데이터를 뽑아낸 수 있음을 알 수 있습니다.  

+ 오픈트레이싱 엔진엑스 모듈 깃허브 저장소: https://oreil.ly/DpgEY
+ 엔진엑스 플러스 오픈트레이싱 동적 모듈 관리자 가이드: https://oreil.ly/coRQC
+ 데이터독(Datadog) 오픈트레이싱 엔진엑스 모듈 플러그인 가이드: https://oreil.ly/f4leF
+ 엔진엑스 블로그 게시글 '엔진엑스 및 엔진엑스 플러스 오픈트레이싱(OpenTracing for NGINX and NGINX Plus): https://oreil.ly/2WUJW
+ 엔진엑스 블로그 게시글 '쿠버네티스 환경에서 엔진엑스 인그레스 컨트롤러와 오픈트레이싱 활성화하기(Enabling OpenTracing with NGINX Ingress Controller for Kubernetes)': https://oreil.ly/GlqZL  

### 15. 성능 튜닝  
<br/>

#### 15.1. 로드 드라이버로 시험 자동화하기  
<br/>

아파치의 로드 드라이버인 제이미터(JMeter), 로커스트(Locust), 개틀링(Gatling)혹은 팀에서 사용 중인 HTTP 부하 시험 도구를 사용합니다. 대상 웹 애플리케이션을 꼼꼼히 시험할 수 있도록 부하 시험 도구를 위한 설정을 만듭니다. 그리고 서비스에 시험을 수행한 뒤 시험에서 수집한 지표를 검토해 필요한 성능 기준을 정합니다. 천천히 동시 접속자를 늘려가면서 실제 서비스 환경을 사용 패턴과 흡사한 부하를 에뮬레이션하고 개선이 필요한 부분을 확인합니다. 원하는 결과를 얻을 때가지 엔진엑스 튜닝하고 시험 절차를 반복합니다.  

자동화된 시험 도구를 사용해 성능 시험을 정의하면 일관성 있는 시험을 수행할 수 있습니다. 이 시험을 통해 엔진엑스 튜닝에 사용할 지표를 만듭니다. 시험은 반복 가능해야 하며 성능 이득이나 손실을 측정할 수 있어야 합니다. 따라서 엔진엑스 설정을 변경하기 전에 동일한 시험을 수행함으로써 엔진엑스 설정 변경이 성능을 개선하는지 혹은 저하시키는지 확인할 성능의 기준점을 만듭니다. 각 변경이 성능에 미치는 영향을 측정하며 성능이 어느 지점에서 향상하는지 파악하는 데 도움이 됩니다.  

#### 15.2. 클라이언트와의 연결 유지하기  
<br/>

keepalive_requests와 keepalive_timeout 지시자를 사용해 단일 연결이 허용하는 요청 수를 늘리고 유휴 연결이 유지되는 시간을 제어합니다.  

```
http {
    keepalive_requests 320;
    keepalive_timeout 300s;
    # ...
}
```

keepalive_requests 지시자의 기본값은 100이며 keepalive_timeout 지시자의 기본값은 75초입니다.  

단일 연결이 소화할 수 있는 요청 수의 기본 설정값은 일반적으로 클라이언트의 요구사항에 부합합니다. 근래에 출시된 브라우저들은 FQDN별로 단일 서버에 대해 연결을 여러 개 맺도록 허용하기 때문입니다. 하지만 특정 도메인에 대한 동시 연결 수는 보통 10개 이하로 제한되며, 따라서 단일 연결에 많은 요청이 전달되는 상황이 발생합니다. 제한을 극복하기 위해 HTTP 1.1에서는 CDN과 같은 별도 네트워크를 활용해 동일한 원본 서버로 요청을 보내는 여러 개의 도메인을 생성합니다. 브라우저는 여러 도메인을 통해 다수의 연결을 만들고 동시에 더 많은 요청을 보냅니다. 이러한 최적화 방식은 프런트엔드 애플리케이션이 지속적으로 백엔드 애플리케이션으로 요청을 보내고 업데이트를 받는 구조에서 무척 유용합니다. 이미 생성된 연결이 많은 요청을 처리할 수 있고 오랫동안 유지되므로 연결 수를 필요한 요청 수만큼 늘리지 않아도 됩니다.  

#### 15.3. 업스트림 서버와의 연결 유지하기  
<br/>

업스트림 컨텍스트에 keepalive 지시자를 사용해 업스트림 서버와 이미 맺어진 연결이 재사용되도록 합니다.  

```
proxy_http_version 1.1;
proxy_set_header Connection "";

upstream backend {
    server 10.0.0.42;
    server 10.0.2.56;
    keepalive 32;
}
```

업스트림 컨텍스트에서 keepalive 지시자를 사용해 각 엔진엑스 워커가 업스트림 서버와 맺은 연결을 캐시하도록 합니다. keepalive는 워커 프로세스별로 유휴 연결을 최대 몇 개까지 유지할 지 지정하며, keepalive가 업스트림 서버와 연결을 유지하게 하려면 예시에서 사용한 프록시 모듈 지시자들을 반드시 사용해야 합니다. proxy_http_version 지시자는 프록시 모듈이 HTTP 1.1 버전을 사용하게 함으로써, 맺어진 연결을 통해 다수의 요청이 처리되도록 해줍니다. proxy_set_header 지시자는 프록시 모듈이 Connection 헤더의 기본값인 close를 지우고 연결이 계속 열려 있도록 합니다.  

업스트림 서버와 맺은 연결을 유지하면 연결 과정에 소요되는 시간이 절약되며 워커 프로세스가 유휴 연결을 활용할 수 있습니다. 유의할 점은 keepalive 지시자에 지정된 연결 수와 실제 맺어진 연결 수가 다를 수 있다는 점입니다. 유휴 연결 수와 맺어진 연결 수는 같은 개념이 아닙니다. keepalive 연결 수는 서비스 부하 수준에 맞춰 충분히 작게 유지돼야 합니다. 그렇지 않으면 업스트림 서버로 향하는 다른 연결 요청이 실패할 수 있습니다. 이처럼 간단한 엔진엑스 튜닝 팁을 활용해 연결을 다룰 때 발생하는 반복 작업을 줄이고 서버 성능을 개선할 수 있습니다.  

#### 15.4. 응답 버퍼링  
<br/>

프록시 버퍼 설정을 변경해 엔진엑스가 메모리에 업스트림 서버의 응답을 저장하도록 합니다.  

```
server {
    proxy_buffering on;
    proxy_buffer_size 8k;
    proxy_buffers 8 32;
    proxy_busy_buffers_size 64k;
    # ...
}
```

proxy_buffering 지시자는 on 또는 off 값으로 설정하며 기본값은 on입니다. proxy_buffer_size 지시자는 업스트림 서버 응답의 앞부분인 헤더 정보를 저장할 버퍼의 크기를 지정하며 기본값은 플랫폼에 따라 4KB 또는 8KB로 설정됩니다. proxy_buffers 지시자는 매개변수로 버퍼 개수와 버퍼 크기를 지정합니다. 기본적으로는 버퍼를 8개 사용하며 버퍼 크기는 플랫폼에 따라 4k 혹은 8k입니다. 엔진엑스는 클라이언트의 요청에 빠르게 반응하기 위해 업스트림 서버의 응답을 완전히 수신하지 않았더라도 클라이언트로 응답을 시작합니다. proxy_busy_buffers_size 지시자는 이를 위해 사용 가능한 버퍼 크기의 상한선을 정하며 기본값은 단일 proxy_buffers나 proxy_buffer_size에 지정된 값의 두 배입니다. proxy_buffering이 비활성화됐다면, 최초 사용자의 요청이 전달된 업스트림 서버가 오류 응답을 할 때 다른 업스트림 서버로 요청을 재전송하지 못하게 됩니다. 응답을 버퍼에 저장하지 않고 이미 사용자에게 전달하기 시작했기 때문입니다.  

응답 바디 크기에 따라 차이는 있지만 프록시 버퍼를 사용하면 엔진엑스 프록시의 성능이 크게 향상됩니다. 관련 설정 튜닝으로 인해 부작용이 발생할 수 있으므로 평균 응답 바디 크기와 성능을 고려해야 하며 반복 시험을 통해 적절한 값을 찾아야 합니다. 버퍼 용량을 불필요하게 크게 할당하면 엔진엑스가 동작할 때 필요한 서버의 메모리 자원을 많이 점유하게 됩니다. 따라서 버퍼 관련 설정은 업스트림 서버의 응답 특성이 파악된 특정 location 블록 단위로 사용해 최적의 성능을 발휘하도록 해야 합니다.  

+ 엔진엑스 proxy_request_buffering 모듈 공식 문서: https://oreil.ly/zL1LK  

#### 15.5. 접근 로그 버퍼링  
<br/>

접근 로그를 저장할 버퍼 크기와 버퍼 플러시(flush) 시간을 설정합니다.  

```
http {
    access_log /var/log/nginx/access.log main buffer=32k flush=1m gzip=1;
}
```

access_log 지시자의 buffer 매개변수는 로그를 디스크에 기록하기 전에 쌓아둘 수 있는 메모리 버퍼의 크기를 나타내며 flush 매개변수는 메모리 버퍼에 쌓인 로그가 디스크에 기록되기 전까지 기다릴 수 있는 최대 시간을 나타냅니다. 로그를 압축해 저장하려면 gzip 매개변수를 사용해 압축률에 따라 레벨 1부터 레벨 9가지 지정합니다. 레벨 1은 속도가 가장 빠르지만 압축률이 낮으며 레벨 9는 압축 효율이 가장 좋지만 속도가 느립니다.  

로그 데이터를 메모리에 버퍼링하는 작업은 최적화를 향한 작은 첫걸음입니다. 사용자 요청이 아주 많은 사이트나 애플리케이션에 적용하면 디스크와 CPU 사용률에 상당히 의미 있는 변화를 줍니다. access_log 지시자에 buffer 매개변수를 사용하면 처리할 로그가 버퍼에 저장하기에 적당한지 살펴본 후 필요시 버퍼에 저장하지 않고 디스크에 바로 기록합니다. buffer 매개변수와 flush 매개변수를 함께 사용하면 로그를 flush에 지정한 시간만큼 메모리에 보관한 뒤 디스크에 기록합니다. 버퍼링을 활성화된 상태로 디스크의 로그 파일을 따라가보면 flush 매개변수에 지정한 시간만큼 로그의 쓰기 작업이 지연됨을 쉽게 확인할 수 있습니다.  

#### 15.6. 운영체제 튜닝  
<br/>

커널 설정 중 net.core.somaxconn 값을 확인합니다. 이 값은 엔진엑스가 요청을 처리하도록 커널이 큐잉(queuing)할 수 있는 최대 연결 수를 나타냅니다. 512보다 큰 값으로 지정한다면 엔진엑스 설정의 listen 지시자의 backlog 매개변수가 같은 값을 갖도록 설정해야 합니다. net.core.somaxconn 값을 설정해야 하는 시점은 커널이 커널 로그에 명시적으로 값을 설정하라고 메시지를 남길 때입니다. 엔진엑스는 연결을 매우 빠르게 처리하므로 보통은 값을 조정할 필요가 없습니다.  

시스템 성능 튜닝 시 파일 디스크립터(file descriptor)의 수를 늘리는 방법을 널리 사용합니다. 리눅스 환경에서 파일 핸들(handle)은 새로운 연결이 생성될 때마다 열리며, 따라서 엔진엑스를 프록시나 로드 밸런서로 사용하는 경우 클라이언트와 업스트림으로 각각 연결을 맺으므로 파일 핸들도 두 개가 열립니다. 대량의 연결을 처리하기 위해 커널의 sys.fs.file_max 옵션을 조정해 시스템의 파일 디스크립터 수를 충분히 늘리거나, 엔진엑스가 시스템 사용자를 통해 실행되는 경우 /etc/security/limits.conf 파일의 내용을 조정할 수 있습니다. 이렇게 시스템 설정을 변경하면서 엔진엑스 설정의 worker_connections와 worker_rlimit_nofile 지시자의 매개변수도 커널 설정 변경에 맞춰 늘려둡니다.  

마지막으로 더 많은 연결을 처리할 수 있도록 임시(ephermeral) 포트를 활성화합니다. 엔진엑스가 리버스 프록시나 로드 밸런서로 동작하면 모든 업스트림 연결은 응답 트래픽을 받기 위해 임시 포트를 열게 됩니다. 이때 필요한 임시 포트의 최대 개수느느 시스템 설정에 따라 충분하지 못할 수도 있습니다. 최대 개수를 확인하려면 커널 설정 중 net.ipv4.ip_local_port_range 값을 살펴봅니다. 이 설정은 최솟값과 최댓값이 있으며 일반적으로 1024에서 65535는 동적 포트나 임시 포트를 할당할 수 있는 마지막 번호입니다. 다만 포트 설정의 최솟값은 엔진엑스가 수신하는 포트 번호보다 커야 한다는 점을 주의합시다.  

운영체제 튜닝은 많은 연결을 수용하기 위한 시스템 튜닝 시 우선적으로 살펴볼 영역입니다. 사용 방식에 따라 시스템 커널에서 다양한 최적화를 수행할 수 있습니다. 하지만 커널 튜닝은 기분에 따라 하는 것이 아니며 변경한 값이 성능을 충분히 향상하는지 측정하고 도움이 되는지 판단해야 합니다. 앞서 이야기했듯 커널 튜닝을 시작하는 시점은 커널 로그 메시지에서 커널 설정값 조정이 필요하다는 메시지를 발견하거나 엔진엑스 오류 로그에서 명시적으로 관련 내용이 언급될 때임을 기억하기 바랍니다.  

### 16. 엔진엑스 인스턴스 매니저  
<br/>

#### 16.0. 소개  
<br/>

엔진엑스 인스턴스 매니저(NGINX Instance Manager)는 엔진엑스 인스턴스 에이전트와 함께 활용되는 서비스로, 동작 중인 엔진엑스 인스턴스의 TLS 인증서나 네트워크를 살펴볼 수 있습니다. 서비스에 제공된 인스턴스와 인증서 목록은 웹 서버와 프록시 서버들을 단일 인터페이스 혹은 API를 이용해 넓은 시야로 바라보도록 해줍니다. 특히, API를 이용하면 데이터 플레인(data plane)을 살펴보고 점검하고 업데이트하는 일련의 작업을 사용 중인 도구나 워크플로와 통합함으로써 자동화할 수 있습니다.  

엔진엑스 인스턴스 매니저 에이전트는 엔진엑스나 엔진엑스 플러스의 지표를 수집하고 중앙화된 인터페이스를 이용해 각 인스턴스의 설정을 직접 점검하거나 업데이트합니다. 엔진엑스 인스턴스 매니저를 엔진엑스 인스턴스에 대한 지표 수집 통합 지점으로 이용하면 각 엔진엑스 설정에 스텁 상태(stub status)를 추가하거나 자표 수집 플랫폼으로 엔진엑스 플러스 지표 API인 종단점 정보를 통합하는 작업의 복잡도가 낮아집니다. 다만 엔진엑스 인스턴스 매지너는 별도의 라이선스를 이용하는 상용 제품이므로 먼저 무료 시험용 버전으로 기능을 시험하고 그 가치를 확인해보기 바랍니다.  

#### 16.1. 셋업 개요  
<br/>

엔진엑스 인스턴스 매니저 서버를 설치할 때도 다른 유료 엔진엑스 제품을 설치할 때와 비슷한 절차를 따릅니다. 필요한 라이선스 파일을 미리 갖춰야 하며 패키지나 저장소에 대한 인증서 키 페이도 필요합니다. 필요한 파일이 모두 준비됐다면 여러분의 시스템 환경에서 제공하는 패키지 관리자로 소프트웨어를 설치합니다. 설치에 관한 최신 정보는 엔진엑스 인스턴스 매니저 설치 가이드를 살펴보기 바랍니다.  

엔진엑스 인스턴스 매니저를 설치했으면 제공되는 UI를 살펴봅시다. 처음 실행하면 인벤토리에 아무것도 저장돼 있지 않습니다.  

동작 중인 엔진엑스 인스턴스를 찾기 위해 '스캔(scan)' 탭으로 이동합니다. 여기에서 여러분의 네트워크에서 동작 중인 엔진엑스와 엔진엑스 플러스 서버를 찾을 수 있습니다. 스캔 도구는 NMAP을 이용해 엔진엑스 웹 서버가 사용할 것으로 생각되는 포트를 조사합니다. 스캔 대상 포트로부터 수신 중인 호스트가 있다면 엔진엑스 인스턴스 매니저는 그것이 엔진엑스 서버인지 확인하고, 맞다면 버전 정보를 취득합니다. 이 과정은 서버로 보낸 요청에 대한 응답의 Server 헤더 정보를 조사해 확인합니다.  

스캔이 종료되면 발견된 인스턴스에 대한 정보를 담은 표가 나타납니다. 표는 각 인스턴스에 대한 상세 정보를 보여줍니다. 엔진엑스 인스턴스가 발견되면 엔진엑스 버전에 따라 영향받을 수 있는 취약점(common vulnerabilities and exposure, CVE)에 대한 확인이 진행되고 그 결과가 나타납니다. 이 결과는 필요한 패치 탐색을 자동화함으로써 여러분의 엔진엑스 서버를 안전하게 유지하는 데 도움이 됩니다.  

'인증서(Certs)' 페이지에서는 TLS를 이용하도록 설정된 호스트를 살펴볼 수 있습니다. 이 도구는 기본적으로 호스트 스캔과 같은 방식으로 동작하되, 사용 중인 인증서를 분석하고 인증서에 대한 일반 이름(common name), 만료 일자(expiration date)같은 정보를 추가로 제공합니다. 이 도구는 사용 중인 인증서를 확인하고 각 인증서에 업데이트가 필요한지 확인하는 데 도움이 됩니다.  

한편 '세팅(Settings)' 페이지에서는 엔진엑스 인스턴스 매니저 라이선스, 관련 기술 문서, API 명세 그리고 지표에 대한 원격 측정을 어떻게 설정하는지 등을 확인할 수 있습니다. 그리고 사용자 등록, 역할 생성 및 할당을 수행해 사용자가 어떤 일을 수행할 수 있는지도 이 페이지에서 지정합니다.  

이처럼 여러 엔진엑스 인스턴스를 통합 관리하려면 각 엔진엑스 서버에 엔진엑스 인스턴스 매니저 에이전트를 설치해야 합니다.  

+ 엔진엑스 인스턴스 매니저 관리자 가이드: https://oreil.ly/3nwIc  

#### 16.2. 에이전트 설치  
<br/>

다음 명령으로 엔진엑스 인스턴스 매니저 서버에서 필요한 에이전트 파일을 다운로드하고 설치 스크립트를 실행해 엔진엑스 인스턴스 매니저 에이전트를 설치합니다.  

```
curl -k https://<엔진엑스 인스턴스 매니저의 호스트명 또는 IP 주소>/install /nginx-agent | sudo sh
```

기본 설치는 이 명령만으로 충분합니다. 화면에 표시되는 인스턴스 이름이나 위치, 혹은 인스턴스 그룹 정보를 설정하려면 /etc/nginx-agent/dynamic-agent.conf 파일 내용을 업데이트한 후 nginx-agent 서비스를 재시작합니다.  

```
# /etc/nginx-agent/dynamic-agent.conf
# 엔진엑스 인스턴스 매니저 에이전트를 위한 동적 설정 파일
#
# 이 파일은 에이전트 설치 스크립트가 API 호출로 동적으로 변경할 수 있는
# 에이전트 설정을 추적하기 위한 파일입니다.
# 이 파일은 수정할 수 있습니다만, 이 시스템의 태그값을 수정하는 API 요청은
# 이 파일에 기술된 태크값을 덮어쓸 수 있습니다.
#
# API 호출로 수정할 수 있는 에이전트 설정값은 다음과 같습니다.
# - tags #
# 에이전트 설치 스크립트로 수정할 수 있는 에이전트 설정값은 다음과 같습니다.
# - instance_name
# - instance_group
# - location
# 예시
instance_name: nginx1.example.org
instance_group: internal
location: clound1
```

여러분의 엔진엑스나 엔진엑스 플러스 인스턴스에 엔진엑스 인스턴스 매니저 에이전트를 설치했다면 엔진엑스 인스턴스 매니저의 인벤토리 페이지에서 인스턴스 목록을 확인할 수 있습니다. 호스트명, 엔진엑스가 설치된 방식, 태그, 연결 상태 등 호스트에 대한 상세 정보를 표로 보여줍니다.  

인스턴스를 선택하면 화면 오른쪽에 더 자세한 정보가 표시되며 수정할 수 있는 옵션이 제공됩니다. '수정(Edit)' 버튼을 누르면 인스턴스의 현재 엔진엑스 설정이 출력되고, 설정 내용을 확인하거나 에디터를 이용해 설정값을 수정할 수 있습니다. 인스턴스가 사용 중인 다른 설정 파일로 바꾸려면 데이터 오른쪽 위의 초록색 드롭다운 버튼을 누릅니다. 설정 내용을 변경했으면 바뀐 내용을 설정에 저장하고, 변경된 설정 파일을 반영하려면 발행(publish) 기능으로 엔진엑스 설정을 리로드해야 합니다. 이처럼 저장과 발생 기능이 분리돼 있어 작업 대상 엔진엑스 서버의 리로드 전에 여러 설정 파일에 변경 작업을 수행할 수 있습니다.  

#### 16.3. API로 엔진엑스 탐색, 설정, 모니터링 자동화하기  
<br/>

엔진엑스 인스턴스 매니저는 설치된 API 버전에 대한 무서를 제공하는 스웨거UI(SwaggerUI)를 통해 오픈API 명세를 제공합니다. 인스턴스 매니저의 '문서(Docs)' 메뉴에서 확인 가능합니다.  

여러분의 네트워크를 주기적으로 스캔해 엔진엑스 인스턴스와 인증서를 확인하는 편이 좋습니다. 수집된 정보는 패치가 필요한 CVE가 만료가 가까운 인증서에 대한 경로르 발송하는 데 사용할 수 있습니다.  

엔진엑스 인스턴스나 인증서에 대한 스캔을 시작하려면 엔진엑스 인스턴스 매니저의 /api/platform/v1/servers/scan 종단점에 CIDR 표기법으로 기술된 스캔 대상 IP 주소와 포트 정보를 포함한 POST 요청을 보냅니다.  

```
curl -X 'POST' 'https://nginx-manager.example.com/api/platform/v1/servers/scan' -H 'accept: application/json' -H 'Content-Type: application/json' \
-d '{
    "cidr": "string",
    "hostDiscovery": "icmp",
    "portRanges": [
        "10.0.1.0/24"
    ]
}
```

진행 중인 스캔 작업을 취소하려면 같은 종단점에 DELETE 요청을 보내고, 진행 중인 스캔 작업의 상태를 확인하려면 GET 요청을 보냅니다.  

스캔 완료된 엔진엑스 인스턴스나 인증서 정보를 확인하려면 /api/platform/v1/scan/servers로 GET 요청을 보냅니다.  

인스턴스 매니저로 관리 중인 엔진엑스 인스턴스의 전체 목록을 보려면 /api/platform/v1/instances 경로로 GET 요청을 보냅니다. 응답은 인스턴스 ID를 포함하며, 이는 계속해서 설정 파일 정보를 조회하는 데 사용할 수 있습니다. 설정 파일들 역시 API를 통해 업데이트되거나 발생될 수 있습니다. 이 기능은 엔진엑스 인스턴스에 대한 설정 업데이트를 자동화하는 데 유용합니다. API에 대한 최신 정보는 오픈API 스펙을 참고하기 바랍니다.  

엔진엑스 인스턴스 매니저는 관리 중인 인스턴스에 대한 지표 정보도 제공합니다. 외부의 지표 수집 도구는 API를 통해 엔진엑스 인스턴스 매니저로부터 직접 지표 정보를 획득할 수 있습니다. API로 확인할 수 없는 지표 정보는 인스턴스 인벤토리 페이지에서 대상 인스턴스를 선택한 뒤 '지표 조회(View Metrics)' 링크를 눌러 조회합니다.  

엔진엑스 인스턴스 매니저의 RESTful API는 여러분의 현재 사용하는 자동화 및 데브옵스 워크플로에 엔진엑스 관리를 통합할 방법을 제공합니다. 지표 수집과 분석은 서비스 전달 환경을 최적화하기 위해 설정 변경에 관한 의사 결정을 하는 데 기초가 됩니다. 그리고 엔진엑스 인스턴스의 지표를 수집할 때 엔진엑스 인스턴스 매니저를 통합 지점으로 활용함으로써 지표 수집의 복잡도를 줄일 수 있습니다.  

+ 엔진엑스 인스턴스 매니저 API 개요: https://docs.nginx.com/nginx-manangement-suite/nim/abount/api-overview
+ 지표 API 활용하기: https://oreil.ly/uH5Ul  

### 17. 엔진엑스 컨트롤러  
<br/>

#### 17.0. 소개  
<br/>

엔진엑스 컨트롤러는 애플리케이션 중심의 컨트롤 플레인(control plane)입니다. 물리적 위치에 관계없이 애플리케이션을 구성하는 모든 엔진엑스 플러스 서버군을 확인하고 셋업하도록 해주는 인터페이스를 제공합니다. 컨트롤러를 사용하면 엔진엑스 플러스 설정 자체보다 엔진엑스 플러스가 클라이언트에 전달하는 애플리케이션에 더 집중할 수 있습니다.  

#### 17.1. 셋업 개요  
<br/>

엔진엑스 컨틀로러 공식 설치 가이드(https://oreil.ly/oM1PL)에서 최신 설치 방법을 확인합니다. 가이드에서 컨트롤러 설치 주의 사항, 알려진 시행착오들, 참고 사항을 살펴봅시다.  

엔진엑스 컨트롤러 3.x 버전은 쿠버네티스 스택으로 설치됩니다. 설치를 시작하기 전에 기술 스펙(https://oreil.ly/OiOCD) 전체를 살펴볼 필요가 있습니다. 엔진엑스 컨트롤러를 사용하려면 별도로 동작하는 PostgreSQL 데이터베이스가 필요합니다. 컨트롤러 인스톨러는 traball 형태의 압축 파일로 제공됩니다. 압축 파일을 풀면 나오는 install.sh 스크립트를 루트 사용자 이외의 권한을 가진 사용자로 실행합니다.  

일부 운영체제 환경에서 이미지 배포 방식의 차이 때문에 다른 패키지 저장소를 사용해야 하는 경우가 있으며, 이때 컨트롤러 설치가 다소 까다롭습니다. 필자가 시험한 바에 따르면 우분투 20.04가 가장 안정적이었으므로 해당 환경에서 컨트롤러를 설치하고 시험해보기를 추천합니다. 물론 엔진엑스 서포트(NGINX Support)를 이용하면 엔진엑스 컨트롤러를 빠르게 설정하고 사용하는 데 도움이 됨을 잊지 맙시다.  

엔진엑스 컨트롤러가 제대로 동작하려면 몇 가지 도구가 미리 설치돼 있어야 합니다. 많은 운영체제 환경에서 대부분의 도구는 표준이지만 JSON 사용을 돕는 jq와 같은 도구는 표준이 아닙니다. 설치 스크립트를 실행하기 전에 필요한 도구가 모두 시스템에 설치됐는지 미리 확인합시다.  

helper.sh 스크립트는 설치 패키지에서 제공되며 설치나 설정 변경 과정을 도와줍니다. 예를 들어, supportpkg 인수는 디버그 패키지를 빌드하고 엔진엑스 서포트 팀으로 로그 정보를 보내 문제 상황을 신속하게 확인하도록 해줍니다. prereqs 인수는 쿠버네티스를 사용하는 데 필요한 패킬지를 설치하고 쿠버네티스를 설치합니다. 엔진엑스 컨트롤러에서 로그를 보려면 ./hepler.sh logs 명령을 사용합니다.  

installer 명령이 실행되면 시스템 요구하항을 만족하는지 점검하고 추가로 필요한 패키지를 설치합니다. 데이터베이스 접근을 위해 installer는 데이터베이스 사용자 정보 입력을 요구합니다. 현재 PostgreSQL을 사용할 수 있으며 동일 서버가 아닌 별도의 서버에서 실행 중이어야 합니다. 물론 입력된 사용자 정보는 데이터에비스를 생성할 권한이 있어야 하며, 명령줄 인수를 통해 installer에 전달됩니다.  

상황에 따라 시계열 데이터베이스 볼륨을 제공해야 할 수도 있습니다. 이를 위해 서버의 로컬 디스크를 사용하거나 NFS 볼륨 혹은 AWS의 EBS 볼륨을 이용합니다. AWS의 EBS 볼륨을 사용할 경우 시스템은 볼륨을 인스턴스에 붙이기 위해 적절한 AWS IAM 권한을 요구합니다.  

설치를 계속 진행하려면 최종 사용자 라이선스에 동의합니다. 문서를 읽은 후 동의하지 않고 화면을 나가려면 q를 누르고, 문제가 없다면 y를 눌러 동의 후 설치를 계속 진행합니다.  

이메일로 사용자를 초대하거나 공지를 발송하려면 SMTP 서버가 필요합니다. SMTP 서버를 사용할 수 없는 상황이라면 나중에 helper.sh 스크립트를 이용해 설정할 수 있습니다. SMTP 설정을 위한 질문에 대해서는 일반적인 값을 넣습니다. 예를 들어, 호스트명은 localhost로 지정하고 포트는 SMTP의 기본 포트인 25로 지정합니다. 그 외에 사용자 인증이나 TLS 사용여부 등을 입력합니다. SMTP 서버가 준비되기 전까지는 엔진엑스 컨트롤러가 이메일을 사용할 수 없음을 기억하기 바랍니다.  

에이전트(Agent) 설정을 생성할 때는 FQDN 정보가 사용되며, FQDN은 확실한 도메인으로 설정돼야 합니다. 조직 이름을 묻는 질문에는 회사 이름이나 팀 이름처럼 레이블링하기 좋은 친숙한 이름을 쓰면 좋습니다. 관리자에 대한 정보를 입력할 때는 이메일 주소가 시스템 로그인 계정으로 쓰인다는 점에 유의합시다.  

SSL/TLS 인증서 경로는 installer의 명령줄 매개변수나 시스템 환경 변수를 통해 제공할 수 있습니다. 이 경로에서 인증서가 확인되지 않으면 installer는 바로 자체 서명 인증서(self-signed certificate)를 만들어 사용합니다.  

설치가 완료되면 installer는 컨트롤러 접근을 위한 링크를 제공합니다. 링크를 따라 등록한 관리자로 접속합니다.  

엔진엑스 컨트롤러는 애플리케이션을 관리하기 위한 단일 컨트롤 플레인을 제공합니다. 사용자 인터페이스는 여러 가지 뷰(view)를 제공하며 플랫폼, 인프라스트럭처, 서비스, 분석 도구 등으로 나뉩니다. 적절히 나뉜 뷰는 각 화면에서 무엇을 해야 할지 명확하게 보여줍니다.  

플랫폼 뷰는 컨트롤러와 사용자 접근을 관리하는 데 활용되며, 인프라스트럭처 뷰는 엔진엑스 컨트롤러 에이전트를 실행시키는 서버에 대한 상세 정보를 제공합니다. 다음 절에서는 엔진엑스 플러스 서버에 에이전트를 설치해 엔진엑스 플러스 인스턴스를 컨트롤러에 추가하는 방법 서비스 뷰는 엔진엑스 컨트롤러가 표방하는 애플리케이션 중심이라는 개념이 무엇인지 보여줍니다. 컨트롤러는 애플리케이션, 운영 환경, 게이트웨이, API를 조직화해 서비스 인프라스트럭처 구조를 정비하고 빠르게 배포하도록 해줍니다.  

+ 엔진엑스 컨트롤러 설치하기: https://oreil.ly/QCZmq
+ 엔진엑스 컨트롤러 기술 스펙: https://oreil.ly/T0fiy
+ 엔진엑스 컨트롤러를 위해 PostgreSQL 설치 및 준비하기: https://oreil.ly/Yb_zm  

#### 17.2. 엔진엑스 플러스를 컨트롤러와 연결하기  
<br/>

엔진엑스 컨트롤러 설치에 대한 문서는 컨트롤러 설치 시 서버에 함께 설치된 문서를 참고합니다. 문서는 서버의 FQDN을 이용해 https://<Controller-FQDN>/docs/infrastructure/agent 경로에서 확인할 수 있으며, 엔진엑스 컨트롤러 에이전트 사용에 필요한 기술 스펙, 설치 및 관리 방법을 제공합니다.  

운영 중인 엔진엑스 플러스에 컨트롤러 에이전트를 설치하는 작업은 간단합니다. 서버의 포트 8443에서 제공되는 컨트롤러 API를 이용해 설치 스크립트를 확보하고 API 키를 이용해 스크립트를 실행합니다. 컨트롤러 UI는 환경에 복사해 붙여 넣으면 바로 사용할 수 있는 명령을 제공합니다. 설치가 끝나면 운영체제가 제공하는 서비스 관리자를 통해 컨트롤러를 실행할 수 있습니다.  

컨트롤러 에이전트가 실행되면 컨트롤러의 인프라스트럭처 뷰에서 가동 중인 엔진엑스 인스턴스를 볼 수 있습니다.  

엔진엑스 플러스 시스템의 인벤토리는 API 요청 목록과 함께 인프라스트럭처 뷰에 출력됩니다. 엔진엑스 컨트롤러에 활성 인스턴스가 한 개 이상 등록돼 있다면 인프라스트럭처 뷰의 '그래드(Graph)' 탭에서 서버와 엔진엑스 플러스의 지표를 확인할 수 있습니다. 플랫폼 뷰의 '에이전트(Agent)' 탭에서 엔진엑스 설정 분석기를 활성화하는 설정이 있습니다. 분석기가 활성홤되면 인프라스트럭처 뷰의 '분석(Analysis)' 탭이 활성화됩니다. 분석 탭은 설치된 엔진엑스 플러스 서버와 현재 사용 중인 설정에 대한 정보를 보여줍니다.  

이제 컨트롤러 에이전트가 설치된 엔진엑스 플러스 노드를 확보했습니다. 동일하 설정인 노드를 만들려면 이 서버의 부팅 가능한 이미지를 만들거나 설치 작업을 지원할 빌드 설정 관리를 만듭니다. 인스턴스가 설정되면 서비스 셋업을 시작할 수 있습니다. 서비스는 필요한 애플리케이션, 환경, 클라이언트에 서비스가 어떻게 제공되는지와 같은 정보로 구성합니다.  

+ 엔진엑스 컨트롤러 에이전트 설치하기: https://oreil.ly/x40XD  

#### 17.3. API를 이용해 엔진엑스 컨트롤러 운영하기  
<br/>

포트 8443을 통해 제공되는 엔진엑스 컨트롤러의 API를 호출할 수 있는지 확인합니다. 엔진엑스 컨트롤러는 기본적으로 API로 설정하고 사용하도록 권장됩니다. 엔진엑스 컨트롤러의 인터페이스는 API로 쉽게 접근할 수 있으며 대시보드 사용을 전제합니다. API 사용법은 https://<Controller-FQDN>/docs/api/api-reference에서도 찾아볼 수 있습니다.  

API를 이용한 자동화를 빠르게 적용해보려면 엔진엑스 컨트롤러 인터페이스에서 이미 적용된 항목을 찾아 직접 수정하거나 API 규격을 참고해 수정합니다. API 규격은 자동화에 필요한 API 메서드, 경로, 페이로드에 대한 내용을 담고 있습니다. 몇 가지 변수를 사용해 엔진엑스 컨트롤러 자동화를 시작할 수 있습니다.  

어떤 엔지니어에게는 API가 엔진엑스 컨트롤러와 상호 작용을 하는 주요 지점일 수 있지만 어떤 엔지니어에게는 웹 인터페이스가 더 익숙할 수 있습니다. 두 접근 방법 모두 가능하며 컨트롤러를 사용하는 유용한 방법입니다. 사실 웹 인터페이스가 사용하는 PAI 요청을 살펴봄으로써 API 문서를 공부할 때보다 더 빠르게 자동화를 구현할 수 있습니다. 엔진엑스 컨트롤러 자동호를 위한 앤서블 설정 컬렉션이 있다는 점도 기억해두기 바랍니다.  

+ 엔진엑스 블로그 게시글 '엔진엑스 컨트롤러에 대한 앤서블 컬렉션 사용(Getting Started with the Ansible Collection for NGINX Controller)': https://oreil.ly/VCdY7  

#### 17.4. 컨트롤러 앱 시큐리티를 이용해 WAF 활성화하기  
<br/>

+ 엔진엑스 컨트롤러 ADC를 사용하면서, 서비스 중인 애플리케이션을 위해 엔진엑스의 웹 애플리케이션 방화벽(Web Application Firewall, WAF) 활성화하기  

아직 엔진엑스 플러스에 대한 보안을 설정하지 않았다면 엔진엑스 웹 프로텍트 WAF 설치 가이드(https://oreil.ly/kgpHa)에서 제시하는 플랫폼별 설정 가이드를 참고해 엔진엑스 앱 프로텍트 모듈을 설치하고 설정합니다. 엔진엑스 컨트롤러 앱 컴포넌트(App Component) 설정의 시큐리티(Security) 항목에서 WAF 헤더 혹은 설정을 찾습니다. 항목을 찾았으면 WAF를 활성화하고 저장합니다.  

WAF는 기본 WAF 정책에 따라 애플리케이션에 대한 요청을 처리합니다. 기본 정책은 모든 공격성 요청의 시그니처에 경고만 하도록 돼 있습니다. 다만 시그니처와 일치율이 높은 요청은 차단합니다. 일치율은 오탐 확률을 결정하는 알고리즘에 따르며, 정책을 위반한 요청에 대한 정보를 지속적으로 수집하면서 시스템에 악영향을 주는 요청은 바로 차단합니다. 악의적일 수도 있는 요청과 차단된 요청은 엔진엑스 컨트롤러 UI에 출력되며 적절히 레이블링됩니다. 엔진엑스 컨트롤러 ADC는 WAF 통계와 WAF 정책을 위반한 요청에 대한 정보를 보여줍니다.  

중요한 것은 애플리케이션이 일정 규모의 트래픽을 처리하고 응답해야 한다는 점입니다. 이를 확인하기 위해 WAF 정책이 차단하거나 악성 요청으로 판단할 만한 요청을 보내 시험해봅니다. 다음 SQL 삽입(SQL Injection) 명령은 매우 기본적인 악성 요청으로, WAF 정책을 시험하기 좋은 예입니다.  

```
curl https://{appComponentEndpoint}/?query=9999999%20UNION%20SELECT%201%2C2
```

정책을 위반해 보안 이벤트가 발생하면 엔진엑스 컨트롤러 ADC는 보안 분석을 위한 데이터를 리포트합니다. 엔진엑스 컨트롤러는 이 지표들을 서버가 제공하는 애플리케이션에 대한 시큐리티 애널리틱스(Security Analytics) 영역에 보여줍니다.  

WAF가 식별한 데이터가 넘어오기 시작하면 시큐리티 이벤트(Security Event) 페이지에서 해당 요청들을 확인할 수 있습니다. 이를 통해 엔진엑스 앱 시큐리티 WAF가 차단하거나 공격성으로 판단한 요청의 상세 정보를 확인합니다.  

접근 제한을 보다 강하게 적용하기 전에 정상 요청이 악성 요청으로 식별되지 않도록 해야 합니다. 정상 요청이 악성 요청으로 식별됐다면 개별 보안 이벤트 정보를 활용해 이유를 점검합니다. 이를 통해 엔진엑스가 클라이언트에 제공하는 애플리케이션에 보안 취약점이 없는지 확인합니다.  

컨트롤러 앱 시큐리티는 애플리케이션을 보호해주는 간단한 WAF를 제공합니다. 모니터링을 통해 제공된 정보를 활용해 보안을 위협하는 공격 트렌드를 살펴보고, 각 이벤트의 세부 사항을 확인해 자세히 분석한 후 어떻게 대응할지 결정할 수 있습니다.  

웹 애플리케이션 방화벽은 오늘날 웹 보안 아키텍처에 매우 중요합니다. 알려진 보안 취약점을 이용해 웹 애플리케이션을 공격하는 일이 지속적으로 일어나고 있습니다. 이러한 악성 공격을 차단하면 웹 애플리케이션을 보호할 수 있을 뿐 아니라 정상 요청을 처리하는 데 필요한 컴퓨팅 리소스를 확보할 수 있습니다.  

WAF는 외부 클라이언트만을 위한 보안 솔루션이 아닙니다. WAF를 내부 트래픽에 대해 사용해, 서비스 내부의 다른 컴포넌트가 공격자에게 점유됨에 따라 내부 네트워크에서 발생하는 악성 트래픽에 대응할 필요가 있습니다.  

### 18. 실전 운영 팁  
<br/>

#### 18.1. include 구문을 사용해 깔끔한 설정 만들기  
<br/>

include 지시자를 사용해 참조할 개별 설정 파일, 디렉토리 혹은 여러 파일 및 디렉터리에 대한 마스크를 지정하고 참조합니다.  

```
http {
    include config.d/compression.conf;
    include sites-enabled/*.conf;
}
```

include 지시자는 단일 매개변수를 사용합니다. 매개변수는 특정 파일을 가리키는 경로를 지정하거나 여러 설정 파일을 지정하기 위해 마스크(mask)를 사용합니다. include는 어떤 컨텍스트서든 사용할 수 있습니다.  

include 구문을 사용해 엔진엑스 설정을 깔끔하고 간결하게 유지할 수 있습니다. 여러 설정 파일을 논리적으로 그룹화함으로써 엔진엑스 설정 파일이 수백 줄의 거대한 내용을 담게 되는 상황을 방지하고, 중복 사용되는 설정을 별도의 모듈화된 설정 파일로 만들어 여러 설정 혹은 설정의 여러 부분에서 참조하도록 합니다. 엔진엑스의 여러 패키지 배포판에 포함된 fastcgi_param 설정은 이러한 규칙에 따라 만들어진 좋은 사례입니다. 단일 엔진엑스 서버에서 다수의 FastCGI 가상 서버를 운영하는 경우, 각 FastCGI 서버가 동일한 설정을 중복해서 갖지 않고 별도로 모듈화된 설정을 참조해 사용합니다. 또 다른 설정 모듈화 예는 SSL 설정을 사용하는 경우입니다. 여러 서버를 운영하면서 비슷한 SSL 설정을 사용하는 경우, 공통 설정을 하나 만들고 필요할 때마다 include 지시자로 참조합니다. 설정을 논리적으로 그룹화하면 설정 파일들을 깔끔하게 조직화해 운영할 수 있으며, 설정을 변경해야 할 때 모듈화된 설정만 변경함으로써 여러 설정에 변경을 동시에 반영할 수 있습니다. 이처럼 설정을 파일로 그룹화하고 include 구문을 통해 참조해 사용하는 방법은 시간을 많이 절약해줍니다.  

#### 18.2. 설정 디버깅하기  
<br/>

엔진엑스 설정을 디버깅하기 위해 다음 팁을 기억해둡니다.  

+ 엔진엑스는 클라이언트 요청에 대해 세부 조건이 가장 일치하는 정책을 적용합니다. 따라서 설정을 구성하기 다소 어렵긴 하지만 엔진엑스는 이 방식으로 가장 효율적으로 동작합니다.  
+ 디버그 로그를 활성화합니다. 디버그 로그를 남기려면 엔진엑스 패키지가 --with-debug 플래그를 사용해 설정됐는지 확인합니다. 이 플래그는 각 운영체제의 패키지 관리자를 통해 다운로드한 엔진엑스에 대부분 포함돼 있지만, 직접 소스 코드를 빌드해 사용하거나 최소한의 패키지로 엔진엑스를 구성해 운영중이라면 한 번 더 확인해야 합니다. 디버그 옵션이 활성화된 것을 확인했으면 error_log 지시자를 사용해 로그 레벨을 debug로 바꿉니다.  

```
error_log /var/log/nginx/error.log debug
```

+ 특정 연결에 대해서만 디버깅을 활성화합니다. debug_connection 지시자는 events 컨텍스트에서 사용할 수 있으며 매개변수는 IP 주소 혹은 CIDR 형식으로 된 IP 주소 범위입니다. 지시자를 여러 번 사용해 디버그 대상으로 여러 IP 주소나 CIDR 주소 범위를 지정할 수 있습니다. 이 방법은 운영 환경에서 모든 연결에 대해 디버깅할 때 발생하는 성능 저하를 피하고 문제 상황을 디버깅하는 데 도움이 됩니다.
+ 특정 가상 서버에 대해서만 디버깅합니다. error_log 지시자는 http, mail, stream, server, location 컨텍스트 등에서 사용 가능하므로 필요에 따라 특정 컨텍스트에서만 디벙깅을 활성화하도록 설정할 수 있습니다.
+ 코어 덤프(core dump)를 활성화하고 이 덤프로부터 백트레이스(backtrace)를 확인합니다. 코어 덤프는 운영체제 수준에서 활성화하거나 엔진엑스 설정 파일을 통해 활성활 수 있습니다.  
+ rewrite 구문을 사용하면서 문제가 발생한 경우 rewrite_log 지시자를 사용해 재작성을 수행하는 동안 무슨 문제가 발생했는지 로그로 남겨 확인합니다.  

+ 엔진엑스는 어떻게 요청을 처리하는가: https://oreil.ly/gw9Vy
+ 관리자를 위한 디버깅 가이드: https://oreil.ly/IfLMF
+ 엔진엑스 rewrite_log 모듈 공식 문서: https://oreil.ly/VYumB